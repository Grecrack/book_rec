{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το παρακάτω απόσπασμα κώδικα εισάγει τις απαραίτητες βιβλιοθήκες και ενότητες για μια εργασία μηχανικής μάθησης. Εδώ περιγράφονται οι λειτουργίες κάθε εισαγωγής:\n",
    "\n",
    "- `numpy` (εισάγεται ως `np`): Μια βιβλιοθήκη για αριθμητικές λειτουργίες και διαχείριση πινάκων στην Python.\n",
    "- `pandas` (εισάγεται ως `pd`): Μια βιβλιοθήκη για την διαχείριση και ανάλυση δεδομένων, παρέχοντας δομές δεδομένων και λειτουργίες για την εργασία με δομημένα δεδομένα.\n",
    "- `scipy.stats`: Ένα αρθρωτό από το SciPy, μια επιστημονική βιβλιοθήκη υπολογισμού στην Python, παρέχοντας στατιστικές λειτουργίες και κατανομές.\n",
    "- `sklearn.model_selection`: Μια ενότητα από την scikit-learn, μια δημοφιλής βιβλιοθήκη μηχανικής μάθησης στην Python, που χρησιμοποιείται για την διαίρεση των δεδομένων σε σύνολα εκπαίδευσης και ελέγχου.\n",
    "- `keras.models`: Μια ενότητα από το Keras, μια βιβλιοθήκη βαθιάς μάθησης, που χρησιμοποιείται για τον καθορισμό και την εκπαίδευση μοντέλων.\n",
    "- `keras.layers`: Μια ενότητα από το Keras, που χρησιμοποιείται για την κατασκευή των στρωμάτων ενός μοντέλου νευρωνικού δικτύου.\n",
    "- `keras.optimizers`: Μια ενότητα από το Keras, που παρέχει διάφορους αλγορίθμους βελτιστοποίησης για την εκπαίδευση νευρωνικών δικτύων.\n",
    "- `keras.callbacks`: Μια ενότητα από το Keras, που περιέχει κλήσεις πίσω που μπορούν να χρησιμοποιηθούν κατά την διάρκεια της εκπαίδευσης του μοντέλου.\n",
    "- `keras.losses`: Μια ενότητα από το Keras, που παρέχει διάφορες συναρτήσεις απώλειας για προβλήματα παλινδρόμησης και ταξινόμησης.\n",
    "\n",
    "Αυτό το απόσπασμα κώδικα εισάγει τις απαραίτητες βιβλιοθήκες και ενότητες για την εκτέλεση μιας εργασίας μηχανικής μάθησης με το Keras και άλλες απαιτούμενες βιβλιοθήκες. Αυτές οι βιβλιοθήκες παρέχουν την απαραίτητη λειτουργικότητα για τη διαχείριση των δεδομένων, την κατασκευή μοντέλων, τη βελτιστοποίηση και την αξιολόγηση των μοντέλων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import MeanAbsoluteError, MeanSquaredError, Huber, LogCosh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Φόρτωση δεδομένων\n",
    "\n",
    "Εδώ γίνεται η φόρτωση των επεξεργασμένων δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=pd.read_csv('../Data/users.csv')\n",
    "ratings=pd.read_csv('../Data/ratings.csv')\n",
    "books=pd.read_csv('../Data/books.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Δημιουργία αντιστοίχισης user-id και book-id\n",
    "\n",
    "Το παρακάτω απόσπασμα κώδικα εξηγεί τον σκοπό κάθε γραμμής:\n",
    "\n",
    "1. **Λήψη μοναδικών αναγνωριστικών χρηστών**: Ανακτά τα μοναδικά αναγνωριστικά χρηστών από την στήλη 'user_id' του DataFrame ratings και τα μετατρέπει σε λίστα χρησιμοποιώντας τη συνάρτηση `tolist()`. Τα αναγνωριστικά χρηστών αποθηκεύονται στη μεταβλητή `user_ids`.\n",
    "\n",
    "2. **Δημιουργία user-id σε δείκτη**: Δημιουργεί ένα λεξικό, `user2user_encoded`, για να αντιστοιχίσει κάθε user-id στον αντίστοιχο δείκτη του. Η συνεπαγόμενη σύνταξη του λεξικού επαναλαμβάνει τη λίστα `user_ids`, αναθέτοντας έναν δείκτη (ξεκινώντας από το 0) σε κάθε user-id χρησιμοποιώντας τη συνάρτηση `enumerate()`. Το προκύπτον λεξικό αντιστοιχίζει κάθε user-id στον αντίστοιχο δείκτη του.\n",
    "\n",
    "3. **Δημιουργία αντιστοίχισης δείκτη σε user-id**: Δημιουργεί ένα λεξικό, `userencoded2user`, για να αντιστοιχίσει κάθε δείκτη στο αντίστοιχο user-id. Η συνεπαγόμενη σύνταξη του λεξικού εκτελεί την αντίστροφη αντιστοίχιση, επαναλαμβάνοντας τους αριθμημένους δείκτες και αντιστοιχίζοντας τον κάθε δείκτη στο αντίστοιχο user-id.\n",
    "\n",
    "4. **Λήψη μοναδικών book-id**: Ανακτά τα μοναδικά book-id από την στήλη 'book_id' του DataFrame ratings και τα μετατρέπει σε λίστα χρησιμοποιώντας τη συνάρτηση `tolist()`. Τα book-id αποθηκεύονται στη μεταβλητή `book_ids`.\n",
    "\n",
    "5. **Δημιουργία αντιστοίχισης book-id σε δείκτη**: Δημιουργεί ένα λεξικό, `book2book_encoded`, για να αντιστοιχίσει κάθε book-id στον αντίστοιχο δείκτη του. Παρόμοια με την αντιστοίχιση των user-id, η συνεπαγόμενη σύνταξη του λεξικού αναθέτει έναν δείκτη (ξεκινώντας από το 0) σε κάθε book-id χρησιμοποιώντας τη συνάρτηση `enumerate()`.\n",
    "\n",
    "6. **Δημιουργία αντιστοίχισης δείκτη σε book-id**: Δημιουργεί ένα λεξικό, `book_encoded2book`, για να αντιστοιχίσει κάθε δείκτη στο αντίστοιχο book-id. Η συνεπαγόμενη σύνταξη του λεξικού εκτελεί την αντίστροφη αντιστοίχιση, αντιστοιχίζοντας τον κάθε δείκτη στο αντίστοιχο book-id.\n",
    "\n",
    "Αυτές οι αντιστοιχίσεις μεταξύ user-id και book-id και των αντίστοιχων δεικτών τους είναι ουσιαστικές όταν εργάζεστε με επίπεδα ενσωμάτωσης (embedding layers) σε συστήματα συστάσεων. Παρέχουν έναν βολικό τρόπο για τη μετατροπή μεταξύ αρχικών αναγνωριστικών και δεικτών κατά τη διάρκεια της εκπαίδευσης και της πρόβλεψης του μοντέλου.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = ratings['user_id'].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "book_ids = ratings['book_id'].unique().tolist()\n",
    "book2book_encoded = {x: i for i, x in enumerate(book_ids)}\n",
    "book_encoded2book = {i: x for i, x in enumerate(book_ids)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Αντιστοίχιση user-id και book-id σε δείκτες χρηστών και βιβλίων\n",
    "\n",
    "1. **Αντιστοίχιση user-id σε Δείκτες**: Προσθέτει μια νέα στήλη με την ονομασία 'user' στο DataFrame των αξιολογήσεων (ratings DataFrame), αντιστοιχίζοντας την στήλη 'user_id' στους αντίστοιχους δείκτες των χρηστών χρησιμοποιώντας τη συνάρτηση `map()` και το λεξικό `user2user_encoded`. Κάθε αναγνωριστικό χρήστη στη στήλη 'user_id' αντικαθίσταται με την αντίστοιχη τιμή δείκτη.\n",
    "\n",
    "2. **Αντιστοίχιση book-id σε Δείκτες**: Προσθέτει μια νέα στήλη με την ονομασία 'book' στο DataFrame των αξιολογήσεων, αντιστοιχίζοντας την στήλη 'book_id' στους αντίστοιχους δείκτες των βιβλίων χρησιμοποιώντας τη συνάρτηση `map()` και το λεξικό `book2book_encoded`. Κάθε αναγνωριστικό βιβλίου στη στήλη 'book_id' αντικαθίσταται με την αντίστοιχη τιμή δείκτη.\n",
    "\n",
    "Με αυτές τις αντιστοιχίσεις, τα user-id και book-id μετατρέπονται στους αντίστοιχους δείκτες τους, οι οποίοι είναι απαραίτητοι για την παροχή των δεδομένων στα επίπεδα ενσωμάτωσης (embedding layers) του μοντέλου συστάσεων. Με αυτόν τον τρόπο, το μοντέλο λειτουργεί με δείκτες αντί για αρχικά αναγνωριστικά, επιτρέποντας αποδοτικούς υπολογισμούς και βελτιωμένη απόδοση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['user'] = ratings['user_id'].map(user2user_encoded)\n",
    "ratings['book'] = ratings['book_id'].map(book2book_encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Διαίρεση των δεδομένων σε σύνολα εκπαίδευσης και ελέγχου\n",
    "\n",
    "1. **Διαίρεση των Δεδομένων σε Σύνολα Εκπαίδευσης και Ελέγχου**: Διαιρεί το DataFrame των αξιολογήσεων (ratings DataFrame) σε σύνολα εκπαίδευσης και ελέγχου χρησιμοποιώντας τη συνάρτηση `train_test_split()` από το scikit-learn. Η συνάρτηση `train_test_split()` δέχεται τα δεδομένα εισόδου (ratings) και τα διαιρεί σε δύο υποσύνολα με βάση την παράμετρο `test_size` που καθορίζεται. Σε αυτήν την περίπτωση, το σύνολο ελέγχου θα έχει μέγεθος 20% του συνόλου δεδομένων.\n",
    "\n",
    "2. **Ανάθεση των Συνόλων Εκπαίδευσης και Ελέγχου**: Αναθέτει τα σύνολα εκπαίδευσης και ελέγχου στις μεταβλητές `train` και `test` αντίστοιχα. Το σύνολο εκπαίδευσης θα περιέχει το 80% των δεδομένων, ενώ το σύνολο ελέγχου θα περιέχει το 20% των δεδομένων.\n",
    "\n",
    "Με τη διαίρεση των δεδομένων σε σύνολα εκπαίδευσης και ελέγχου, δημιουργούνται ξεχωριστά υποσύνολα που μπορούν να χρησιμοποιηθούν για την εκπαίδευση και την αξιολόγηση του μοντέλου συστάσεων. Το σύνολο εκπαίδευσης χρησιμοποιείται για την εκπαίδευση του μοντέλου, ενώ το σύνολο ελέγχου χρησιμοποιείται για την αξιολόγηση της απόδοσής του και την γενίκευσή του σε μη ορατά δεδομένα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ανάκτηση του αριθμού των χρηστών και βιβλίων\n",
    "\n",
    "1. **Ανάκτηση του Αριθμού των Χρηστών**: Υπολογίζει τον αριθμό των μοναδικών χρηστών στο σύνολο δεδομένων, παίρνοντας το μήκος του λεξικού `user2user_encoded`. Η συνάρτηση `len()` επιστρέφει τον αριθμό των στοιχείων στο λεξικό, που αντιπροσωπεύει τον συνολικό αριθμό των μοναδικών χρηστών.\n",
    "\n",
    "2. **Ανάκτηση του Αριθμού των Βιβλίων**: Υπολογίζει τον αριθμό των μοναδικών βιβλίων στο σύνολο δεδομένων, παίρνοντας το μήκος του λεξικού `book_encoded2book`. Αντίστοιχα, η συνάρτηση `len()` επιστρέφει τον αριθμό των στοιχείων στο λεξικό, που αντιπροσωπεύει τον συνολικό αριθμό των μοναδικών βιβλίων.\n",
    "\n",
    "Μέσω της ανάκτησης του αριθμού των χρηστών και των βιβλίων, μπορούμε να προσδιορίσουμε τις διαστάσεις των ενσωματώσεων (embedding layers) στο μοντέλο συστάσεων. Ο αριθμός των χρηστών αντιστοιχεί στον αριθμό των μοναδικών δεικτών χρηστών, ενώ ο αριθμός των βιβλίων αντιστοιχεί στον αριθμό των μοναδικών δεικτών βιβλίων. Αυτές οι τιμές είναι ουσιώδεις για τον καθορισμό των σωστών διαστάσεων των ενσωματώσεων για την αναπαράσταση των χρηστών και των βιβλίων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(user2user_encoded)\n",
    "num_books = len(book_encoded2book)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ορισμός της διάστασης των ενσωματώσεων\n",
    "\n",
    "1. **Ορισμός της Διάστασης των Ενσωματώσεων**: Καθορίζει τον αριθμό των διαστάσεων των διανυσμάτων ενσωμάτωσης στο μοντέλο συστάσεων. Η μεταβλητή `embedding_dim` ορίζεται σε 10, που σημαίνει ότι κάθε χρήστης και βιβλίο θα αναπαρίσταται από ένα διάνυσμα μήκους 10 στον χώρο των ενσωματώσεων.\n",
    "\n",
    "Με τον ορισμό της διάστασης των ενσωματώσεων, καθορίζουμε το μέγεθος των αναπαραστάσεων με διανύσματα για τους χρήστες και τα βιβλία. Μια υψηλότερη διάσταση ενσωμάτωσης μπορεί να επιτρέπει πιο εκφραστικές αναπαραστάσεις, αλλά μπορεί επίσης να αυξήσει την πολυπλοκότητα του μοντέλου και τις απαιτήσεις σε πόρους. Από την άλλη πλευρά, μια χαμηλότερη διάσταση ενσωμάτωσης μπορεί να οδηγήσει σε πιο συμπαγείς αναπαραστάσεις, αλλά μπορεί επίσης να περιορίσει την ικανότητα του μοντέλου να αντιληφθεί περίπλοκες αλληλεπιδράσεις χρήστη-αντικειμένου."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Κατασκευή μοντέλου\n",
    "\n",
    "Χρησιμοποιούμε το Keras Functional API για να δημιουργήσουμε ένα μοντέλο με επίπεδα Embedding για τους χρήστες και τα βιβλία. Αυτές οι ενσωματώσεις θα μάθουν να αναπαριστούν τις προτιμήσεις των χρηστών και τις ιδιότητες των βιβλίων κατά τη διάρκεια της εκπαίδευσης."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Ορισμός Επιπέδων Εισόδου**: Δημιουργεί δύο επίπεδα εισόδου, `user_input` και `book_input`, που αντιστοιχούν στις εισόδους των χρηστών και των βιβλίων, αντίστοιχα. Αυτά τα επίπεδα εισόδου καθορίζουν το σχήμα των δεδομένων εισόδου.\n",
    "\n",
    "2. **Επίπεδα Ενσωμάτωσης**: Δημιουργεί επίπεδα ενσωμάτωσης για τους χρήστες και τα βιβλία χρησιμοποιώντας την κλάση `Embedding`. Τα επίπεδα ενσωμάτωσης αντιστοιχούν τους δείκτες των χρηστών και των βιβλίων στα αντίστοιχα διανύσματα ενσωμάτωσης στον διαστηματικό χώρο. Οι διαστάσεις των επιπέδων ενσωμάτωσης καθορίζονται από τον αριθμό των χρηστών και των βιβλίων (`num_users` και `num_books`) και την καθορισμένη `embedding_dim`.\n",
    "\n",
    "3. **Επίπεδα Επίπλευσης**: Επίπεδα επίπλευσης για τους χρήστες και τα βιβλία χρησιμοποιώντας την κλάση `Flatten`. Αυτό το βήμα μετατρέπει τα 2D τανυστικά αποτελέσματα από τα επίπεδα ενσωμάτωσης σε 1D διανύσματα.\n",
    "\n",
    "4. **Επίπεδα Συνένωσης**: Συνενώνει τα επίπεδα επίπλευσης των χρηστών και των βιβλίων χρησιμοποιώντας την κλάση `Concatenate`. Αυτό το βήμα συνδυάζει τις αναπαραστάσεις των χρηστών και των βιβλίων σε ένα μόνο διάνυσμα που καταγράφει τις αλληλεπιδράσεις μεταξύ των χρηστών και των βιβλίων.\n",
    "\n",
    "5. **Πυκνά Επίπεδα**: Προσθέτει ένα πυκνό επίπεδο με 16 μονάδες και τη συνάρτηση ενεργοποίησης ReLU πάνω από το ενωμένο επίπεδο. Αυτό το επίπεδο μαθαίνει υψηλότερες αναπαραστάσεις βάσει των συνδυασμένων πληροφοριών των χρηστών και των βιβλίων.\n",
    "\n",
    "6. **Επίπεδο Εξόδου**: Προσθέτει ένα πυκνό επίπεδο με 1 μονάδα και γραμμική συνάρτηση ενεργοποίησης ως επίπεδο εξόδου. Αυτό το επίπεδο προβλέπει τη βαθμολογία για ένα συγκεκριμένο ζεύγος χρήστη-βιβλίου.\n",
    "\n",
    "7. **Δημιουργία του Μοντέλου**: Δημιουργεί ένα αντίγραφο της κλάσης `Model`, καθορίζοντας τα επίπεδα εισόδου και εξόδου. Αυτό το μοντέλο καθορίζει την αρχιτεκτονική του συστήματος συστάσεων.\n",
    "\n",
    "8. **Επιστροφή του Μοντέλου**: Επιστρέφει το δημιουργημένο μοντέλο.\n",
    "\n",
    "Αυτή η συνάρτηση συνθέτει το μοντέλο συστάσεων με τα επίπεδα και την αρχιτεκτονική του."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    user_input = Input(shape=(1,))\n",
    "    book_input = Input(shape=(1,))\n",
    "\n",
    "    user_embedding = Embedding(num_users, embedding_dim)(user_input)\n",
    "    book_embedding = Embedding(num_books, embedding_dim)(book_input)\n",
    "\n",
    "    user_flatten = Flatten()(user_embedding)\n",
    "    book_flatten = Flatten()(book_embedding)\n",
    "\n",
    "    concatenated = Concatenate()([user_flatten, book_flatten])\n",
    "\n",
    "    dense_1 = Dense(16, activation='relu')(concatenated)\n",
    "    output = Dense(1, activation='linear')(dense_1)\n",
    "\n",
    "    model = Model(inputs=[user_input, book_input], outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εκπαιδευση μοντελου"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση `train_model` πραγματοποιεί τα ακόλουθα βήματα για την εκπαίδευση του μοντέλου συστάσεων:\n",
    "\n",
    "1. **Συντακτική Ανάλυση του Μοντέλου**: Μεταγλωττίζει το μοντέλο συστάσεων με την καθορισμένη `συνάρτηση απώλειας` και τον `βελτιστοποιητή`. Αυτό το βήμα ρυθμίζει το μοντέλο για εκπαίδευση καθορίζοντας τη συνάρτηση απώλειας που πρέπει να βελτιστοποιηθεί και τον αλγόριθμο βελτιστοποίησης που πρέπει να χρησιμοποιηθεί.\n",
    "\n",
    "2. **Εκπαίδευση του Μοντέλου**: Προσαρμόζει το μοντέλο συστάσεων στα δεδομένα εκπαίδευσης χρησιμοποιώντας τη μέθοδο `fit`. Καθορίζει τα είσοδα εκπαίδευσης (`[train.user.values, train.book.values]`), τους στόχους εκπαίδευσης (`train.rating.values`) και άλλες παράμετρους όπως το `batch_size`, τα `epochs` και το `verbose`. Αυτό το βήμα εκπαιδεύει το μοντέλο στα δεδομένα εκπαίδευσης για τον καθορισμένο αριθμό εποχών.\n",
    "\n",
    "3. **Επικύρωση του Μοντέλου**: Αξιολογεί το εκπαιδευμένο μοντέλο στα δεδομένα επικύρωσης (`[test.user.values, test.book.values]` και `test.rating.values`) κατά τη διάρκεια της διαδικασίας εκπαίδευσης. Αυτό παρέχει πληροφορίες για την απόδοση του μοντέλου σε μη διαθέσιμα δεδομένα και βοηθά στην παρακολούθηση της προόδου του.\n",
    "\n",
    "4. **Αποθήκευση του Μοντέλου**: Αποθηκεύει το εκπαιδευμένο μοντέλο στην καθορισμένη `διαδρομή αποθήκευσης του μοντέλου` χρησιμοποιώντας τον `Συντονιστή Έλεγχου Μοντέλου (ModelCheckpoint)`. Αυτό εξασφαλίζει ότι μόνο το καλύτερο μοντέλο βάσει της απώλειας επικύρωσης θα αποθηκευτεί.\n",
    "\n",
    "5. **Επιστροφή της Απώλειας Επικύρωσης**: Επιστρέφει την απώλεια επικύρωσης (`val_loss`) από το ιστορικό του μοντέλου. Η απώλεια επικύρωσης παρέχει μια ένδειξη για το πόσο καλά το μοντέλο γενικεύει σε μη διαθέσιμα δεδομένα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch_size, optimizer, loss_function, model_save_path, num_epochs):\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, mode='min')\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                        batch_size=batch_size, epochs=num_epochs, verbose=1,\n",
    "                        validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                        callbacks=[checkpoint])\n",
    "    model.save(model_save_path)\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, mode='min')\n",
    "    return history.history['val_loss'][-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ρύθμιση του Μοντέλου Συστάσεων</b>\n",
    "\n",
    "- **Βελτιστοποιητές (Optimizers)**: Μια λίστα που περιέχει παραδείγματα διαφορετικών βελτιστοποιητών, συμπεριλαμβανομένων των Adam και RMSprop. Οι βελτιστοποιητές είναι υπεύθυνοι για την ενημέρωση των βαρών του μοντέλου κατά τη διάρκεια της εκπαίδευσης για την ελαχιστοποίηση της συνάρτησης απώλειας.\n",
    "\n",
    "- **Συναρτήσεις Απώλειας (Loss Functions)**: Μια λίστα που περιέχει παραδείγματα διαφορετικών συναρτήσεων απώλειας, όπως οι MeanAbsoluteError, MeanSquaredError, Huber και LogCosh. Οι συναρτήσεις απώλειας μετρούν τη διαφορά μεταξύ των προβλεπόμενων βαθμολογιών και των πραγματικών βαθμολογιών.\n",
    "\n",
    "- **Μεγέθη Δέσμης (Batch Sizes)**: Μια λίστα που περιέχει διάφορα μεγέθη δέσμης, όπως τα 32 και 64, τα οποία καθορίζουν τον αριθμό των δειγμάτων που επεξεργάζονται πριν από την ενημέρωση των βαρών του μοντέλου.\n",
    "\n",
    "- **Διαδρομές Μοντέλου (Model Paths)**: Μια κενή λίστα που θα αποθηκεύει τις διαδρομές των καλύτερων μοντέλων που βρέθηκαν κατά τη διάρκεια της διαδικασίας ρύθμισης.\n",
    "\n",
    "- **Καλύτερη Απώλεια Επικύρωσης (Best Validation Loss)**: Μια μεταβλητή που αρχικοποιείται με ένα μεγάλο αριθμό (`float('inf')`) για να παρακολουθεί την καλύτερη απώλεια επικύρωσης που επιτεύχθηκε κατά τη διάρκεια της εκπαίδευσης.\n",
    "\n",
    "- **Βέλτιστος Βελτιστοποιητής (Best Optimizer)**: Μια μεταβλητή που θα αποθηκεύει τον βελτιστοποιητή που παρουσιάζει την καλύτερη απώλεια επικύρωσης.\n",
    "\n",
    "- **Βέλτιστη Συνάρτηση Απώλειας (Best Loss Function)**: Μια μεταβλητή που θα αποθηκεύει τη συνάρτηση απώλειας που παρουσιάζει την καλύτερη απώλεια επικύρωσης.\n",
    "\n",
    "- **Βέλτιστο Μέγεθος Δέσμης (Best Batch Size)**: Μια μεταβλητή που θα αποθηκεύει το μέγεθος δέσμης που παρουσιάζει την καλύτερη απώλεια επικύρωσης.\n",
    "\n",
    "- **Βέλτιστος Αριθμός Εποχών (Best Number of Epochs)**: Μια μεταβλητή που θα αποθηκεύει τον αριθμό εποχών που αντιστοιχεί στην καλύτερη απώλεια επικύρωσης.\n",
    "\n",
    "- **Διαδρομή του Καλύτερου Μοντέλου (Best Model Path)**: Μια μεταβλητή που θα αποθηκεύει τη διαδρομή του μοντέλου με την καλύτερη απώλεια επικύρωσης.\n",
    "\n",
    "Αυτές οι μεταβλητές και λίστες θα χρησιμοποιηθούν για την καταγραφή και ενημέρωση των βέλτιστων υπερπαραμέτρων και της απόδοσης του μοντέλου κατά τη διάρκεια της διαδικασίας ρύθμισης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [Adam(), RMSprop()]\n",
    "loss_functions = [MeanAbsoluteError(), MeanSquaredError(), Huber(), LogCosh()]\n",
    "batch_sizes = [32, 64]\n",
    "model_paths = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_optimizer = None\n",
    "best_loss_function = None\n",
    "best_batch_size = None\n",
    "best_num_epochs = None\n",
    "best_model_path = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ρύθμιση των υπερπαραμέτρων και εκπαίδευση του μοντέλου συστάσεων</b>\n",
    "\n",
    "1. **Βρόχος Βελτιστοποιητών**: Ο εξωτερικός βρόχος επανάληψης διατρέχει τους βελτιστοποιητές στη λίστα `optimizers`.\n",
    "\n",
    "2. **Βρόχος Συνάρτησης Απώλειας**: Ο δεύτερος βρόχος επανάληψης διατρέχει τις συναρτήσεις απώλειας στη λίστα `loss_functions`.\n",
    "\n",
    "3. **Βρόχος Μεγέθους Δέσμης**: Ο εσωτερικός βρόχος επανάληψης διατρέχει τα μεγέθη δέσμης στη λίστα `batch_sizes`.\n",
    "\n",
    "4. **Αριθμός Εποχών**: Η μεταβλητή `num_epochs` ορίζεται σε 20, που υποδηλώνει τον αριθμό των εποχών εκπαίδευσης για κάθε συνδυασμό υπερπαραμέτρων.\n",
    "\n",
    "5. **Δημιουργία Μοντέλου**: Δημιουργείται μια νέα περίπτωση του μοντέλου συστάσεων χρησιμοποιώντας την συνάρτηση `create_model()`.\n",
    "\n",
    "6. **Διαδρομή Αποθήκευσης Μοντέλου**: Η μεταβλητή `model_save_path` δημιουργείται για να καθορίσει τη διαδρομή για την αποθήκευση του εκπαιδευμένου μοντέλου με βάση τον τρέχοντα συνδυασμό βελτιστοποιητή, συνάρτησης απώλειας και μεγέθους δέσμης.\n",
    "\n",
    "7. **Εκτύπωση Υπερπαραμέτρων**: Ο βελτιστοποιητής, η συνάρτηση απώλειας και το μέγεθος δέσμης εκτυπώνονται για να παρακολουθηθεί η πρόοδος της διαδικασίας ρύθμισης.\n",
    "\n",
    "8. **Εκπαίδευση του Μοντέλου**: Η συνάρτηση `train_model()` καλείται για να εκπαιδεύσει το μοντέλο με τις τρέχουσες υπερπαραμέτρους. Η συνάρτηση παίρνει ως είσοδο το μέγεθος δέσμης, τον βελτιστοποιητή, τη συνάρτηση απώλειας, τη διαδρομή αποθήκευσης μοντέλου και τον αριθμό εποχών. Επιστρέφει την απώλεια επικύρωσης του εκπαιδευμένου μοντέλου.\n",
    "\n",
    "9. **Ενημέρωση των Καλύτερων Υπερπαραμέτρων**: Εάν η απώλεια επικύρωσης που έχει επιτευχθεί με τις τρέχουσες υπερπαραμέτρους είναι μικρότερη από την προηγούμενη καλύτερη απώλεια επικύρωσης (`best_val_loss`), ενημερώνονται οι καλύτερες υπερπαράμετροι και πληροφορίες του μοντέλου.\n",
    "\n",
    "10. **Διαδρομή Καλύτερου Μοντέλου**: Η μεταβλητή `best_model_path` αποθηκεύει τη διαδρομή του μοντέλου με τη χαμηλότερη απώλεια επικύρωσης μεταξύ όλων των συνδυασμών.\n",
    "\n",
    "Με την επανάληψη σε διάφορους συνδυασμούς βελτιστοποιητών, συναρτήσεων απώλειας και μεγεθών δέσμης, τον καλύτερο συνδυασμό υπερπαραμέτρων για την εκπαίδευση του μοντέλου συστάσεων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for optimizer in optimizers:\n",
    "    for loss_function in loss_functions:\n",
    "        for batch_size in batch_sizes:\n",
    "            num_epochs = 20\n",
    "            model = create_model()\n",
    "            model_save_path = f\"model_{optimizer.__class__.__name__}_{loss_function.__class__.__name__}_batch{batch_size}.h5\"\n",
    "            model_paths.append(model_save_path)\n",
    "            print(optimizer, loss_function, batch_size)\n",
    "            val_loss = train_model(batch_size, optimizer, loss_function, model_save_path, num_epochs)\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_optimizer = optimizer\n",
    "                best_loss_function = loss_function\n",
    "                best_batch_size = batch_size\n",
    "                best_num_epochs = num_epochs\n",
    "                best_model_path = model_save_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Καλύτερος Βελτιστοποιητής**: Η μεταβλητή `best_optimizer` περιέχει το αντικείμενο του βελτιστοποιητή με τη χαμηλότερη απώλεια επικύρωσης. Αυτή η γραμμή εκτυπώνει το όνομα της κλάσης του καλύτερου βελτιστοποιητή χρησιμοποιώντας το χαρακτηριστικό `__class__.__name__`.\n",
    "\n",
    "2. **Καλύτερη Συνάρτηση Απώλειας**: Η μεταβλητή `best_loss_function` περιέχει το αντικείμενο της συνάρτησης απώλειας με τη χαμηλότερη απώλεια επικύρωσης. Αυτή η γραμμή εκτυπώνει το όνομα της κλάσης της καλύτερης συνάρτησης απώλειας χρησιμοποιώντας το χαρακτηριστικό `__class__.__name__`.\n",
    "\n",
    "3. **Καλύτερο Μέγεθος Δέσμης**: Η μεταβλητή `best_batch_size` αποθηκεύει την τιμή του μεγέθους δέσμης που προκάλεσε τη χαμηλότερη απώλεια επικύρωσης.\n",
    "\n",
    "4. **Καλύτερος Αριθμός Εποχών**: Η μεταβλητή `best_num_epochs` αποθηκεύει τον αριθμό των εποχών που χρησιμοποιήθηκε για την εκπαίδευση του μοντέλου με τις καλύτερες υπερπαραμέτρους.\n",
    "\n",
    "5. **Διαδρομή Καλύτερου Μοντέλου**: Η μεταβλητή `best_model_path` περιέχει τη διαδρομή αρχείου όπου αποθηκεύεται το καλύτερο εκπαιδευμένο μοντέλο.\n",
    "\n",
    "Εκτυπώνοντας αυτές τις πληροφορίες, μπορείτε να παρακολουθείτε εύκολα τις καλύτερες υπερπαραμέτρους και τις λεπτομέρειες του μοντέλου για περαιτέρω ανάλυση και αξιολόγηση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best optimizer: {best_optimizer.__class__.__name__}\")\n",
    "print(f\"Best loss function: {best_loss_function.__class__.__name__}\")\n",
    "print(f\"Best batch size: {best_batch_size}\")\n",
    "print(f\"Best number of epochs: {best_num_epochs}\")\n",
    "print(f\"Best model path: {best_model_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αξιολογούμε τα εκπαιδευμένα μοντέλα στα δεδομένα ελέγχου για να δούμε ποιο από αυτά επιδέχεται καλύτερη απόδοση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\n",
    "    'model_Adam_MeanAbsoluteError_batch32.h5', 'model_Adam_MeanAbsoluteError_batch64.h5',\n",
    "    'model_Adam_MeanSquaredError_batch32.h5', 'model_Adam_MeanSquaredError_batch64.h5',\n",
    "    'model_Adam_Huber_batch32.h5', 'model_Adam_Huber_batch64.h5',\n",
    "    'model_Adam_LogCosh_batch32.h5', 'model_Adam_LogCosh_batch64.h5',\n",
    "    'model_RMSprop_MeanAbsoluteError_batch32.h5', 'model_RMSprop_MeanAbsoluteError_batch64.h5',\n",
    "    'model_RMSprop_MeanSquaredError_batch32.h5', 'model_RMSprop_MeanSquaredError_batch64.h5',\n",
    "    'model_RMSprop_Huber_batch32.h5', 'model_RMSprop_Huber_batch64.h5',\n",
    "    'model_RMSprop_LogCosh_batch32.h5', 'model_RMSprop_LogCosh_batch64.h5'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_path in model_paths:\n",
    "    model = load_model(model_path)\n",
    "    evaluation = model.evaluate([test.user.values, test.book.values], test.rating.values)\n",
    "    results.append((model_path, evaluation))\n",
    "\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "\n",
    "for i, (model_path, evaluation) in enumerate(results, start=1):\n",
    "    print(f'Rank {i}: Test for {model_path}: {evaluation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
