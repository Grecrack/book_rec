{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import MeanAbsoluteError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "We read the CSV file and load it into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/training/ratings.csv')\n",
    "\n",
    "books_df = pd.read_csv('../Data/training/books.csv')\n",
    "book_id_to_name = pd.Series(books_df.title.values, index = books_df.index).to_dict()\n",
    "\n",
    "# Get unique user IDs from the ratings data\n",
    "user_ids = data['user_id'].unique()\n",
    "user_ids = sorted(user_ids)\n",
    "\n",
    "# Create a DataFrame with user IDs\n",
    "users = pd.DataFrame({'user_id': user_ids})\n",
    "\n",
    "# Save the users DataFrame to a users.csv file\n",
    "users.to_csv('../Data/users.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the first few records and a summary of the data for a quick examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id  user_id  rating\n",
      "0        1      314       5\n",
      "1        1      439       3\n",
      "2        1      588       5\n",
      "3        1     1169       4\n",
      "4        1     1185       4\n",
      "             book_id        user_id         rating\n",
      "count  981756.000000  981756.000000  981756.000000\n",
      "mean     4943.275636   25616.759933       3.856534\n",
      "std      2873.207415   15228.338826       0.983941\n",
      "min         1.000000       1.000000       1.000000\n",
      "25%      2457.000000   12372.000000       3.000000\n",
      "50%      4921.000000   25077.000000       4.000000\n",
      "75%      7414.000000   38572.000000       5.000000\n",
      "max     10000.000000   53424.000000       5.000000\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_id    0\n",
      "user_id    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create user-id and book-id mapping\n",
    "We're creating two mapping dictionaries for users and books - from id to index and from index to id.  \n",
    "This will help in embedding layer where we'll be dealing with indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = data['user_id'].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "book_ids = data['book_id'].unique().tolist()\n",
    "book2book_encoded = {x: i for i, x in enumerate(book_ids)}\n",
    "book_encoded2book = {i: x for i, x in enumerate(book_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{314: 0,\n",
       " 439: 1,\n",
       " 588: 2,\n",
       " 1169: 3,\n",
       " 1185: 4,\n",
       " 2077: 5,\n",
       " 2487: 6,\n",
       " 2900: 7,\n",
       " 3662: 8,\n",
       " 3922: 9,\n",
       " 5379: 10,\n",
       " 5461: 11,\n",
       " 5885: 12,\n",
       " 6630: 13,\n",
       " 7563: 14,\n",
       " 9246: 15,\n",
       " 10140: 16,\n",
       " 10146: 17,\n",
       " 10246: 18,\n",
       " 10335: 19,\n",
       " 10610: 20,\n",
       " 10944: 21,\n",
       " 11854: 22,\n",
       " 11927: 23,\n",
       " 12471: 24,\n",
       " 13282: 25,\n",
       " 13544: 26,\n",
       " 15494: 27,\n",
       " 16377: 28,\n",
       " 16913: 29,\n",
       " 17434: 30,\n",
       " 17663: 31,\n",
       " 17984: 32,\n",
       " 18031: 33,\n",
       " 18313: 34,\n",
       " 18361: 35,\n",
       " 20076: 36,\n",
       " 20467: 37,\n",
       " 20848: 38,\n",
       " 21228: 39,\n",
       " 21487: 40,\n",
       " 21713: 41,\n",
       " 22602: 42,\n",
       " 23576: 43,\n",
       " 23612: 44,\n",
       " 24326: 45,\n",
       " 24389: 46,\n",
       " 24499: 47,\n",
       " 24834: 48,\n",
       " 24845: 49,\n",
       " 25164: 50,\n",
       " 25182: 51,\n",
       " 25214: 52,\n",
       " 26145: 53,\n",
       " 26629: 54,\n",
       " 26661: 55,\n",
       " 28158: 56,\n",
       " 28767: 57,\n",
       " 29123: 58,\n",
       " 29703: 59,\n",
       " 30681: 60,\n",
       " 31001: 61,\n",
       " 32055: 62,\n",
       " 32305: 63,\n",
       " 32592: 64,\n",
       " 32635: 65,\n",
       " 32748: 66,\n",
       " 32923: 67,\n",
       " 33065: 68,\n",
       " 33697: 69,\n",
       " 33716: 70,\n",
       " 33872: 71,\n",
       " 33890: 72,\n",
       " 37284: 73,\n",
       " 37834: 74,\n",
       " 38080: 75,\n",
       " 38082: 76,\n",
       " 38475: 77,\n",
       " 39423: 78,\n",
       " 41074: 79,\n",
       " 42404: 80,\n",
       " 43985: 81,\n",
       " 44243: 82,\n",
       " 44397: 83,\n",
       " 45269: 84,\n",
       " 45493: 85,\n",
       " 46977: 86,\n",
       " 47476: 87,\n",
       " 47746: 88,\n",
       " 47800: 89,\n",
       " 48482: 90,\n",
       " 49298: 91,\n",
       " 50104: 92,\n",
       " 50342: 93,\n",
       " 51166: 94,\n",
       " 51460: 95,\n",
       " 51480: 96,\n",
       " 51838: 97,\n",
       " 52036: 98,\n",
       " 53245: 99,\n",
       " 3022: 100,\n",
       " 5115: 101,\n",
       " 5436: 102,\n",
       " 6063: 103,\n",
       " 6342: 104,\n",
       " 8167: 105,\n",
       " 9731: 106,\n",
       " 10111: 107,\n",
       " 10288: 108,\n",
       " 10509: 109,\n",
       " 10751: 110,\n",
       " 11285: 111,\n",
       " 11408: 112,\n",
       " 11691: 113,\n",
       " 11692: 114,\n",
       " 11868: 115,\n",
       " 11945: 116,\n",
       " 12874: 117,\n",
       " 12946: 118,\n",
       " 13794: 119,\n",
       " 14372: 120,\n",
       " 14546: 121,\n",
       " 14603: 122,\n",
       " 15604: 123,\n",
       " 17566: 124,\n",
       " 17643: 125,\n",
       " 19526: 126,\n",
       " 19724: 127,\n",
       " 19729: 128,\n",
       " 19942: 129,\n",
       " 21217: 130,\n",
       " 21676: 131,\n",
       " 21733: 132,\n",
       " 27499: 133,\n",
       " 30313: 134,\n",
       " 30944: 135,\n",
       " 32918: 136,\n",
       " 36099: 137,\n",
       " 42508: 138,\n",
       " 42810: 139,\n",
       " 46421: 140,\n",
       " 47478: 141,\n",
       " 48559: 142,\n",
       " 48687: 143,\n",
       " 50096: 144,\n",
       " 50133: 145,\n",
       " 53292: 146,\n",
       " 4536: 147,\n",
       " 5272: 148,\n",
       " 6634: 149,\n",
       " 7001: 150,\n",
       " 9771: 151,\n",
       " 10249: 152,\n",
       " 11599: 153,\n",
       " 13274: 154,\n",
       " 16569: 155,\n",
       " 19984: 156,\n",
       " 20782: 157,\n",
       " 26398: 158,\n",
       " 36240: 159,\n",
       " 37855: 160,\n",
       " 43602: 161,\n",
       " 49288: 162,\n",
       " 49289: 163,\n",
       " 49295: 164,\n",
       " 49297: 165,\n",
       " 50101: 166,\n",
       " 50102: 167,\n",
       " 2324: 168,\n",
       " 3739: 169,\n",
       " 4606: 170,\n",
       " 8178: 171,\n",
       " 12381: 172,\n",
       " 13034: 173,\n",
       " 13776: 174,\n",
       " 14192: 175,\n",
       " 14207: 176,\n",
       " 17228: 177,\n",
       " 20406: 178,\n",
       " 25840: 179,\n",
       " 26579: 180,\n",
       " 27834: 181,\n",
       " 27934: 182,\n",
       " 30283: 183,\n",
       " 32338: 184,\n",
       " 32745: 185,\n",
       " 34688: 186,\n",
       " 46482: 187,\n",
       " 47411: 188,\n",
       " 47730: 189,\n",
       " 1952: 190,\n",
       " 8370: 191,\n",
       " 10402: 192,\n",
       " 12476: 193,\n",
       " 15547: 194,\n",
       " 29819: 195,\n",
       " 38798: 196,\n",
       " 45554: 197,\n",
       " 46139: 198,\n",
       " 173: 199,\n",
       " 725: 200,\n",
       " 2171: 201,\n",
       " 6016: 202,\n",
       " 8440: 203,\n",
       " 8612: 204,\n",
       " 9195: 205,\n",
       " 9722: 206,\n",
       " 10727: 207,\n",
       " 14222: 208,\n",
       " 14285: 209,\n",
       " 15318: 210,\n",
       " 17329: 211,\n",
       " 17405: 212,\n",
       " 18179: 213,\n",
       " 18199: 214,\n",
       " 18316: 215,\n",
       " 18550: 216,\n",
       " 18798: 217,\n",
       " 18957: 218,\n",
       " 22212: 219,\n",
       " 22534: 220,\n",
       " 25030: 221,\n",
       " 26146: 222,\n",
       " 26244: 223,\n",
       " 26942: 224,\n",
       " 28831: 225,\n",
       " 29031: 226,\n",
       " 29644: 227,\n",
       " 29689: 228,\n",
       " 30601: 229,\n",
       " 30879: 230,\n",
       " 31305: 231,\n",
       " 31760: 232,\n",
       " 32419: 233,\n",
       " 33119: 234,\n",
       " 33147: 235,\n",
       " 33207: 236,\n",
       " 34531: 237,\n",
       " 35259: 238,\n",
       " 35982: 239,\n",
       " 36664: 240,\n",
       " 37035: 241,\n",
       " 37041: 242,\n",
       " 38687: 243,\n",
       " 38851: 244,\n",
       " 39720: 245,\n",
       " 40167: 246,\n",
       " 40251: 247,\n",
       " 40490: 248,\n",
       " 41318: 249,\n",
       " 47490: 250,\n",
       " 49138: 251,\n",
       " 49382: 252,\n",
       " 49830: 253,\n",
       " 50610: 254,\n",
       " 51065: 255,\n",
       " 51762: 256,\n",
       " 52469: 257,\n",
       " 52583: 258,\n",
       " 52740: 259,\n",
       " 53145: 260,\n",
       " 951: 261,\n",
       " 5629: 262,\n",
       " 8484: 263,\n",
       " 12455: 264,\n",
       " 14248: 265,\n",
       " 22164: 266,\n",
       " 26718: 267,\n",
       " 37690: 268,\n",
       " 38865: 269,\n",
       " 40126: 270,\n",
       " 43622: 271,\n",
       " 2276: 272,\n",
       " 13991: 273,\n",
       " 36695: 274,\n",
       " 42574: 275,\n",
       " 3087: 276,\n",
       " 11445: 277,\n",
       " 11999: 278,\n",
       " 12466: 279,\n",
       " 14936: 280,\n",
       " 16177: 281,\n",
       " 18857: 282,\n",
       " 26053: 283,\n",
       " 53293: 284,\n",
       " 20967: 285,\n",
       " 28824: 286,\n",
       " 50999: 287,\n",
       " 5645: 288,\n",
       " 30233: 289,\n",
       " 1136: 290,\n",
       " 3114: 291,\n",
       " 8669: 292,\n",
       " 13000: 293,\n",
       " 13826: 294,\n",
       " 15054: 295,\n",
       " 16587: 296,\n",
       " 17242: 297,\n",
       " 19171: 298,\n",
       " 20991: 299,\n",
       " 24582: 300,\n",
       " 26750: 301,\n",
       " 32058: 302,\n",
       " 36031: 303,\n",
       " 37153: 304,\n",
       " 40566: 305,\n",
       " 48291: 306,\n",
       " 48297: 307,\n",
       " 52007: 308,\n",
       " 8510: 309,\n",
       " 30794: 310,\n",
       " 6698: 311,\n",
       " 11569: 312,\n",
       " 23303: 313,\n",
       " 48440: 314,\n",
       " 9806: 315,\n",
       " 11272: 316,\n",
       " 13407: 317,\n",
       " 24143: 318,\n",
       " 29951: 319,\n",
       " 6252: 320,\n",
       " 8454: 321,\n",
       " 11239: 322,\n",
       " 13360: 323,\n",
       " 27612: 324,\n",
       " 30833: 325,\n",
       " 33864: 326,\n",
       " 41240: 327,\n",
       " 9011: 328,\n",
       " 15889: 329,\n",
       " 18100: 330,\n",
       " 25278: 331,\n",
       " 37746: 332,\n",
       " 1088: 333,\n",
       " 30184: 334,\n",
       " 40468: 335,\n",
       " 8710: 336,\n",
       " 9244: 337,\n",
       " 23603: 338,\n",
       " 13095: 339,\n",
       " 15748: 340,\n",
       " 19191: 341,\n",
       " 30871: 342,\n",
       " 21724: 343,\n",
       " 32576: 344,\n",
       " 3641: 345,\n",
       " 8909: 346,\n",
       " 14385: 347,\n",
       " 16576: 348,\n",
       " 17105: 349,\n",
       " 20363: 350,\n",
       " 21543: 351,\n",
       " 26282: 352,\n",
       " 26883: 353,\n",
       " 27027: 354,\n",
       " 35146: 355,\n",
       " 43037: 356,\n",
       " 49152: 357,\n",
       " 368: 358,\n",
       " 2665: 359,\n",
       " 4821: 360,\n",
       " 7979: 361,\n",
       " 8060: 362,\n",
       " 13163: 363,\n",
       " 13580: 364,\n",
       " 16403: 365,\n",
       " 17832: 366,\n",
       " 19668: 367,\n",
       " 22313: 368,\n",
       " 22368: 369,\n",
       " 24567: 370,\n",
       " 26097: 371,\n",
       " 26800: 372,\n",
       " 27267: 373,\n",
       " 27585: 374,\n",
       " 28803: 375,\n",
       " 29353: 376,\n",
       " 29732: 377,\n",
       " 31198: 378,\n",
       " 32490: 379,\n",
       " 33357: 380,\n",
       " 39032: 381,\n",
       " 39618: 382,\n",
       " 39933: 383,\n",
       " 41062: 384,\n",
       " 41282: 385,\n",
       " 41744: 386,\n",
       " 43039: 387,\n",
       " 45498: 388,\n",
       " 46479: 389,\n",
       " 48389: 390,\n",
       " 49514: 391,\n",
       " 50593: 392,\n",
       " 51452: 393,\n",
       " 13378: 394,\n",
       " 22243: 395,\n",
       " 45811: 396,\n",
       " 8579: 397,\n",
       " 9668: 398,\n",
       " 9804: 399,\n",
       " 25048: 400,\n",
       " 31852: 401,\n",
       " 1350: 402,\n",
       " 9843: 403,\n",
       " 11837: 404,\n",
       " 14235: 405,\n",
       " 43300: 406,\n",
       " 48007: 407,\n",
       " 48822: 408,\n",
       " 3005: 409,\n",
       " 6025: 410,\n",
       " 7225: 411,\n",
       " 9165: 412,\n",
       " 11545: 413,\n",
       " 13879: 414,\n",
       " 14136: 415,\n",
       " 15935: 416,\n",
       " 17883: 417,\n",
       " 21781: 418,\n",
       " 41997: 419,\n",
       " 46147: 420,\n",
       " 6323: 421,\n",
       " 8388: 422,\n",
       " 10087: 423,\n",
       " 10662: 424,\n",
       " 10792: 425,\n",
       " 11527: 426,\n",
       " 12002: 427,\n",
       " 13189: 428,\n",
       " 18053: 429,\n",
       " 29155: 430,\n",
       " 35326: 431,\n",
       " 35780: 432,\n",
       " 52929: 433,\n",
       " 32033: 434,\n",
       " 34083: 435,\n",
       " 44496: 436,\n",
       " 1677: 437,\n",
       " 7152: 438,\n",
       " 10256: 439,\n",
       " 13084: 440,\n",
       " 15020: 441,\n",
       " 15645: 442,\n",
       " 16046: 443,\n",
       " 39452: 444,\n",
       " 33455: 445,\n",
       " 3122: 446,\n",
       " 4901: 447,\n",
       " 6856: 448,\n",
       " 7610: 449,\n",
       " 7674: 450,\n",
       " 8519: 451,\n",
       " 10457: 452,\n",
       " 12827: 453,\n",
       " 14370: 454,\n",
       " 17475: 455,\n",
       " 17652: 456,\n",
       " 17747: 457,\n",
       " 20737: 458,\n",
       " 21237: 459,\n",
       " 23497: 460,\n",
       " 24011: 461,\n",
       " 32139: 462,\n",
       " 33409: 463,\n",
       " 35111: 464,\n",
       " 35296: 465,\n",
       " 37127: 466,\n",
       " 37897: 467,\n",
       " 38766: 468,\n",
       " 41963: 469,\n",
       " 43343: 470,\n",
       " 43727: 471,\n",
       " 44023: 472,\n",
       " 44171: 473,\n",
       " 46133: 474,\n",
       " 46527: 475,\n",
       " 49998: 476,\n",
       " 50119: 477,\n",
       " 50289: 478,\n",
       " 50774: 479,\n",
       " 51692: 480,\n",
       " 25065: 481,\n",
       " 3263: 482,\n",
       " 7999: 483,\n",
       " 10120: 484,\n",
       " 13112: 485,\n",
       " 17804: 486,\n",
       " 21230: 487,\n",
       " 23558: 488,\n",
       " 1393: 489,\n",
       " 1759: 490,\n",
       " 2271: 491,\n",
       " 2722: 492,\n",
       " 5152: 493,\n",
       " 5357: 494,\n",
       " 8286: 495,\n",
       " 9787: 496,\n",
       " 12771: 497,\n",
       " 14234: 498,\n",
       " 14585: 499,\n",
       " 14839: 500,\n",
       " 14943: 501,\n",
       " 15608: 502,\n",
       " 15767: 503,\n",
       " 20375: 504,\n",
       " 20873: 505,\n",
       " 21851: 506,\n",
       " 26825: 507,\n",
       " 26992: 508,\n",
       " 27460: 509,\n",
       " 27808: 510,\n",
       " 32809: 511,\n",
       " 36308: 512,\n",
       " 41145: 513,\n",
       " 41861: 514,\n",
       " 42943: 515,\n",
       " 43887: 516,\n",
       " 48726: 517,\n",
       " 49184: 518,\n",
       " 49988: 519,\n",
       " 50976: 520,\n",
       " 52136: 521,\n",
       " 52425: 522,\n",
       " 1794: 523,\n",
       " 12361: 524,\n",
       " 17359: 525,\n",
       " 41300: 526,\n",
       " 21658: 527,\n",
       " 1296: 528,\n",
       " 3688: 529,\n",
       " 4147: 530,\n",
       " 8749: 531,\n",
       " 10297: 532,\n",
       " 10885: 533,\n",
       " 11836: 534,\n",
       " 13925: 535,\n",
       " 28943: 536,\n",
       " 30304: 537,\n",
       " 32952: 538,\n",
       " 44937: 539,\n",
       " 3050: 540,\n",
       " 6596: 541,\n",
       " 6867: 542,\n",
       " 8028: 543,\n",
       " 8444: 544,\n",
       " 11502: 545,\n",
       " 13629: 546,\n",
       " 14411: 547,\n",
       " 23063: 548,\n",
       " 23185: 549,\n",
       " 24441: 550,\n",
       " 28343: 551,\n",
       " 28531: 552,\n",
       " 34363: 553,\n",
       " 39195: 554,\n",
       " 41577: 555,\n",
       " 43176: 556,\n",
       " 44836: 557,\n",
       " 50753: 558,\n",
       " 16346: 559,\n",
       " 35608: 560,\n",
       " 10907: 561,\n",
       " 13195: 562,\n",
       " 14890: 563,\n",
       " 19944: 564,\n",
       " 20074: 565,\n",
       " 20414: 566,\n",
       " 23004: 567,\n",
       " 24092: 568,\n",
       " 25872: 569,\n",
       " 27740: 570,\n",
       " 32199: 571,\n",
       " 36883: 572,\n",
       " 40317: 573,\n",
       " 46823: 574,\n",
       " 2477: 575,\n",
       " 2998: 576,\n",
       " 3465: 577,\n",
       " 6097: 578,\n",
       " 11382: 579,\n",
       " 12734: 580,\n",
       " 12791: 581,\n",
       " 13003: 582,\n",
       " 13745: 583,\n",
       " 14177: 584,\n",
       " 16859: 585,\n",
       " 17665: 586,\n",
       " 18433: 587,\n",
       " 18908: 588,\n",
       " 21739: 589,\n",
       " 21877: 590,\n",
       " 23956: 591,\n",
       " 28416: 592,\n",
       " 29502: 593,\n",
       " 34193: 594,\n",
       " 34703: 595,\n",
       " 37405: 596,\n",
       " 37549: 597,\n",
       " 37611: 598,\n",
       " 40840: 599,\n",
       " 44305: 600,\n",
       " 44907: 601,\n",
       " 44963: 602,\n",
       " 46958: 603,\n",
       " 48196: 604,\n",
       " 48282: 605,\n",
       " 49752: 606,\n",
       " 50715: 607,\n",
       " 51612: 608,\n",
       " 8096: 609,\n",
       " 12861: 610,\n",
       " 35: 611,\n",
       " 3918: 612,\n",
       " 7970: 613,\n",
       " 8526: 614,\n",
       " 12442: 615,\n",
       " 19541: 616,\n",
       " 22913: 617,\n",
       " 23711: 618,\n",
       " 30160: 619,\n",
       " 35866: 620,\n",
       " 17222: 621,\n",
       " 17450: 622,\n",
       " 18493: 623,\n",
       " 39703: 624,\n",
       " 41747: 625,\n",
       " 8340: 626,\n",
       " 1947: 627,\n",
       " 2056: 628,\n",
       " 2940: 629,\n",
       " 5944: 630,\n",
       " 8337: 631,\n",
       " 10048: 632,\n",
       " 11727: 633,\n",
       " 11829: 634,\n",
       " 13361: 635,\n",
       " 14468: 636,\n",
       " 20332: 637,\n",
       " 21372: 638,\n",
       " 27448: 639,\n",
       " 30761: 640,\n",
       " 33621: 641,\n",
       " 35274: 642,\n",
       " 35521: 643,\n",
       " 37754: 644,\n",
       " 38070: 645,\n",
       " 39508: 646,\n",
       " 40793: 647,\n",
       " 40819: 648,\n",
       " 41854: 649,\n",
       " 42213: 650,\n",
       " 42287: 651,\n",
       " 45834: 652,\n",
       " 48704: 653,\n",
       " 51316: 654,\n",
       " 51776: 655,\n",
       " 9257: 656,\n",
       " 16421: 657,\n",
       " 40975: 658,\n",
       " 5109: 659,\n",
       " 8828: 660,\n",
       " 15522: 661,\n",
       " 19926: 662,\n",
       " 21268: 663,\n",
       " 21366: 664,\n",
       " 31336: 665,\n",
       " 33527: 666,\n",
       " 36725: 667,\n",
       " 41113: 668,\n",
       " 43554: 669,\n",
       " 45071: 670,\n",
       " 48050: 671,\n",
       " 50399: 672,\n",
       " 52214: 673,\n",
       " 1449: 674,\n",
       " 2347: 675,\n",
       " 4280: 676,\n",
       " 7212: 677,\n",
       " 8258: 678,\n",
       " 8569: 679,\n",
       " 9561: 680,\n",
       " 18120: 681,\n",
       " 20243: 682,\n",
       " 21360: 683,\n",
       " 21728: 684,\n",
       " 21788: 685,\n",
       " 23768: 686,\n",
       " 27512: 687,\n",
       " 30290: 688,\n",
       " 33947: 689,\n",
       " 34787: 690,\n",
       " 35568: 691,\n",
       " 38067: 692,\n",
       " 42568: 693,\n",
       " 45593: 694,\n",
       " 16821: 695,\n",
       " 27515: 696,\n",
       " 7801: 697,\n",
       " 15838: 698,\n",
       " 2066: 699,\n",
       " 2721: 700,\n",
       " 2874: 701,\n",
       " 5172: 702,\n",
       " 5633: 703,\n",
       " 5802: 704,\n",
       " 6360: 705,\n",
       " 6397: 706,\n",
       " 7406: 707,\n",
       " 7778: 708,\n",
       " 10688: 709,\n",
       " 11073: 710,\n",
       " 11957: 711,\n",
       " 13962: 712,\n",
       " 15501: 713,\n",
       " 17220: 714,\n",
       " 17547: 715,\n",
       " 20451: 716,\n",
       " 21164: 717,\n",
       " 23291: 718,\n",
       " 23738: 719,\n",
       " 25687: 720,\n",
       " 26182: 721,\n",
       " 26529: 722,\n",
       " 27125: 723,\n",
       " 30368: 724,\n",
       " 32149: 725,\n",
       " 36126: 726,\n",
       " 40346: 727,\n",
       " 41142: 728,\n",
       " 45059: 729,\n",
       " 46754: 730,\n",
       " 47173: 731,\n",
       " 47811: 732,\n",
       " 48493: 733,\n",
       " 2988: 734,\n",
       " 6658: 735,\n",
       " 13083: 736,\n",
       " 15186: 737,\n",
       " 21759: 738,\n",
       " 25266: 739,\n",
       " 30300: 740,\n",
       " 48285: 741,\n",
       " 51834: 742,\n",
       " 3827: 743,\n",
       " 1772: 744,\n",
       " 3362: 745,\n",
       " 4967: 746,\n",
       " 5487: 747,\n",
       " 5610: 748,\n",
       " 6958: 749,\n",
       " 17207: 750,\n",
       " 18068: 751,\n",
       " 24288: 752,\n",
       " 25320: 753,\n",
       " 25678: 754,\n",
       " 34167: 755,\n",
       " 2283: 756,\n",
       " 6567: 757,\n",
       " 14293: 758,\n",
       " 35739: 759,\n",
       " 37099: 760,\n",
       " 44650: 761,\n",
       " 47018: 762,\n",
       " 1037: 763,\n",
       " 4289: 764,\n",
       " 8833: 765,\n",
       " 9384: 766,\n",
       " 12135: 767,\n",
       " 13019: 768,\n",
       " 13299: 769,\n",
       " 15010: 770,\n",
       " 27900: 771,\n",
       " 41402: 772,\n",
       " 12145: 773,\n",
       " 42355: 774,\n",
       " 48450: 775,\n",
       " 50684: 776,\n",
       " 53173: 777,\n",
       " 946: 778,\n",
       " 2421: 779,\n",
       " 5812: 780,\n",
       " 7976: 781,\n",
       " 10315: 782,\n",
       " 11191: 783,\n",
       " 11263: 784,\n",
       " 13134: 785,\n",
       " 14873: 786,\n",
       " 16330: 787,\n",
       " 18920: 788,\n",
       " 19611: 789,\n",
       " 20247: 790,\n",
       " 29845: 791,\n",
       " 31754: 792,\n",
       " 33633: 793,\n",
       " 34763: 794,\n",
       " 35024: 795,\n",
       " 37393: 796,\n",
       " 40884: 797,\n",
       " 45935: 798,\n",
       " 48111: 799,\n",
       " 52344: 800,\n",
       " 1440: 801,\n",
       " 11421: 802,\n",
       " 16129: 803,\n",
       " 26482: 804,\n",
       " 29037: 805,\n",
       " 30513: 806,\n",
       " 35986: 807,\n",
       " 36121: 808,\n",
       " 46472: 809,\n",
       " 28458: 810,\n",
       " 33337: 811,\n",
       " 33473: 812,\n",
       " 1456: 813,\n",
       " 4044: 814,\n",
       " 4212: 815,\n",
       " 9357: 816,\n",
       " 9382: 817,\n",
       " 19895: 818,\n",
       " 21160: 819,\n",
       " 21525: 820,\n",
       " 24609: 821,\n",
       " 25698: 822,\n",
       " 25812: 823,\n",
       " 26320: 824,\n",
       " 27513: 825,\n",
       " 32916: 826,\n",
       " 38185: 827,\n",
       " 343: 828,\n",
       " 1428: 829,\n",
       " 2910: 830,\n",
       " 3785: 831,\n",
       " 3969: 832,\n",
       " 4000: 833,\n",
       " 4107: 834,\n",
       " 4900: 835,\n",
       " 5766: 836,\n",
       " 6000: 837,\n",
       " 7211: 838,\n",
       " 7302: 839,\n",
       " 7319: 840,\n",
       " 8305: 841,\n",
       " 9369: 842,\n",
       " 9985: 843,\n",
       " 11031: 844,\n",
       " 11941: 845,\n",
       " 12372: 846,\n",
       " 12397: 847,\n",
       " 12776: 848,\n",
       " 12942: 849,\n",
       " 13894: 850,\n",
       " 14742: 851,\n",
       " 16086: 852,\n",
       " 17876: 853,\n",
       " 18077: 854,\n",
       " 19138: 855,\n",
       " 19683: 856,\n",
       " 19755: 857,\n",
       " 20814: 858,\n",
       " 21251: 859,\n",
       " 22190: 860,\n",
       " 22719: 861,\n",
       " 23096: 862,\n",
       " 23610: 863,\n",
       " 23744: 864,\n",
       " 23842: 865,\n",
       " 26096: 866,\n",
       " 26223: 867,\n",
       " 26460: 868,\n",
       " 26925: 869,\n",
       " 27103: 870,\n",
       " 27455: 871,\n",
       " 27492: 872,\n",
       " 28452: 873,\n",
       " 29336: 874,\n",
       " 29832: 875,\n",
       " 31354: 876,\n",
       " 31505: 877,\n",
       " 32649: 878,\n",
       " 34585: 879,\n",
       " 34915: 880,\n",
       " 35731: 881,\n",
       " 35824: 882,\n",
       " 36752: 883,\n",
       " 36984: 884,\n",
       " 37364: 885,\n",
       " 37909: 886,\n",
       " 38071: 887,\n",
       " 38121: 888,\n",
       " 38564: 889,\n",
       " 38734: 890,\n",
       " 39646: 891,\n",
       " 46689: 892,\n",
       " 47740: 893,\n",
       " 48219: 894,\n",
       " 49573: 895,\n",
       " 52024: 896,\n",
       " 52741: 897,\n",
       " 12840: 898,\n",
       " 4715: 899,\n",
       " 5759: 900,\n",
       " 6929: 901,\n",
       " 13381: 902,\n",
       " 14016: 903,\n",
       " 14599: 904,\n",
       " 14929: 905,\n",
       " 16941: 906,\n",
       " 18145: 907,\n",
       " 18250: 908,\n",
       " 20059: 909,\n",
       " 21861: 910,\n",
       " 22487: 911,\n",
       " 26638: 912,\n",
       " 27997: 913,\n",
       " 28149: 914,\n",
       " 29765: 915,\n",
       " 31512: 916,\n",
       " 39013: 917,\n",
       " 40115: 918,\n",
       " 40360: 919,\n",
       " 41435: 920,\n",
       " 48622: 921,\n",
       " 38446: 922,\n",
       " 43949: 923,\n",
       " 9830: 924,\n",
       " 20740: 925,\n",
       " 21558: 926,\n",
       " 41114: 927,\n",
       " 41228: 928,\n",
       " 46102: 929,\n",
       " 50940: 930,\n",
       " 52965: 931,\n",
       " 3420: 932,\n",
       " 3721: 933,\n",
       " 4891: 934,\n",
       " 5912: 935,\n",
       " 10181: 936,\n",
       " 11577: 937,\n",
       " 14205: 938,\n",
       " 27045: 939,\n",
       " 27221: 940,\n",
       " 30259: 941,\n",
       " 37482: 942,\n",
       " 41792: 943,\n",
       " 50905: 944,\n",
       " 51618: 945,\n",
       " 52895: 946,\n",
       " 178: 947,\n",
       " 3246: 948,\n",
       " 15037: 949,\n",
       " 26018: 950,\n",
       " 27663: 951,\n",
       " 35157: 952,\n",
       " 36490: 953,\n",
       " 7580: 954,\n",
       " 8641: 955,\n",
       " 14575: 956,\n",
       " 15254: 957,\n",
       " 29489: 958,\n",
       " 41319: 959,\n",
       " 44694: 960,\n",
       " 46447: 961,\n",
       " 18767: 962,\n",
       " 41733: 963,\n",
       " 48809: 964,\n",
       " 274: 965,\n",
       " 5580: 966,\n",
       " 12623: 967,\n",
       " 34639: 968,\n",
       " 44617: 969,\n",
       " 47239: 970,\n",
       " 53281: 971,\n",
       " 1019: 972,\n",
       " 1484: 973,\n",
       " 4735: 974,\n",
       " 4972: 975,\n",
       " 5624: 976,\n",
       " 5917: 977,\n",
       " 8959: 978,\n",
       " 9176: 979,\n",
       " 9733: 980,\n",
       " 10309: 981,\n",
       " 10502: 982,\n",
       " 10527: 983,\n",
       " 11076: 984,\n",
       " 11911: 985,\n",
       " 13197: 986,\n",
       " 14654: 987,\n",
       " 14987: 988,\n",
       " 21744: 989,\n",
       " 22611: 990,\n",
       " 23839: 991,\n",
       " 24132: 992,\n",
       " 25255: 993,\n",
       " 25340: 994,\n",
       " 25761: 995,\n",
       " 27011: 996,\n",
       " 30768: 997,\n",
       " 31729: 998,\n",
       " 31782: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2user_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save your dictionaries\n",
    "with open('../Data/processed/user2user_encoded.pkl', 'wb') as f:\n",
    "    pickle.dump(user2user_encoded, f)\n",
    "\n",
    "with open('../Data/processed/book2book_encoded.pkl', 'wb') as f:\n",
    "    pickle.dump(book2book_encoded, f)\n",
    "\n",
    "# save book_id to name mapping\n",
    "with open('../Data/processed/book_id_to_name.pkl', 'wb') as f:\n",
    "    pickle.dump(book_id_to_name, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map user-id and book-ids to user and book indices\n",
    "We're creating two new columns in our DataFrame to hold the indices of users and books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user'] = data['user_id'].map(user2user_encoded)\n",
    "data['book'] = data['book_id'].map(book2book_encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing set\n",
    "We split our data into a training set (80%) and a test set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of users and books\n",
    "We calculate the total number of unique users and books in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(user2user_encoded)\n",
    "num_books = len(book_encoded2book)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set embedding dimension\n",
    "This is a hyperparameter for our model representing the size of the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model\n",
    "We're using Keras Functional API to build a model with Embedding layers for users and books.  \n",
    "These embeddings will learn to represent user preferences and book properties during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=[1])\n",
    "user_embedding = Embedding(num_users, embedding_size)(user_input)\n",
    "user_vec = Flatten()(user_embedding)\n",
    "\n",
    "book_input = Input(shape=[1])\n",
    "book_embedding = Embedding(num_books, embedding_size)(book_input)\n",
    "book_vec = Flatten()(book_embedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the dot product of these vectors to predict the user's rating of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = Dot(axes=1)([book_vec, user_vec])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model takes as input the user and book indices, and outputs the predicted rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[user_input, book_input], outputs=product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile our model with a mean squared error loss function, perfect for regression problem, and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where you want to save the best model\n",
    "mae_checkpoint_path = '../Data/mae_best_model.h5'\n",
    "mse_checkpoint_path = '../Data/mse_best_model.h5'\n",
    "\n",
    "# Define a callback for model checkpointing\n",
    "mae_checkpoint = ModelCheckpoint(mae_checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "mse_checkpoint = ModelCheckpoint(mse_checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "mae_initial_weights=model.get_weights()\n",
    "mse_initial_weights=model.get_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "We train our model for 5 epochs, with a batch size of 64. We also specify our validation data for validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=MeanAbsoluteError(), optimizer=Adam())\n",
    "print('loss function=MeanAbsoluteError()')\n",
    "print('optimizer=Adam()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss=MeanAbsoluteError(), optimizer=RMSprop())\n",
    "print('optimizer=RMSprop()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss=MeanAbsoluteError(), optimizer=SGD())\n",
    "print('optimizer=SGD()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "print('loss function=mean_squared_error')\n",
    "print('optimizer=Adam()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss='mean_squared_error', optimizer=RMSprop())\n",
    "print('optimizer=RMSprop()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD())\n",
    "print('optimizer=SGD()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "We evaluate our trained model on the test data to see how well it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136/6136 [==============================] - 4s 584us/step - loss: 0.9376\n",
      "Test MSE: 0.9375975728034973\n"
     ]
    }
   ],
   "source": [
    "model=load_model('../book/mse_best_model.h5')\n",
    "mse = model.evaluate([test.user.values, test.book.values], test.rating.values)\n",
    "print(f'Test MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136/6136 [==============================] - 3s 545us/step - loss: 0.7050\n",
      "Test MSE: 0.7050154209136963\n"
     ]
    }
   ],
   "source": [
    "model=load_model('../book/mae_best_model.h5')\n",
    "mae = model.evaluate([test.user.values, test.book.values], test.rating.values)\n",
    "print(f'Test MSE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m book_id_to_name_keys \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(book_id_to_name\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m      4\u001b[0m \u001b[39m# Now find the difference\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m missing_ids \u001b[39m=\u001b[39m book_ids \u001b[39m-\u001b[39;49m book_id_to_name_keys\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m missing_ids:\n\u001b[0;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe following book IDs are not included in the dictionary:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'set'"
     ]
    }
   ],
   "source": [
    "book_ids = data['book_id'].unique().tolist()\n",
    "book_id_to_name_keys = set(book_id_to_name.keys())\n",
    "\n",
    "# Now find the difference\n",
    "missing_ids = book_ids - book_id_to_name_keys\n",
    "\n",
    "if missing_ids:\n",
    "    print(\"The following book IDs are not included in the dictionary:\")\n",
    "    for book_id in missing_ids:\n",
    "        print(book_id)\n",
    "else:\n",
    "    print(\"All book IDs are included in the dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "for index, row in books_df.iterrows():\n",
    "    image_url = row['image_url']\n",
    "    \n",
    "    \n",
    "    if image_url.startswith('https://s.gr-assets.com/'):\n",
    "        print(index,' startswith s.gr')\n",
    "        book_title = row['title']\n",
    "        search_title = transform_to_search_engine_friendly(book_title)\n",
    "        search_term = f\"{search_title}+book+cover+amazon\"\n",
    "        \n",
    "        # Construct the search URL\n",
    "        search_url = f\"https://www.googleapis.com/customsearch/v1?key={api_key}&cx={search_engine_id}&q={search_term}\"\n",
    "        print(search_url)\n",
    "        # Perform the search and retrieve the image URLs\n",
    "        response = requests.get(search_url)\n",
    "        search_results = response.json()\n",
    "        items = search_results.get(\"items\", [])  # Get the list of items from the search results\n",
    "\n",
    "        index = 0\n",
    "        image_url = None\n",
    "\n",
    "        while index < len(items) and image_url is None:\n",
    "            item = items[index]\n",
    "            pagemap = item.get(\"pagemap\", {})  # Get the pagemap dictionary of the item\n",
    "            scraped = pagemap.get(\"scraped\", [])  # Get the list of scraped items\n",
    "    \n",
    "            if scraped:\n",
    "                image_link = scraped[0].get(\"image_link\")  # Get the image link from the scraped item\n",
    "                if image_link:\n",
    "                    image_url = image_link  # Found an image link, assign it to image_url\n",
    "    \n",
    "        index += 1\n",
    "\n",
    "        print(image_url)\n",
    "\n",
    "        books_df.at[index, 'image_url'] = image_url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
