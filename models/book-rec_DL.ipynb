{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import MeanAbsoluteError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "We read the CSV file and load it into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m books_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../Data/book/books.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m book_id_to_name \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(books_df\u001b[39m.\u001b[39mtitle\u001b[39m.\u001b[39mvalues, index \u001b[39m=\u001b[39m books_df\u001b[39m.\u001b[39mbook_id)\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m----> 5\u001b[0m book_id_to_name\u001b[39m.\u001b[39;49mto_csv\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/book/ratings.csv')\n",
    "\n",
    "books_df = pd.read_csv('../Data/book/books.csv')\n",
    "book_id_to_name = pd.Series(books_df.title.values, index = books_df.book_id).to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the first few records and a summary of the data for a quick examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id  user_id  rating\n",
      "0        1      314       5\n",
      "1        1      439       3\n",
      "2        1      588       5\n",
      "3        1     1169       4\n",
      "4        1     1185       4\n",
      "             book_id        user_id         rating\n",
      "count  981756.000000  981756.000000  981756.000000\n",
      "mean     4943.275636   25616.759933       3.856534\n",
      "std      2873.207415   15228.338826       0.983941\n",
      "min         1.000000       1.000000       1.000000\n",
      "25%      2457.000000   12372.000000       3.000000\n",
      "50%      4921.000000   25077.000000       4.000000\n",
      "75%      7414.000000   38572.000000       5.000000\n",
      "max     10000.000000   53424.000000       5.000000\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_id    0\n",
      "user_id    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create user-id and book-id mapping\n",
    "We're creating two mapping dictionaries for users and books - from id to index and from index to id.  \n",
    "This will help in embedding layer where we'll be dealing with indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = data['user_id'].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "book_ids = data['book_id'].unique().tolist()\n",
    "book2book_encoded = {x: i for i, x in enumerate(book_ids)}\n",
    "book_encoded2book = {i: x for i, x in enumerate(book_ids)}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map user-id and book-ids to user and book indices\n",
    "We're creating two new columns in our DataFrame to hold the indices of users and books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user'] = data['user_id'].map(user2user_encoded)\n",
    "data['book'] = data['book_id'].map(book2book_encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing set\n",
    "We split our data into a training set (80%) and a test set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of users and books\n",
    "We calculate the total number of unique users and books in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(user2user_encoded)\n",
    "num_books = len(book_encoded2book)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set embedding dimension\n",
    "This is a hyperparameter for our model representing the size of the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model\n",
    "We're using Keras Functional API to build a model with Embedding layers for users and books.  \n",
    "These embeddings will learn to represent user preferences and book properties during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=[1])\n",
    "user_embedding = Embedding(num_users, embedding_size)(user_input)\n",
    "user_vec = Flatten()(user_embedding)\n",
    "\n",
    "book_input = Input(shape=[1])\n",
    "book_embedding = Embedding(num_books, embedding_size)(book_input)\n",
    "book_vec = Flatten()(book_embedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the dot product of these vectors to predict the user's rating of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = Dot(axes=1)([book_vec, user_vec])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model takes as input the user and book indices, and outputs the predicted rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[user_input, book_input], outputs=product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile our model with a mean squared error loss function, perfect for regression problem, and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where you want to save the best model\n",
    "mae_checkpoint_path = '../data/book/mae_best_model.h5'\n",
    "mse_checkpoint_path = '../data/book/mse_best_model.h5'\n",
    "\n",
    "# Define a callback for model checkpointing\n",
    "mae_checkpoint = ModelCheckpoint(mae_checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "mse_checkpoint = ModelCheckpoint(mse_checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "mae_initial_weights=model.get_weights()\n",
    "mse_initial_weights=model.get_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "We train our model for 5 epochs, with a batch size of 64. We also specify our validation data for validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss function=MeanAbsoluteError()\n",
      "optimizer=Adam()\n",
      "batch_size=8\n",
      "Epoch 1/20\n",
      "98153/98176 [============================>.] - ETA: 0s - loss: 2.9423\n",
      "Epoch 1: val_loss improved from inf to 1.52491, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 168s 2ms/step - loss: 2.9420 - val_loss: 1.5249\n",
      "Epoch 2/20\n",
      "98163/98176 [============================>.] - ETA: 0s - loss: 1.1185\n",
      "Epoch 2: val_loss improved from 1.52491 to 0.96768, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 160s 2ms/step - loss: 1.1185 - val_loss: 0.9677\n",
      "Epoch 3/20\n",
      "98170/98176 [============================>.] - ETA: 0s - loss: 0.8374\n",
      "Epoch 3: val_loss improved from 0.96768 to 0.85716, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 160s 2ms/step - loss: 0.8374 - val_loss: 0.8572\n",
      "Epoch 4/20\n",
      "98168/98176 [============================>.] - ETA: 0s - loss: 0.7477\n",
      "Epoch 4: val_loss improved from 0.85716 to 0.81646, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 163s 2ms/step - loss: 0.7477 - val_loss: 0.8165\n",
      "Epoch 5/20\n",
      "98173/98176 [============================>.] - ETA: 0s - loss: 0.7023\n",
      "Epoch 5: val_loss improved from 0.81646 to 0.79604, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 162s 2ms/step - loss: 0.7023 - val_loss: 0.7960\n",
      "Epoch 6/20\n",
      "98165/98176 [============================>.] - ETA: 0s - loss: 0.6739\n",
      "Epoch 6: val_loss improved from 0.79604 to 0.78428, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 161s 2ms/step - loss: 0.6739 - val_loss: 0.7843\n",
      "Epoch 7/20\n",
      "98151/98176 [============================>.] - ETA: 0s - loss: 0.6552\n",
      "Epoch 7: val_loss improved from 0.78428 to 0.77697, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 157s 2ms/step - loss: 0.6552 - val_loss: 0.7770\n",
      "Epoch 8/20\n",
      "98153/98176 [============================>.] - ETA: 0s - loss: 0.6414\n",
      "Epoch 8: val_loss improved from 0.77697 to 0.77613, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 157s 2ms/step - loss: 0.6414 - val_loss: 0.7761\n",
      "Epoch 9/20\n",
      "98150/98176 [============================>.] - ETA: 0s - loss: 0.6300\n",
      "Epoch 9: val_loss improved from 0.77613 to 0.77363, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 158s 2ms/step - loss: 0.6300 - val_loss: 0.7736\n",
      "Epoch 10/20\n",
      "98145/98176 [============================>.] - ETA: 0s - loss: 0.6202\n",
      "Epoch 10: val_loss improved from 0.77363 to 0.77189, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 158s 2ms/step - loss: 0.6202 - val_loss: 0.7719\n",
      "Epoch 11/20\n",
      "98144/98176 [============================>.] - ETA: 0s - loss: 0.6119\n",
      "Epoch 11: val_loss did not improve from 0.77189\n",
      "98176/98176 [==============================] - 156s 2ms/step - loss: 0.6119 - val_loss: 0.7722\n",
      "Epoch 12/20\n",
      "98151/98176 [============================>.] - ETA: 0s - loss: 0.6041\n",
      "Epoch 12: val_loss improved from 0.77189 to 0.77109, saving model to ../data/book\\mae_best_model.h5\n",
      "98176/98176 [==============================] - 157s 2ms/step - loss: 0.6041 - val_loss: 0.7711\n",
      "Epoch 13/20\n",
      "98149/98176 [============================>.] - ETA: 0s - loss: 0.5975\n",
      "Epoch 13: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 156s 2ms/step - loss: 0.5975 - val_loss: 0.7733\n",
      "Epoch 14/20\n",
      "98160/98176 [============================>.] - ETA: 0s - loss: 0.5905\n",
      "Epoch 14: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 158s 2ms/step - loss: 0.5905 - val_loss: 0.7749\n",
      "Epoch 15/20\n",
      "98159/98176 [============================>.] - ETA: 0s - loss: 0.5845\n",
      "Epoch 15: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 157s 2ms/step - loss: 0.5845 - val_loss: 0.7766\n",
      "Epoch 16/20\n",
      "98156/98176 [============================>.] - ETA: 0s - loss: 0.5788\n",
      "Epoch 16: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 157s 2ms/step - loss: 0.5788 - val_loss: 0.7789\n",
      "Epoch 17/20\n",
      "98167/98176 [============================>.] - ETA: 0s - loss: 0.5737\n",
      "Epoch 17: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 159s 2ms/step - loss: 0.5737 - val_loss: 0.7811\n",
      "Epoch 18/20\n",
      "98147/98176 [============================>.] - ETA: 0s - loss: 0.5689\n",
      "Epoch 18: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 159s 2ms/step - loss: 0.5689 - val_loss: 0.7820\n",
      "Epoch 19/20\n",
      "98145/98176 [============================>.] - ETA: 0s - loss: 0.5639\n",
      "Epoch 19: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 158s 2ms/step - loss: 0.5640 - val_loss: 0.7840\n",
      "Epoch 20/20\n",
      "98176/98176 [==============================] - ETA: 0s - loss: 0.5596\n",
      "Epoch 20: val_loss did not improve from 0.77109\n",
      "98176/98176 [==============================] - 157s 2ms/step - loss: 0.5596 - val_loss: 0.7863\n",
      "\n",
      "batch_size=16\n",
      "Epoch 1/20\n",
      "49077/49088 [============================>.] - ETA: 0s - loss: 3.1670\n",
      "Epoch 1: val_loss did not improve from 0.77109\n",
      "49088/49088 [==============================] - 80s 2ms/step - loss: 3.1667 - val_loss: 1.7582\n",
      "Epoch 2/20\n",
      "49060/49088 [============================>.] - ETA: 0s - loss: 1.2147\n",
      "Epoch 2: val_loss did not improve from 0.77109\n",
      "49088/49088 [==============================] - 80s 2ms/step - loss: 1.2146 - val_loss: 1.0100\n",
      "Epoch 3/20\n",
      "49086/49088 [============================>.] - ETA: 0s - loss: 0.8601\n",
      "Epoch 3: val_loss did not improve from 0.77109\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.8600 - val_loss: 0.8732\n",
      "Epoch 4/20\n",
      "49083/49088 [============================>.] - ETA: 0s - loss: 0.7523\n",
      "Epoch 4: val_loss did not improve from 0.77109\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.7523 - val_loss: 0.8189\n",
      "Epoch 5/20\n",
      "49059/49088 [============================>.] - ETA: 0s - loss: 0.6983\n",
      "Epoch 5: val_loss did not improve from 0.77109\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.6983 - val_loss: 0.7936\n",
      "Epoch 6/20\n",
      "49069/49088 [============================>.] - ETA: 0s - loss: 0.6639\n",
      "Epoch 6: val_loss did not improve from 0.77109\n",
      "49088/49088 [==============================] - 80s 2ms/step - loss: 0.6639 - val_loss: 0.7765\n",
      "Epoch 7/20\n",
      "49074/49088 [============================>.] - ETA: 0s - loss: 0.6408\n",
      "Epoch 7: val_loss improved from 0.77109 to 0.76896, saving model to ../data/book\\mae_best_model.h5\n",
      "49088/49088 [==============================] - 81s 2ms/step - loss: 0.6408 - val_loss: 0.7690\n",
      "Epoch 8/20\n",
      "49076/49088 [============================>.] - ETA: 0s - loss: 0.6232\n",
      "Epoch 8: val_loss improved from 0.76896 to 0.76523, saving model to ../data/book\\mae_best_model.h5\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.6232 - val_loss: 0.7652\n",
      "Epoch 9/20\n",
      "49082/49088 [============================>.] - ETA: 0s - loss: 0.6089\n",
      "Epoch 9: val_loss improved from 0.76523 to 0.75981, saving model to ../data/book\\mae_best_model.h5\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.6089 - val_loss: 0.7598\n",
      "Epoch 10/20\n",
      "49066/49088 [============================>.] - ETA: 0s - loss: 0.5976\n",
      "Epoch 10: val_loss improved from 0.75981 to 0.75956, saving model to ../data/book\\mae_best_model.h5\n",
      "49088/49088 [==============================] - 80s 2ms/step - loss: 0.5976 - val_loss: 0.7596\n",
      "Epoch 11/20\n",
      "49083/49088 [============================>.] - ETA: 0s - loss: 0.5873\n",
      "Epoch 11: val_loss improved from 0.75956 to 0.75780, saving model to ../data/book\\mae_best_model.h5\n",
      "49088/49088 [==============================] - 80s 2ms/step - loss: 0.5873 - val_loss: 0.7578\n",
      "Epoch 12/20\n",
      "49069/49088 [============================>.] - ETA: 0s - loss: 0.5779\n",
      "Epoch 12: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.5779 - val_loss: 0.7582\n",
      "Epoch 13/20\n",
      "49084/49088 [============================>.] - ETA: 0s - loss: 0.5690\n",
      "Epoch 13: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.5690 - val_loss: 0.7591\n",
      "Epoch 14/20\n",
      "49072/49088 [============================>.] - ETA: 0s - loss: 0.5609\n",
      "Epoch 14: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 78s 2ms/step - loss: 0.5610 - val_loss: 0.7615\n",
      "Epoch 15/20\n",
      "49078/49088 [============================>.] - ETA: 0s - loss: 0.5535\n",
      "Epoch 15: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 78s 2ms/step - loss: 0.5535 - val_loss: 0.7642\n",
      "Epoch 16/20\n",
      "49059/49088 [============================>.] - ETA: 0s - loss: 0.5469\n",
      "Epoch 16: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 78s 2ms/step - loss: 0.5469 - val_loss: 0.7645\n",
      "Epoch 17/20\n",
      "49066/49088 [============================>.] - ETA: 0s - loss: 0.5404\n",
      "Epoch 17: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 78s 2ms/step - loss: 0.5403 - val_loss: 0.7680\n",
      "Epoch 18/20\n",
      "49068/49088 [============================>.] - ETA: 0s - loss: 0.5343\n",
      "Epoch 18: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 78s 2ms/step - loss: 0.5343 - val_loss: 0.7697\n",
      "Epoch 19/20\n",
      "49061/49088 [============================>.] - ETA: 0s - loss: 0.5290\n",
      "Epoch 19: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 79s 2ms/step - loss: 0.5290 - val_loss: 0.7726\n",
      "Epoch 20/20\n",
      "49082/49088 [============================>.] - ETA: 0s - loss: 0.5236\n",
      "Epoch 20: val_loss did not improve from 0.75780\n",
      "49088/49088 [==============================] - 82s 2ms/step - loss: 0.5236 - val_loss: 0.7747\n",
      "\n",
      "batch_size=32\n",
      "Epoch 1/20\n",
      "24522/24544 [============================>.] - ETA: 0s - loss: 3.5200\n",
      "Epoch 1: val_loss did not improve from 0.75780\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 3.5190 - val_loss: 2.3972\n",
      "Epoch 2/20\n",
      "24533/24544 [============================>.] - ETA: 0s - loss: 1.4801\n",
      "Epoch 2: val_loss did not improve from 0.75780\n",
      "24544/24544 [==============================] - 41s 2ms/step - loss: 1.4800 - val_loss: 1.0886\n",
      "Epoch 3/20\n",
      "24527/24544 [============================>.] - ETA: 0s - loss: 0.9039\n",
      "Epoch 3: val_loss did not improve from 0.75780\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.9039 - val_loss: 0.8921\n",
      "Epoch 4/20\n",
      "24523/24544 [============================>.] - ETA: 0s - loss: 0.7644\n",
      "Epoch 4: val_loss did not improve from 0.75780\n",
      "24544/24544 [==============================] - 41s 2ms/step - loss: 0.7644 - val_loss: 0.8214\n",
      "Epoch 5/20\n",
      "24512/24544 [============================>.] - ETA: 0s - loss: 0.6980\n",
      "Epoch 5: val_loss did not improve from 0.75780\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.6980 - val_loss: 0.7889\n",
      "Epoch 6/20\n",
      "24512/24544 [============================>.] - ETA: 0s - loss: 0.6578\n",
      "Epoch 6: val_loss did not improve from 0.75780\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.6578 - val_loss: 0.7695\n",
      "Epoch 7/20\n",
      "24543/24544 [============================>.] - ETA: 0s - loss: 0.6305\n",
      "Epoch 7: val_loss improved from 0.75780 to 0.75778, saving model to ../data/book\\mae_best_model.h5\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.6305 - val_loss: 0.7578\n",
      "Epoch 8/20\n",
      "24534/24544 [============================>.] - ETA: 0s - loss: 0.6099\n",
      "Epoch 8: val_loss improved from 0.75778 to 0.75219, saving model to ../data/book\\mae_best_model.h5\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.6098 - val_loss: 0.7522\n",
      "Epoch 9/20\n",
      "24539/24544 [============================>.] - ETA: 0s - loss: 0.5932\n",
      "Epoch 9: val_loss improved from 0.75219 to 0.74658, saving model to ../data/book\\mae_best_model.h5\n",
      "24544/24544 [==============================] - 41s 2ms/step - loss: 0.5932 - val_loss: 0.7466\n",
      "Epoch 10/20\n",
      "24534/24544 [============================>.] - ETA: 0s - loss: 0.5796\n",
      "Epoch 10: val_loss improved from 0.74658 to 0.74500, saving model to ../data/book\\mae_best_model.h5\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5796 - val_loss: 0.7450\n",
      "Epoch 11/20\n",
      "24541/24544 [============================>.] - ETA: 0s - loss: 0.5681\n",
      "Epoch 11: val_loss improved from 0.74500 to 0.74418, saving model to ../data/book\\mae_best_model.h5\n",
      "24544/24544 [==============================] - 41s 2ms/step - loss: 0.5681 - val_loss: 0.7442\n",
      "Epoch 12/20\n",
      "24521/24544 [============================>.] - ETA: 0s - loss: 0.5576\n",
      "Epoch 12: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5576 - val_loss: 0.7449\n",
      "Epoch 13/20\n",
      "24543/24544 [============================>.] - ETA: 0s - loss: 0.5476\n",
      "Epoch 13: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5476 - val_loss: 0.7454\n",
      "Epoch 14/20\n",
      "24518/24544 [============================>.] - ETA: 0s - loss: 0.5384\n",
      "Epoch 14: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5384 - val_loss: 0.7474\n",
      "Epoch 15/20\n",
      "24526/24544 [============================>.] - ETA: 0s - loss: 0.5302\n",
      "Epoch 15: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5302 - val_loss: 0.7485\n",
      "Epoch 16/20\n",
      "24526/24544 [============================>.] - ETA: 0s - loss: 0.5224\n",
      "Epoch 16: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5224 - val_loss: 0.7516\n",
      "Epoch 17/20\n",
      "24532/24544 [============================>.] - ETA: 0s - loss: 0.5155\n",
      "Epoch 17: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 39s 2ms/step - loss: 0.5155 - val_loss: 0.7547\n",
      "Epoch 18/20\n",
      "24524/24544 [============================>.] - ETA: 0s - loss: 0.5085\n",
      "Epoch 18: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5085 - val_loss: 0.7560\n",
      "Epoch 19/20\n",
      "24515/24544 [============================>.] - ETA: 0s - loss: 0.5024\n",
      "Epoch 19: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 40s 2ms/step - loss: 0.5024 - val_loss: 0.7597\n",
      "Epoch 20/20\n",
      "24532/24544 [============================>.] - ETA: 0s - loss: 0.4966\n",
      "Epoch 20: val_loss did not improve from 0.74418\n",
      "24544/24544 [==============================] - 39s 2ms/step - loss: 0.4966 - val_loss: 0.7621\n",
      "\n",
      "batch_size=64\n",
      "Epoch 1/20\n",
      "12270/12272 [============================>.] - ETA: 0s - loss: 3.7811\n",
      "Epoch 1: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 20s 2ms/step - loss: 3.7810 - val_loss: 3.3003\n",
      "Epoch 2/20\n",
      "12265/12272 [============================>.] - ETA: 0s - loss: 2.0932\n",
      "Epoch 2: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 27s 2ms/step - loss: 2.0928 - val_loss: 1.3276\n",
      "Epoch 3/20\n",
      "12261/12272 [============================>.] - ETA: 0s - loss: 1.0385\n",
      "Epoch 3: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 29s 2ms/step - loss: 1.0383 - val_loss: 0.9580\n",
      "Epoch 4/20\n",
      "12271/12272 [============================>.] - ETA: 0s - loss: 0.8123\n",
      "Epoch 4: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.8123 - val_loss: 0.8496\n",
      "Epoch 5/20\n",
      "12258/12272 [============================>.] - ETA: 0s - loss: 0.7199\n",
      "Epoch 5: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.7199 - val_loss: 0.7997\n",
      "Epoch 6/20\n",
      "12268/12272 [============================>.] - ETA: 0s - loss: 0.6680\n",
      "Epoch 6: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 34s 3ms/step - loss: 0.6680 - val_loss: 0.7717\n",
      "Epoch 7/20\n",
      "12266/12272 [============================>.] - ETA: 0s - loss: 0.6333\n",
      "Epoch 7: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.6333 - val_loss: 0.7555\n",
      "Epoch 8/20\n",
      "12265/12272 [============================>.] - ETA: 0s - loss: 0.6080\n",
      "Epoch 8: val_loss did not improve from 0.74418\n",
      "12272/12272 [==============================] - 29s 2ms/step - loss: 0.6080 - val_loss: 0.7442\n",
      "Epoch 9/20\n",
      "12271/12272 [============================>.] - ETA: 0s - loss: 0.5885\n",
      "Epoch 9: val_loss improved from 0.74418 to 0.73842, saving model to ../data/book\\mae_best_model.h5\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.5885 - val_loss: 0.7384\n",
      "Epoch 10/20\n",
      "12267/12272 [============================>.] - ETA: 0s - loss: 0.5724\n",
      "Epoch 10: val_loss improved from 0.73842 to 0.73591, saving model to ../data/book\\mae_best_model.h5\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.5724 - val_loss: 0.7359\n",
      "Epoch 11/20\n",
      "12257/12272 [============================>.] - ETA: 0s - loss: 0.5592\n",
      "Epoch 11: val_loss improved from 0.73591 to 0.73300, saving model to ../data/book\\mae_best_model.h5\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.5592 - val_loss: 0.7330\n",
      "Epoch 12/20\n",
      "12269/12272 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 12: val_loss improved from 0.73300 to 0.73141, saving model to ../data/book\\mae_best_model.h5\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.5474 - val_loss: 0.7314\n",
      "Epoch 13/20\n",
      "12254/12272 [============================>.] - ETA: 0s - loss: 0.5365\n",
      "Epoch 13: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 27s 2ms/step - loss: 0.5364 - val_loss: 0.7318\n",
      "Epoch 14/20\n",
      "12258/12272 [============================>.] - ETA: 0s - loss: 0.5261\n",
      "Epoch 14: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.5261 - val_loss: 0.7334\n",
      "Epoch 15/20\n",
      "12271/12272 [============================>.] - ETA: 0s - loss: 0.5168\n",
      "Epoch 15: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 27s 2ms/step - loss: 0.5168 - val_loss: 0.7353\n",
      "Epoch 16/20\n",
      "12269/12272 [============================>.] - ETA: 0s - loss: 0.5085\n",
      "Epoch 16: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.5085 - val_loss: 0.7351\n",
      "Epoch 17/20\n",
      "12258/12272 [============================>.] - ETA: 0s - loss: 0.4999\n",
      "Epoch 17: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.4999 - val_loss: 0.7398\n",
      "Epoch 18/20\n",
      "12266/12272 [============================>.] - ETA: 0s - loss: 0.4925\n",
      "Epoch 18: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.4925 - val_loss: 0.7426\n",
      "Epoch 19/20\n",
      "12257/12272 [============================>.] - ETA: 0s - loss: 0.4854\n",
      "Epoch 19: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 28s 2ms/step - loss: 0.4854 - val_loss: 0.7450\n",
      "Epoch 20/20\n",
      "12260/12272 [============================>.] - ETA: 0s - loss: 0.4788\n",
      "Epoch 20: val_loss did not improve from 0.73141\n",
      "12272/12272 [==============================] - 21s 2ms/step - loss: 0.4788 - val_loss: 0.7481\n",
      "\n",
      "batch_size=128\n",
      "Epoch 1/20\n",
      "6110/6136 [============================>.] - ETA: 0s - loss: 3.8569\n",
      "Epoch 1: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 3.8568 - val_loss: 3.8508\n",
      "Epoch 2/20\n",
      "6113/6136 [============================>.] - ETA: 0s - loss: 3.1789\n",
      "Epoch 2: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 3.1746 - val_loss: 2.0390\n",
      "Epoch 3/20\n",
      "6115/6136 [============================>.] - ETA: 0s - loss: 1.3932\n",
      "Epoch 3: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 1.3919 - val_loss: 1.0937\n",
      "Epoch 4/20\n",
      "6118/6136 [============================>.] - ETA: 0s - loss: 0.9102\n",
      "Epoch 4: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.9101 - val_loss: 0.8915\n",
      "Epoch 5/20\n",
      "6113/6136 [============================>.] - ETA: 0s - loss: 0.7672\n",
      "Epoch 5: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.7671 - val_loss: 0.8136\n",
      "Epoch 6/20\n",
      "6118/6136 [============================>.] - ETA: 0s - loss: 0.6986\n",
      "Epoch 6: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.6986 - val_loss: 0.7733\n",
      "Epoch 7/20\n",
      "6108/6136 [============================>.] - ETA: 0s - loss: 0.6573\n",
      "Epoch 7: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.6574 - val_loss: 0.7482\n",
      "Epoch 8/20\n",
      "6115/6136 [============================>.] - ETA: 0s - loss: 0.6292\n",
      "Epoch 8: val_loss did not improve from 0.73141\n",
      "6136/6136 [==============================] - 11s 2ms/step - loss: 0.6292 - val_loss: 0.7334\n",
      "Epoch 9/20\n",
      "6107/6136 [============================>.] - ETA: 0s - loss: 0.6080\n",
      "Epoch 9: val_loss improved from 0.73141 to 0.72333, saving model to ../data/book\\mae_best_model.h5\n",
      "6136/6136 [==============================] - 11s 2ms/step - loss: 0.6080 - val_loss: 0.7233\n",
      "Epoch 10/20\n",
      "6108/6136 [============================>.] - ETA: 0s - loss: 0.5912\n",
      "Epoch 10: val_loss improved from 0.72333 to 0.71621, saving model to ../data/book\\mae_best_model.h5\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.5912 - val_loss: 0.7162\n",
      "Epoch 11/20\n",
      "6123/6136 [============================>.] - ETA: 0s - loss: 0.5774\n",
      "Epoch 11: val_loss improved from 0.71621 to 0.71276, saving model to ../data/book\\mae_best_model.h5\n",
      "6136/6136 [==============================] - 11s 2ms/step - loss: 0.5775 - val_loss: 0.7128\n",
      "Epoch 12/20\n",
      "6127/6136 [============================>.] - ETA: 0s - loss: 0.5653\n",
      "Epoch 12: val_loss improved from 0.71276 to 0.70777, saving model to ../data/book\\mae_best_model.h5\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.5653 - val_loss: 0.7078\n",
      "Epoch 13/20\n",
      "6121/6136 [============================>.] - ETA: 0s - loss: 0.5542\n",
      "Epoch 13: val_loss improved from 0.70777 to 0.70708, saving model to ../data/book\\mae_best_model.h5\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.5542 - val_loss: 0.7071\n",
      "Epoch 14/20\n",
      "6113/6136 [============================>.] - ETA: 0s - loss: 0.5435\n",
      "Epoch 14: val_loss improved from 0.70708 to 0.70514, saving model to ../data/book\\mae_best_model.h5\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.5435 - val_loss: 0.7051\n",
      "Epoch 15/20\n",
      "6114/6136 [============================>.] - ETA: 0s - loss: 0.5335\n",
      "Epoch 15: val_loss improved from 0.70514 to 0.70502, saving model to ../data/book\\mae_best_model.h5\n",
      "6136/6136 [==============================] - 11s 2ms/step - loss: 0.5336 - val_loss: 0.7050\n",
      "Epoch 16/20\n",
      "6130/6136 [============================>.] - ETA: 0s - loss: 0.5236\n",
      "Epoch 16: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.5236 - val_loss: 0.7053\n",
      "Epoch 17/20\n",
      "6124/6136 [============================>.] - ETA: 0s - loss: 0.5142\n",
      "Epoch 17: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.5142 - val_loss: 0.7066\n",
      "Epoch 18/20\n",
      "6134/6136 [============================>.] - ETA: 0s - loss: 0.5052\n",
      "Epoch 18: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.5052 - val_loss: 0.7078\n",
      "Epoch 19/20\n",
      "6121/6136 [============================>.] - ETA: 0s - loss: 0.4965\n",
      "Epoch 19: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 11s 2ms/step - loss: 0.4965 - val_loss: 0.7096\n",
      "Epoch 20/20\n",
      "6114/6136 [============================>.] - ETA: 0s - loss: 0.4880\n",
      "Epoch 20: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 10s 2ms/step - loss: 0.4881 - val_loss: 0.7128\n",
      "\n",
      "\n",
      "\n",
      "optimizer=RMSprop()\n",
      "batch_size=8\n",
      "Epoch 1/100\n",
      "98121/98176 [============================>.] - ETA: 0s - loss: 3.8566\n",
      "Epoch 1: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 950us/step - loss: 3.8566 - val_loss: 3.8446\n",
      "Epoch 2/100\n",
      "98165/98176 [============================>.] - ETA: 0s - loss: 3.7681\n",
      "Epoch 2: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 949us/step - loss: 3.7681 - val_loss: 3.6315\n",
      "Epoch 3/100\n",
      "98149/98176 [============================>.] - ETA: 0s - loss: 3.3661\n",
      "Epoch 3: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 945us/step - loss: 3.3660 - val_loss: 3.0934\n",
      "Epoch 4/100\n",
      "98166/98176 [============================>.] - ETA: 0s - loss: 2.7698\n",
      "Epoch 4: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 948us/step - loss: 2.7698 - val_loss: 2.5099\n",
      "Epoch 5/100\n",
      "98134/98176 [============================>.] - ETA: 0s - loss: 2.2220\n",
      "Epoch 5: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 947us/step - loss: 2.2219 - val_loss: 2.0410\n",
      "Epoch 6/100\n",
      "98176/98176 [==============================] - ETA: 0s - loss: 1.8164\n",
      "Epoch 6: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 948us/step - loss: 1.8164 - val_loss: 1.7157\n",
      "Epoch 7/100\n",
      "98152/98176 [============================>.] - ETA: 0s - loss: 1.5386\n",
      "Epoch 7: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 947us/step - loss: 1.5386 - val_loss: 1.4953\n",
      "Epoch 8/100\n",
      "98169/98176 [============================>.] - ETA: 0s - loss: 1.3467\n",
      "Epoch 8: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 955us/step - loss: 1.3467 - val_loss: 1.3421\n",
      "Epoch 9/100\n",
      "98132/98176 [============================>.] - ETA: 0s - loss: 1.2104\n",
      "Epoch 9: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 951us/step - loss: 1.2104 - val_loss: 1.2319\n",
      "Epoch 10/100\n",
      "98173/98176 [============================>.] - ETA: 0s - loss: 1.1104\n",
      "Epoch 10: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 947us/step - loss: 1.1104 - val_loss: 1.1502\n",
      "Epoch 11/100\n",
      "98141/98176 [============================>.] - ETA: 0s - loss: 1.0333\n",
      "Epoch 11: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 947us/step - loss: 1.0332 - val_loss: 1.0873\n",
      "Epoch 12/100\n",
      "98159/98176 [============================>.] - ETA: 0s - loss: 0.9720\n",
      "Epoch 12: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 945us/step - loss: 0.9720 - val_loss: 1.0375\n",
      "Epoch 13/100\n",
      "98150/98176 [============================>.] - ETA: 0s - loss: 0.9221\n",
      "Epoch 13: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 949us/step - loss: 0.9221 - val_loss: 0.9970\n",
      "Epoch 14/100\n",
      "98165/98176 [============================>.] - ETA: 0s - loss: 0.8808\n",
      "Epoch 14: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 945us/step - loss: 0.8808 - val_loss: 0.9636\n",
      "Epoch 15/100\n",
      "98129/98176 [============================>.] - ETA: 0s - loss: 0.8460\n",
      "Epoch 15: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 950us/step - loss: 0.8460 - val_loss: 0.9353\n",
      "Epoch 16/100\n",
      "98143/98176 [============================>.] - ETA: 0s - loss: 0.8161\n",
      "Epoch 16: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 951us/step - loss: 0.8161 - val_loss: 0.9112\n",
      "Epoch 17/100\n",
      "98144/98176 [============================>.] - ETA: 0s - loss: 0.7902\n",
      "Epoch 17: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 948us/step - loss: 0.7902 - val_loss: 0.8902\n",
      "Epoch 18/100\n",
      "98168/98176 [============================>.] - ETA: 0s - loss: 0.7675\n",
      "Epoch 18: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 950us/step - loss: 0.7675 - val_loss: 0.8724\n",
      "Epoch 19/100\n",
      "98161/98176 [============================>.] - ETA: 0s - loss: 0.7475\n",
      "Epoch 19: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 95s 968us/step - loss: 0.7475 - val_loss: 0.8561\n",
      "Epoch 20/100\n",
      "98127/98176 [============================>.] - ETA: 0s - loss: 0.7298\n",
      "Epoch 20: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 96s 977us/step - loss: 0.7298 - val_loss: 0.8422\n",
      "Epoch 21/100\n",
      "98125/98176 [============================>.] - ETA: 0s - loss: 0.7139\n",
      "Epoch 21: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 96s 975us/step - loss: 0.7139 - val_loss: 0.8300\n",
      "Epoch 22/100\n",
      "98121/98176 [============================>.] - ETA: 0s - loss: 0.6996\n",
      "Epoch 22: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 96s 977us/step - loss: 0.6996 - val_loss: 0.8192\n",
      "Epoch 23/100\n",
      "98142/98176 [============================>.] - ETA: 0s - loss: 0.6867\n",
      "Epoch 23: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 953us/step - loss: 0.6867 - val_loss: 0.8090\n",
      "Epoch 24/100\n",
      "98157/98176 [============================>.] - ETA: 0s - loss: 0.6749\n",
      "Epoch 24: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 959us/step - loss: 0.6749 - val_loss: 0.8004\n",
      "Epoch 25/100\n",
      "98173/98176 [============================>.] - ETA: 0s - loss: 0.6642\n",
      "Epoch 25: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 96s 975us/step - loss: 0.6642 - val_loss: 0.7926\n",
      "Epoch 26/100\n",
      "98156/98176 [============================>.] - ETA: 0s - loss: 0.6545\n",
      "Epoch 26: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 95s 971us/step - loss: 0.6545 - val_loss: 0.7858\n",
      "Epoch 27/100\n",
      "98131/98176 [============================>.] - ETA: 0s - loss: 0.6454\n",
      "Epoch 27: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.6454 - val_loss: 0.7792\n",
      "Epoch 28/100\n",
      "98142/98176 [============================>.] - ETA: 0s - loss: 0.6371\n",
      "Epoch 28: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.6371 - val_loss: 0.7732\n",
      "Epoch 29/100\n",
      "98125/98176 [============================>.] - ETA: 0s - loss: 0.6295\n",
      "Epoch 29: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.6295 - val_loss: 0.7680\n",
      "Epoch 30/100\n",
      "98169/98176 [============================>.] - ETA: 0s - loss: 0.6225\n",
      "Epoch 30: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 936us/step - loss: 0.6225 - val_loss: 0.7636\n",
      "Epoch 31/100\n",
      "98139/98176 [============================>.] - ETA: 0s - loss: 0.6161\n",
      "Epoch 31: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 937us/step - loss: 0.6161 - val_loss: 0.7592\n",
      "Epoch 32/100\n",
      "98126/98176 [============================>.] - ETA: 0s - loss: 0.6101\n",
      "Epoch 32: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 937us/step - loss: 0.6101 - val_loss: 0.7549\n",
      "Epoch 33/100\n",
      "98131/98176 [============================>.] - ETA: 0s - loss: 0.6045\n",
      "Epoch 33: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 937us/step - loss: 0.6045 - val_loss: 0.7516\n",
      "Epoch 34/100\n",
      "98134/98176 [============================>.] - ETA: 0s - loss: 0.5992\n",
      "Epoch 34: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.5992 - val_loss: 0.7483\n",
      "Epoch 35/100\n",
      "98130/98176 [============================>.] - ETA: 0s - loss: 0.5943\n",
      "Epoch 35: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 949us/step - loss: 0.5944 - val_loss: 0.7452\n",
      "Epoch 36/100\n",
      "98127/98176 [============================>.] - ETA: 0s - loss: 0.5899\n",
      "Epoch 36: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 941us/step - loss: 0.5899 - val_loss: 0.7426\n",
      "Epoch 37/100\n",
      "98156/98176 [============================>.] - ETA: 0s - loss: 0.5857\n",
      "Epoch 37: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 942us/step - loss: 0.5857 - val_loss: 0.7398\n",
      "Epoch 38/100\n",
      "98141/98176 [============================>.] - ETA: 0s - loss: 0.5816\n",
      "Epoch 38: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.5817 - val_loss: 0.7375\n",
      "Epoch 39/100\n",
      "98161/98176 [============================>.] - ETA: 0s - loss: 0.5779\n",
      "Epoch 39: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.5779 - val_loss: 0.7351\n",
      "Epoch 40/100\n",
      "98174/98176 [============================>.] - ETA: 0s - loss: 0.5744\n",
      "Epoch 40: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 936us/step - loss: 0.5744 - val_loss: 0.7333\n",
      "Epoch 41/100\n",
      "98131/98176 [============================>.] - ETA: 0s - loss: 0.5712\n",
      "Epoch 41: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 936us/step - loss: 0.5712 - val_loss: 0.7318\n",
      "Epoch 42/100\n",
      "98143/98176 [============================>.] - ETA: 0s - loss: 0.5680\n",
      "Epoch 42: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 937us/step - loss: 0.5681 - val_loss: 0.7301\n",
      "Epoch 43/100\n",
      "98175/98176 [============================>.] - ETA: 0s - loss: 0.5651\n",
      "Epoch 43: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 935us/step - loss: 0.5651 - val_loss: 0.7283\n",
      "Epoch 44/100\n",
      "98159/98176 [============================>.] - ETA: 0s - loss: 0.5624\n",
      "Epoch 44: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 935us/step - loss: 0.5624 - val_loss: 0.7271\n",
      "Epoch 45/100\n",
      "98117/98176 [============================>.] - ETA: 0s - loss: 0.5598\n",
      "Epoch 45: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 942us/step - loss: 0.5598 - val_loss: 0.7256\n",
      "Epoch 46/100\n",
      "98156/98176 [============================>.] - ETA: 0s - loss: 0.5572\n",
      "Epoch 46: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 940us/step - loss: 0.5572 - val_loss: 0.7243\n",
      "Epoch 47/100\n",
      "98157/98176 [============================>.] - ETA: 0s - loss: 0.5550\n",
      "Epoch 47: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 942us/step - loss: 0.5550 - val_loss: 0.7235\n",
      "Epoch 48/100\n",
      "98150/98176 [============================>.] - ETA: 0s - loss: 0.5526\n",
      "Epoch 48: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 942us/step - loss: 0.5526 - val_loss: 0.7223\n",
      "Epoch 49/100\n",
      "98157/98176 [============================>.] - ETA: 0s - loss: 0.5506\n",
      "Epoch 49: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 937us/step - loss: 0.5506 - val_loss: 0.7216\n",
      "Epoch 50/100\n",
      "98159/98176 [============================>.] - ETA: 0s - loss: 0.5485\n",
      "Epoch 50: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.5485 - val_loss: 0.7210\n",
      "Epoch 51/100\n",
      "98123/98176 [============================>.] - ETA: 0s - loss: 0.5466\n",
      "Epoch 51: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 937us/step - loss: 0.5466 - val_loss: 0.7200\n",
      "Epoch 52/100\n",
      "98165/98176 [============================>.] - ETA: 0s - loss: 0.5449\n",
      "Epoch 52: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 936us/step - loss: 0.5449 - val_loss: 0.7195\n",
      "Epoch 53/100\n",
      "98118/98176 [============================>.] - ETA: 0s - loss: 0.5431\n",
      "Epoch 53: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 937us/step - loss: 0.5432 - val_loss: 0.7187\n",
      "Epoch 54/100\n",
      "98147/98176 [============================>.] - ETA: 0s - loss: 0.5414\n",
      "Epoch 54: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.5414 - val_loss: 0.7181\n",
      "Epoch 55/100\n",
      "98132/98176 [============================>.] - ETA: 0s - loss: 0.5399\n",
      "Epoch 55: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 945us/step - loss: 0.5399 - val_loss: 0.7175\n",
      "Epoch 56/100\n",
      "98153/98176 [============================>.] - ETA: 0s - loss: 0.5384\n",
      "Epoch 56: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 958us/step - loss: 0.5384 - val_loss: 0.7173\n",
      "Epoch 57/100\n",
      "98161/98176 [============================>.] - ETA: 0s - loss: 0.5369\n",
      "Epoch 57: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 959us/step - loss: 0.5369 - val_loss: 0.7169\n",
      "Epoch 58/100\n",
      "98134/98176 [============================>.] - ETA: 0s - loss: 0.5356\n",
      "Epoch 58: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 958us/step - loss: 0.5355 - val_loss: 0.7164\n",
      "Epoch 59/100\n",
      "98175/98176 [============================>.] - ETA: 0s - loss: 0.5343\n",
      "Epoch 59: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 940us/step - loss: 0.5343 - val_loss: 0.7160\n",
      "Epoch 60/100\n",
      "98159/98176 [============================>.] - ETA: 0s - loss: 0.5330\n",
      "Epoch 60: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 940us/step - loss: 0.5330 - val_loss: 0.7157\n",
      "Epoch 61/100\n",
      "98152/98176 [============================>.] - ETA: 0s - loss: 0.5318\n",
      "Epoch 61: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 939us/step - loss: 0.5318 - val_loss: 0.7153\n",
      "Epoch 62/100\n",
      "98119/98176 [============================>.] - ETA: 0s - loss: 0.5306\n",
      "Epoch 62: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 942us/step - loss: 0.5306 - val_loss: 0.7154\n",
      "Epoch 63/100\n",
      "98137/98176 [============================>.] - ETA: 0s - loss: 0.5294\n",
      "Epoch 63: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 942us/step - loss: 0.5294 - val_loss: 0.7148\n",
      "Epoch 64/100\n",
      "98171/98176 [============================>.] - ETA: 0s - loss: 0.5283\n",
      "Epoch 64: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 939us/step - loss: 0.5283 - val_loss: 0.7149\n",
      "Epoch 65/100\n",
      "98135/98176 [============================>.] - ETA: 0s - loss: 0.5273\n",
      "Epoch 65: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 943us/step - loss: 0.5273 - val_loss: 0.7147\n",
      "Epoch 66/100\n",
      "98141/98176 [============================>.] - ETA: 0s - loss: 0.5263\n",
      "Epoch 66: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 961us/step - loss: 0.5263 - val_loss: 0.7145\n",
      "Epoch 67/100\n",
      "98161/98176 [============================>.] - ETA: 0s - loss: 0.5253\n",
      "Epoch 67: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 939us/step - loss: 0.5253 - val_loss: 0.7144\n",
      "Epoch 68/100\n",
      "98153/98176 [============================>.] - ETA: 0s - loss: 0.5244\n",
      "Epoch 68: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 939us/step - loss: 0.5244 - val_loss: 0.7138\n",
      "Epoch 69/100\n",
      "98132/98176 [============================>.] - ETA: 0s - loss: 0.5234\n",
      "Epoch 69: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 962us/step - loss: 0.5234 - val_loss: 0.7138\n",
      "Epoch 70/100\n",
      "98145/98176 [============================>.] - ETA: 0s - loss: 0.5225\n",
      "Epoch 70: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 959us/step - loss: 0.5226 - val_loss: 0.7139\n",
      "Epoch 71/100\n",
      "98144/98176 [============================>.] - ETA: 0s - loss: 0.5216\n",
      "Epoch 71: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 943us/step - loss: 0.5216 - val_loss: 0.7137\n",
      "Epoch 72/100\n",
      "98162/98176 [============================>.] - ETA: 0s - loss: 0.5207\n",
      "Epoch 72: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 944us/step - loss: 0.5207 - val_loss: 0.7142\n",
      "Epoch 73/100\n",
      "98129/98176 [============================>.] - ETA: 0s - loss: 0.5199\n",
      "Epoch 73: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 942us/step - loss: 0.5199 - val_loss: 0.7140\n",
      "Epoch 74/100\n",
      "98127/98176 [============================>.] - ETA: 0s - loss: 0.5192\n",
      "Epoch 74: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 944us/step - loss: 0.5192 - val_loss: 0.7139\n",
      "Epoch 75/100\n",
      "98124/98176 [============================>.] - ETA: 0s - loss: 0.5184\n",
      "Epoch 75: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 943us/step - loss: 0.5184 - val_loss: 0.7137\n",
      "Epoch 76/100\n",
      "98172/98176 [============================>.] - ETA: 0s - loss: 0.5176\n",
      "Epoch 76: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 946us/step - loss: 0.5176 - val_loss: 0.7136\n",
      "Epoch 77/100\n",
      "98150/98176 [============================>.] - ETA: 0s - loss: 0.5168\n",
      "Epoch 77: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 943us/step - loss: 0.5168 - val_loss: 0.7139\n",
      "Epoch 78/100\n",
      "98129/98176 [============================>.] - ETA: 0s - loss: 0.5161\n",
      "Epoch 78: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 943us/step - loss: 0.5161 - val_loss: 0.7141\n",
      "Epoch 79/100\n",
      "98169/98176 [============================>.] - ETA: 0s - loss: 0.5155\n",
      "Epoch 79: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 946us/step - loss: 0.5154 - val_loss: 0.7139\n",
      "Epoch 80/100\n",
      "98134/98176 [============================>.] - ETA: 0s - loss: 0.5148\n",
      "Epoch 80: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 942us/step - loss: 0.5147 - val_loss: 0.7138\n",
      "Epoch 81/100\n",
      "98122/98176 [============================>.] - ETA: 0s - loss: 0.5141\n",
      "Epoch 81: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 940us/step - loss: 0.5141 - val_loss: 0.7142\n",
      "Epoch 82/100\n",
      "98133/98176 [============================>.] - ETA: 0s - loss: 0.5134\n",
      "Epoch 82: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 948us/step - loss: 0.5134 - val_loss: 0.7139\n",
      "Epoch 83/100\n",
      "98140/98176 [============================>.] - ETA: 0s - loss: 0.5127\n",
      "Epoch 83: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 944us/step - loss: 0.5127 - val_loss: 0.7143\n",
      "Epoch 84/100\n",
      "98153/98176 [============================>.] - ETA: 0s - loss: 0.5121\n",
      "Epoch 84: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 962us/step - loss: 0.5121 - val_loss: 0.7144\n",
      "Epoch 85/100\n",
      "98174/98176 [============================>.] - ETA: 0s - loss: 0.5116\n",
      "Epoch 85: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 958us/step - loss: 0.5116 - val_loss: 0.7146\n",
      "Epoch 86/100\n",
      "98122/98176 [============================>.] - ETA: 0s - loss: 0.5110\n",
      "Epoch 86: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 956us/step - loss: 0.5110 - val_loss: 0.7146\n",
      "Epoch 87/100\n",
      "98175/98176 [============================>.] - ETA: 0s - loss: 0.5104\n",
      "Epoch 87: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 960us/step - loss: 0.5104 - val_loss: 0.7150\n",
      "Epoch 88/100\n",
      "98163/98176 [============================>.] - ETA: 0s - loss: 0.5099\n",
      "Epoch 88: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 959us/step - loss: 0.5099 - val_loss: 0.7153\n",
      "Epoch 89/100\n",
      "98119/98176 [============================>.] - ETA: 0s - loss: 0.5092\n",
      "Epoch 89: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 957us/step - loss: 0.5092 - val_loss: 0.7154\n",
      "Epoch 90/100\n",
      "98132/98176 [============================>.] - ETA: 0s - loss: 0.5087\n",
      "Epoch 90: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 941us/step - loss: 0.5087 - val_loss: 0.7158\n",
      "Epoch 91/100\n",
      "98116/98176 [============================>.] - ETA: 0s - loss: 0.5081\n",
      "Epoch 91: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 942us/step - loss: 0.5081 - val_loss: 0.7159\n",
      "Epoch 92/100\n",
      "98164/98176 [============================>.] - ETA: 0s - loss: 0.5077\n",
      "Epoch 92: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.5077 - val_loss: 0.7164\n",
      "Epoch 93/100\n",
      "98167/98176 [============================>.] - ETA: 0s - loss: 0.5072\n",
      "Epoch 93: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 938us/step - loss: 0.5072 - val_loss: 0.7162\n",
      "Epoch 94/100\n",
      "98154/98176 [============================>.] - ETA: 0s - loss: 0.5066\n",
      "Epoch 94: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 943us/step - loss: 0.5066 - val_loss: 0.7166\n",
      "Epoch 95/100\n",
      "98176/98176 [==============================] - ETA: 0s - loss: 0.5062\n",
      "Epoch 95: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 941us/step - loss: 0.5062 - val_loss: 0.7167\n",
      "Epoch 96/100\n",
      "98131/98176 [============================>.] - ETA: 0s - loss: 0.5057\n",
      "Epoch 96: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 960us/step - loss: 0.5057 - val_loss: 0.7175\n",
      "Epoch 97/100\n",
      "98131/98176 [============================>.] - ETA: 0s - loss: 0.5053\n",
      "Epoch 97: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 94s 960us/step - loss: 0.5053 - val_loss: 0.7173\n",
      "Epoch 98/100\n",
      "98160/98176 [============================>.] - ETA: 0s - loss: 0.5048\n",
      "Epoch 98: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 945us/step - loss: 0.5048 - val_loss: 0.7180\n",
      "Epoch 99/100\n",
      "98149/98176 [============================>.] - ETA: 0s - loss: 0.5044\n",
      "Epoch 99: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 93s 947us/step - loss: 0.5043 - val_loss: 0.7183\n",
      "Epoch 100/100\n",
      "98169/98176 [============================>.] - ETA: 0s - loss: 0.5039\n",
      "Epoch 100: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 92s 942us/step - loss: 0.5039 - val_loss: 0.7183\n",
      "\n",
      "batch_size=16\n",
      "Epoch 1/100\n",
      "49047/49088 [============================>.] - ETA: 0s - loss: 3.8562\n",
      "Epoch 1: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 943us/step - loss: 3.8562 - val_loss: 3.8450\n",
      "Epoch 2/100\n",
      "49088/49088 [==============================] - ETA: 0s - loss: 3.7747\n",
      "Epoch 2: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 3.7747 - val_loss: 3.6500\n",
      "Epoch 3/100\n",
      "49070/49088 [============================>.] - ETA: 0s - loss: 3.4065\n",
      "Epoch 3: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 3.4064 - val_loss: 3.1534\n",
      "Epoch 4/100\n",
      "49067/49088 [============================>.] - ETA: 0s - loss: 2.8387\n",
      "Epoch 4: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 2.8386 - val_loss: 2.5824\n",
      "Epoch 5/100\n",
      "49040/49088 [============================>.] - ETA: 0s - loss: 2.2913\n",
      "Epoch 5: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 2.2910 - val_loss: 2.1058\n",
      "Epoch 6/100\n",
      "49044/49088 [============================>.] - ETA: 0s - loss: 1.8721\n",
      "Epoch 6: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 1.8720 - val_loss: 1.7651\n",
      "Epoch 7/100\n",
      "49078/49088 [============================>.] - ETA: 0s - loss: 1.5792\n",
      "Epoch 7: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 1.5792 - val_loss: 1.5314\n",
      "Epoch 8/100\n",
      "49088/49088 [==============================] - ETA: 0s - loss: 1.3758\n",
      "Epoch 8: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 943us/step - loss: 1.3758 - val_loss: 1.3686\n",
      "Epoch 9/100\n",
      "49087/49088 [============================>.] - ETA: 0s - loss: 1.2314\n",
      "Epoch 9: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 1.2314 - val_loss: 1.2521\n",
      "Epoch 10/100\n",
      "49087/49088 [============================>.] - ETA: 0s - loss: 1.1257\n",
      "Epoch 10: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 1.1257 - val_loss: 1.1661\n",
      "Epoch 11/100\n",
      "49069/49088 [============================>.] - ETA: 0s - loss: 1.0450\n",
      "Epoch 11: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 1.0450 - val_loss: 1.1003\n",
      "Epoch 12/100\n",
      "49042/49088 [============================>.] - ETA: 0s - loss: 0.9815\n",
      "Epoch 12: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 944us/step - loss: 0.9814 - val_loss: 1.0488\n",
      "Epoch 13/100\n",
      "49048/49088 [============================>.] - ETA: 0s - loss: 0.9299\n",
      "Epoch 13: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 947us/step - loss: 0.9299 - val_loss: 1.0070\n",
      "Epoch 14/100\n",
      "49055/49088 [============================>.] - ETA: 0s - loss: 0.8872\n",
      "Epoch 14: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 943us/step - loss: 0.8873 - val_loss: 0.9728\n",
      "Epoch 15/100\n",
      "49046/49088 [============================>.] - ETA: 0s - loss: 0.8515\n",
      "Epoch 15: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.8515 - val_loss: 0.9437\n",
      "Epoch 16/100\n",
      "49077/49088 [============================>.] - ETA: 0s - loss: 0.8208\n",
      "Epoch 16: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.8208 - val_loss: 0.9188\n",
      "Epoch 17/100\n",
      "49034/49088 [============================>.] - ETA: 0s - loss: 0.7943\n",
      "Epoch 17: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.7943 - val_loss: 0.8973\n",
      "Epoch 18/100\n",
      "49030/49088 [============================>.] - ETA: 0s - loss: 0.7711\n",
      "Epoch 18: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 951us/step - loss: 0.7711 - val_loss: 0.8791\n",
      "Epoch 19/100\n",
      "49054/49088 [============================>.] - ETA: 0s - loss: 0.7505\n",
      "Epoch 19: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 941us/step - loss: 0.7505 - val_loss: 0.8630\n",
      "Epoch 20/100\n",
      "49059/49088 [============================>.] - ETA: 0s - loss: 0.7324\n",
      "Epoch 20: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 940us/step - loss: 0.7324 - val_loss: 0.8488\n",
      "Epoch 21/100\n",
      "49080/49088 [============================>.] - ETA: 0s - loss: 0.7162\n",
      "Epoch 21: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 943us/step - loss: 0.7162 - val_loss: 0.8365\n",
      "Epoch 22/100\n",
      "49036/49088 [============================>.] - ETA: 0s - loss: 0.7016\n",
      "Epoch 22: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 943us/step - loss: 0.7015 - val_loss: 0.8250\n",
      "Epoch 23/100\n",
      "49058/49088 [============================>.] - ETA: 0s - loss: 0.6884\n",
      "Epoch 23: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.6884 - val_loss: 0.8153\n",
      "Epoch 24/100\n",
      "49088/49088 [==============================] - ETA: 0s - loss: 0.6763\n",
      "Epoch 24: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 947us/step - loss: 0.6763 - val_loss: 0.8060\n",
      "Epoch 25/100\n",
      "49064/49088 [============================>.] - ETA: 0s - loss: 0.6654\n",
      "Epoch 25: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.6654 - val_loss: 0.7980\n",
      "Epoch 26/100\n",
      "49073/49088 [============================>.] - ETA: 0s - loss: 0.6555\n",
      "Epoch 26: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 951us/step - loss: 0.6555 - val_loss: 0.7908\n",
      "Epoch 27/100\n",
      "49051/49088 [============================>.] - ETA: 0s - loss: 0.6463\n",
      "Epoch 27: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.6463 - val_loss: 0.7840\n",
      "Epoch 28/100\n",
      "49029/49088 [============================>.] - ETA: 0s - loss: 0.6379\n",
      "Epoch 28: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 951us/step - loss: 0.6379 - val_loss: 0.7783\n",
      "Epoch 29/100\n",
      "49035/49088 [============================>.] - ETA: 0s - loss: 0.6302\n",
      "Epoch 29: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.6302 - val_loss: 0.7729\n",
      "Epoch 30/100\n",
      "49056/49088 [============================>.] - ETA: 0s - loss: 0.6230\n",
      "Epoch 30: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.6230 - val_loss: 0.7680\n",
      "Epoch 31/100\n",
      "49041/49088 [============================>.] - ETA: 0s - loss: 0.6164\n",
      "Epoch 31: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.6164 - val_loss: 0.7636\n",
      "Epoch 32/100\n",
      "49048/49088 [============================>.] - ETA: 0s - loss: 0.6102\n",
      "Epoch 32: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.6102 - val_loss: 0.7596\n",
      "Epoch 33/100\n",
      "49036/49088 [============================>.] - ETA: 0s - loss: 0.6045\n",
      "Epoch 33: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.6045 - val_loss: 0.7558\n",
      "Epoch 34/100\n",
      "49075/49088 [============================>.] - ETA: 0s - loss: 0.5992\n",
      "Epoch 34: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5992 - val_loss: 0.7525\n",
      "Epoch 35/100\n",
      "49086/49088 [============================>.] - ETA: 0s - loss: 0.5941\n",
      "Epoch 35: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5941 - val_loss: 0.7488\n",
      "Epoch 36/100\n",
      "49084/49088 [============================>.] - ETA: 0s - loss: 0.5895\n",
      "Epoch 36: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5895 - val_loss: 0.7460\n",
      "Epoch 37/100\n",
      "49059/49088 [============================>.] - ETA: 0s - loss: 0.5850\n",
      "Epoch 37: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5851 - val_loss: 0.7436\n",
      "Epoch 38/100\n",
      "49068/49088 [============================>.] - ETA: 0s - loss: 0.5810\n",
      "Epoch 38: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 951us/step - loss: 0.5810 - val_loss: 0.7408\n",
      "Epoch 39/100\n",
      "49064/49088 [============================>.] - ETA: 0s - loss: 0.5771\n",
      "Epoch 39: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5771 - val_loss: 0.7385\n",
      "Epoch 40/100\n",
      "49032/49088 [============================>.] - ETA: 0s - loss: 0.5735\n",
      "Epoch 40: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5735 - val_loss: 0.7367\n",
      "Epoch 41/100\n",
      "49073/49088 [============================>.] - ETA: 0s - loss: 0.5701\n",
      "Epoch 41: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.5701 - val_loss: 0.7347\n",
      "Epoch 42/100\n",
      "49047/49088 [============================>.] - ETA: 0s - loss: 0.5667\n",
      "Epoch 42: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.5668 - val_loss: 0.7329\n",
      "Epoch 43/100\n",
      "49028/49088 [============================>.] - ETA: 0s - loss: 0.5639\n",
      "Epoch 43: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5639 - val_loss: 0.7311\n",
      "Epoch 44/100\n",
      "49035/49088 [============================>.] - ETA: 0s - loss: 0.5609\n",
      "Epoch 44: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5609 - val_loss: 0.7297\n",
      "Epoch 45/100\n",
      "49073/49088 [============================>.] - ETA: 0s - loss: 0.5583\n",
      "Epoch 45: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5583 - val_loss: 0.7283\n",
      "Epoch 46/100\n",
      "49051/49088 [============================>.] - ETA: 0s - loss: 0.5557\n",
      "Epoch 46: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5557 - val_loss: 0.7272\n",
      "Epoch 47/100\n",
      "49076/49088 [============================>.] - ETA: 0s - loss: 0.5533\n",
      "Epoch 47: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5532 - val_loss: 0.7259\n",
      "Epoch 48/100\n",
      "49038/49088 [============================>.] - ETA: 0s - loss: 0.5509\n",
      "Epoch 48: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5509 - val_loss: 0.7247\n",
      "Epoch 49/100\n",
      "49066/49088 [============================>.] - ETA: 0s - loss: 0.5489\n",
      "Epoch 49: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5489 - val_loss: 0.7238\n",
      "Epoch 50/100\n",
      "49088/49088 [==============================] - ETA: 0s - loss: 0.5466\n",
      "Epoch 50: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5466 - val_loss: 0.7228\n",
      "Epoch 51/100\n",
      "49063/49088 [============================>.] - ETA: 0s - loss: 0.5447\n",
      "Epoch 51: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5447 - val_loss: 0.7223\n",
      "Epoch 52/100\n",
      "49074/49088 [============================>.] - ETA: 0s - loss: 0.5429\n",
      "Epoch 52: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5429 - val_loss: 0.7213\n",
      "Epoch 53/100\n",
      "49036/49088 [============================>.] - ETA: 0s - loss: 0.5410\n",
      "Epoch 53: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5410 - val_loss: 0.7209\n",
      "Epoch 54/100\n",
      "49060/49088 [============================>.] - ETA: 0s - loss: 0.5393\n",
      "Epoch 54: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.5393 - val_loss: 0.7201\n",
      "Epoch 55/100\n",
      "49059/49088 [============================>.] - ETA: 0s - loss: 0.5378\n",
      "Epoch 55: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.5378 - val_loss: 0.7195\n",
      "Epoch 56/100\n",
      "49041/49088 [============================>.] - ETA: 0s - loss: 0.5361\n",
      "Epoch 56: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5361 - val_loss: 0.7191\n",
      "Epoch 57/100\n",
      "49062/49088 [============================>.] - ETA: 0s - loss: 0.5346\n",
      "Epoch 57: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5346 - val_loss: 0.7187\n",
      "Epoch 58/100\n",
      "49040/49088 [============================>.] - ETA: 0s - loss: 0.5333\n",
      "Epoch 58: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5333 - val_loss: 0.7181\n",
      "Epoch 59/100\n",
      "49059/49088 [============================>.] - ETA: 0s - loss: 0.5319\n",
      "Epoch 59: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5319 - val_loss: 0.7179\n",
      "Epoch 60/100\n",
      "49077/49088 [============================>.] - ETA: 0s - loss: 0.5306\n",
      "Epoch 60: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5306 - val_loss: 0.7174\n",
      "Epoch 61/100\n",
      "49074/49088 [============================>.] - ETA: 0s - loss: 0.5293\n",
      "Epoch 61: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5293 - val_loss: 0.7171\n",
      "Epoch 62/100\n",
      "49044/49088 [============================>.] - ETA: 0s - loss: 0.5281\n",
      "Epoch 62: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5281 - val_loss: 0.7170\n",
      "Epoch 63/100\n",
      "49028/49088 [============================>.] - ETA: 0s - loss: 0.5269\n",
      "Epoch 63: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5270 - val_loss: 0.7165\n",
      "Epoch 64/100\n",
      "49079/49088 [============================>.] - ETA: 0s - loss: 0.5258\n",
      "Epoch 64: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5258 - val_loss: 0.7163\n",
      "Epoch 65/100\n",
      "49043/49088 [============================>.] - ETA: 0s - loss: 0.5247\n",
      "Epoch 65: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5248 - val_loss: 0.7162\n",
      "Epoch 66/100\n",
      "49071/49088 [============================>.] - ETA: 0s - loss: 0.5236\n",
      "Epoch 66: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5236 - val_loss: 0.7156\n",
      "Epoch 67/100\n",
      "49048/49088 [============================>.] - ETA: 0s - loss: 0.5226\n",
      "Epoch 67: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.5226 - val_loss: 0.7154\n",
      "Epoch 68/100\n",
      "49032/49088 [============================>.] - ETA: 0s - loss: 0.5215\n",
      "Epoch 68: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5215 - val_loss: 0.7155\n",
      "Epoch 69/100\n",
      "49032/49088 [============================>.] - ETA: 0s - loss: 0.5206\n",
      "Epoch 69: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5206 - val_loss: 0.7151\n",
      "Epoch 70/100\n",
      "49066/49088 [============================>.] - ETA: 0s - loss: 0.5197\n",
      "Epoch 70: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 943us/step - loss: 0.5197 - val_loss: 0.7153\n",
      "Epoch 71/100\n",
      "49045/49088 [============================>.] - ETA: 0s - loss: 0.5187\n",
      "Epoch 71: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5187 - val_loss: 0.7151\n",
      "Epoch 72/100\n",
      "49059/49088 [============================>.] - ETA: 0s - loss: 0.5179\n",
      "Epoch 72: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5178 - val_loss: 0.7154\n",
      "Epoch 73/100\n",
      "49057/49088 [============================>.] - ETA: 0s - loss: 0.5170\n",
      "Epoch 73: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 944us/step - loss: 0.5170 - val_loss: 0.7152\n",
      "Epoch 74/100\n",
      "49078/49088 [============================>.] - ETA: 0s - loss: 0.5161\n",
      "Epoch 74: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5161 - val_loss: 0.7151\n",
      "Epoch 75/100\n",
      "49082/49088 [============================>.] - ETA: 0s - loss: 0.5154\n",
      "Epoch 75: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5153 - val_loss: 0.7150\n",
      "Epoch 76/100\n",
      "49054/49088 [============================>.] - ETA: 0s - loss: 0.5145\n",
      "Epoch 76: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5145 - val_loss: 0.7149\n",
      "Epoch 77/100\n",
      "49081/49088 [============================>.] - ETA: 0s - loss: 0.5137\n",
      "Epoch 77: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5137 - val_loss: 0.7150\n",
      "Epoch 78/100\n",
      "49054/49088 [============================>.] - ETA: 0s - loss: 0.5130\n",
      "Epoch 78: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5130 - val_loss: 0.7154\n",
      "Epoch 79/100\n",
      "49056/49088 [============================>.] - ETA: 0s - loss: 0.5122\n",
      "Epoch 79: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5122 - val_loss: 0.7156\n",
      "Epoch 80/100\n",
      "49077/49088 [============================>.] - ETA: 0s - loss: 0.5116\n",
      "Epoch 80: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 951us/step - loss: 0.5116 - val_loss: 0.7158\n",
      "Epoch 81/100\n",
      "49062/49088 [============================>.] - ETA: 0s - loss: 0.5108\n",
      "Epoch 81: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5108 - val_loss: 0.7157\n",
      "Epoch 82/100\n",
      "49055/49088 [============================>.] - ETA: 0s - loss: 0.5101\n",
      "Epoch 82: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5101 - val_loss: 0.7156\n",
      "Epoch 83/100\n",
      "49056/49088 [============================>.] - ETA: 0s - loss: 0.5094\n",
      "Epoch 83: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5094 - val_loss: 0.7156\n",
      "Epoch 84/100\n",
      "49072/49088 [============================>.] - ETA: 0s - loss: 0.5088\n",
      "Epoch 84: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5088 - val_loss: 0.7160\n",
      "Epoch 85/100\n",
      "49073/49088 [============================>.] - ETA: 0s - loss: 0.5081\n",
      "Epoch 85: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 944us/step - loss: 0.5081 - val_loss: 0.7161\n",
      "Epoch 86/100\n",
      "49032/49088 [============================>.] - ETA: 0s - loss: 0.5075\n",
      "Epoch 86: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 943us/step - loss: 0.5075 - val_loss: 0.7168\n",
      "Epoch 87/100\n",
      "49071/49088 [============================>.] - ETA: 0s - loss: 0.5069\n",
      "Epoch 87: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5069 - val_loss: 0.7167\n",
      "Epoch 88/100\n",
      "49057/49088 [============================>.] - ETA: 0s - loss: 0.5065\n",
      "Epoch 88: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5064 - val_loss: 0.7169\n",
      "Epoch 89/100\n",
      "49033/49088 [============================>.] - ETA: 0s - loss: 0.5058\n",
      "Epoch 89: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5058 - val_loss: 0.7170\n",
      "Epoch 90/100\n",
      "49043/49088 [============================>.] - ETA: 0s - loss: 0.5052\n",
      "Epoch 90: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5052 - val_loss: 0.7172\n",
      "Epoch 91/100\n",
      "49032/49088 [============================>.] - ETA: 0s - loss: 0.5046\n",
      "Epoch 91: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5046 - val_loss: 0.7174\n",
      "Epoch 92/100\n",
      "49053/49088 [============================>.] - ETA: 0s - loss: 0.5041\n",
      "Epoch 92: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5042 - val_loss: 0.7179\n",
      "Epoch 93/100\n",
      "49057/49088 [============================>.] - ETA: 0s - loss: 0.5036\n",
      "Epoch 93: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.5036 - val_loss: 0.7183\n",
      "Epoch 94/100\n",
      "49085/49088 [============================>.] - ETA: 0s - loss: 0.5031\n",
      "Epoch 94: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 950us/step - loss: 0.5031 - val_loss: 0.7186\n",
      "Epoch 95/100\n",
      "49048/49088 [============================>.] - ETA: 0s - loss: 0.5025\n",
      "Epoch 95: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 947us/step - loss: 0.5026 - val_loss: 0.7189\n",
      "Epoch 96/100\n",
      "49032/49088 [============================>.] - ETA: 0s - loss: 0.5020\n",
      "Epoch 96: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 945us/step - loss: 0.5020 - val_loss: 0.7193\n",
      "Epoch 97/100\n",
      "49040/49088 [============================>.] - ETA: 0s - loss: 0.5015\n",
      "Epoch 97: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 946us/step - loss: 0.5015 - val_loss: 0.7195\n",
      "Epoch 98/100\n",
      "49032/49088 [============================>.] - ETA: 0s - loss: 0.5012\n",
      "Epoch 98: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 46s 947us/step - loss: 0.5012 - val_loss: 0.7201\n",
      "Epoch 99/100\n",
      "49056/49088 [============================>.] - ETA: 0s - loss: 0.5007\n",
      "Epoch 99: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 949us/step - loss: 0.5007 - val_loss: 0.7205\n",
      "Epoch 100/100\n",
      "49043/49088 [============================>.] - ETA: 0s - loss: 0.5003\n",
      "Epoch 100: val_loss did not improve from 0.70502\n",
      "49088/49088 [==============================] - 47s 948us/step - loss: 0.5003 - val_loss: 0.7205\n",
      "\n",
      "batch_size=32\n",
      "Epoch 1/100\n",
      "24539/24544 [============================>.] - ETA: 0s - loss: 3.8556\n",
      "Epoch 1: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 978us/step - loss: 3.8556 - val_loss: 3.8434\n",
      "Epoch 2/100\n",
      "24507/24544 [============================>.] - ETA: 0s - loss: 3.7633\n",
      "Epoch 2: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 981us/step - loss: 3.7630 - val_loss: 3.6226\n",
      "Epoch 3/100\n",
      "24496/24544 [============================>.] - ETA: 0s - loss: 3.3568\n",
      "Epoch 3: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 979us/step - loss: 3.3565 - val_loss: 3.0844\n",
      "Epoch 4/100\n",
      "24512/24544 [============================>.] - ETA: 0s - loss: 2.7627\n",
      "Epoch 4: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 2.7622 - val_loss: 2.5047\n",
      "Epoch 5/100\n",
      "24502/24544 [============================>.] - ETA: 0s - loss: 2.2187\n",
      "Epoch 5: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 2.2183 - val_loss: 2.0395\n",
      "Epoch 6/100\n",
      "24518/24544 [============================>.] - ETA: 0s - loss: 1.8151\n",
      "Epoch 6: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 1.8150 - val_loss: 1.7152\n",
      "Epoch 7/100\n",
      "24542/24544 [============================>.] - ETA: 0s - loss: 1.5382\n",
      "Epoch 7: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 1.5382 - val_loss: 1.4953\n",
      "Epoch 8/100\n",
      "24528/24544 [============================>.] - ETA: 0s - loss: 1.3471\n",
      "Epoch 8: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 1.3471 - val_loss: 1.3422\n",
      "Epoch 9/100\n",
      "24489/24544 [============================>.] - ETA: 0s - loss: 1.2113\n",
      "Epoch 9: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 1.2112 - val_loss: 1.2325\n",
      "Epoch 10/100\n",
      "24529/24544 [============================>.] - ETA: 0s - loss: 1.1114\n",
      "Epoch 10: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 971us/step - loss: 1.1114 - val_loss: 1.1507\n",
      "Epoch 11/100\n",
      "24543/24544 [============================>.] - ETA: 0s - loss: 1.0349\n",
      "Epoch 11: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 1.0349 - val_loss: 1.0881\n",
      "Epoch 12/100\n",
      "24487/24544 [============================>.] - ETA: 0s - loss: 0.9742\n",
      "Epoch 12: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.9741 - val_loss: 1.0385\n",
      "Epoch 13/100\n",
      "24538/24544 [============================>.] - ETA: 0s - loss: 0.9246\n",
      "Epoch 13: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 978us/step - loss: 0.9245 - val_loss: 0.9985\n",
      "Epoch 14/100\n",
      "24519/24544 [============================>.] - ETA: 0s - loss: 0.8836\n",
      "Epoch 14: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.8836 - val_loss: 0.9649\n",
      "Epoch 15/100\n",
      "24503/24544 [============================>.] - ETA: 0s - loss: 0.8490\n",
      "Epoch 15: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.8490 - val_loss: 0.9363\n",
      "Epoch 16/100\n",
      "24510/24544 [============================>.] - ETA: 0s - loss: 0.8194\n",
      "Epoch 16: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 0.8194 - val_loss: 0.9119\n",
      "Epoch 17/100\n",
      "24531/24544 [============================>.] - ETA: 0s - loss: 0.7935\n",
      "Epoch 17: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 978us/step - loss: 0.7934 - val_loss: 0.8913\n",
      "Epoch 18/100\n",
      "24516/24544 [============================>.] - ETA: 0s - loss: 0.7708\n",
      "Epoch 18: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 979us/step - loss: 0.7708 - val_loss: 0.8728\n",
      "Epoch 19/100\n",
      "24519/24544 [============================>.] - ETA: 0s - loss: 0.7509\n",
      "Epoch 19: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.7509 - val_loss: 0.8569\n",
      "Epoch 20/100\n",
      "24514/24544 [============================>.] - ETA: 0s - loss: 0.7332\n",
      "Epoch 20: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 979us/step - loss: 0.7332 - val_loss: 0.8428\n",
      "Epoch 21/100\n",
      "24501/24544 [============================>.] - ETA: 0s - loss: 0.7173\n",
      "Epoch 21: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.7173 - val_loss: 0.8300\n",
      "Epoch 22/100\n",
      "24498/24544 [============================>.] - ETA: 0s - loss: 0.7030\n",
      "Epoch 22: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.7031 - val_loss: 0.8188\n",
      "Epoch 23/100\n",
      "24534/24544 [============================>.] - ETA: 0s - loss: 0.6900\n",
      "Epoch 23: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.6900 - val_loss: 0.8088\n",
      "Epoch 24/100\n",
      "24527/24544 [============================>.] - ETA: 0s - loss: 0.6783\n",
      "Epoch 24: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.6783 - val_loss: 0.7997\n",
      "Epoch 25/100\n",
      "24492/24544 [============================>.] - ETA: 0s - loss: 0.6676\n",
      "Epoch 25: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.6675 - val_loss: 0.7917\n",
      "Epoch 26/100\n",
      "24501/24544 [============================>.] - ETA: 0s - loss: 0.6578\n",
      "Epoch 26: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.6578 - val_loss: 0.7842\n",
      "Epoch 27/100\n",
      "24534/24544 [============================>.] - ETA: 0s - loss: 0.6487\n",
      "Epoch 27: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.6487 - val_loss: 0.7773\n",
      "Epoch 28/100\n",
      "24510/24544 [============================>.] - ETA: 0s - loss: 0.6404\n",
      "Epoch 28: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 0.6404 - val_loss: 0.7714\n",
      "Epoch 29/100\n",
      "24536/24544 [============================>.] - ETA: 0s - loss: 0.6328\n",
      "Epoch 29: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.6328 - val_loss: 0.7658\n",
      "Epoch 30/100\n",
      "24505/24544 [============================>.] - ETA: 0s - loss: 0.6256\n",
      "Epoch 30: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.6256 - val_loss: 0.7613\n",
      "Epoch 31/100\n",
      "24501/24544 [============================>.] - ETA: 0s - loss: 0.6191\n",
      "Epoch 31: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.6191 - val_loss: 0.7566\n",
      "Epoch 32/100\n",
      "24529/24544 [============================>.] - ETA: 0s - loss: 0.6131\n",
      "Epoch 32: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.6131 - val_loss: 0.7521\n",
      "Epoch 33/100\n",
      "24541/24544 [============================>.] - ETA: 0s - loss: 0.6074\n",
      "Epoch 33: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 970us/step - loss: 0.6074 - val_loss: 0.7483\n",
      "Epoch 34/100\n",
      "24520/24544 [============================>.] - ETA: 0s - loss: 0.6023\n",
      "Epoch 34: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 978us/step - loss: 0.6023 - val_loss: 0.7451\n",
      "Epoch 35/100\n",
      "24496/24544 [============================>.] - ETA: 0s - loss: 0.5973\n",
      "Epoch 35: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5973 - val_loss: 0.7416\n",
      "Epoch 36/100\n",
      "24524/24544 [============================>.] - ETA: 0s - loss: 0.5928\n",
      "Epoch 36: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5928 - val_loss: 0.7385\n",
      "Epoch 37/100\n",
      "24501/24544 [============================>.] - ETA: 0s - loss: 0.5885\n",
      "Epoch 37: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5885 - val_loss: 0.7361\n",
      "Epoch 38/100\n",
      "24530/24544 [============================>.] - ETA: 0s - loss: 0.5845\n",
      "Epoch 38: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.5845 - val_loss: 0.7335\n",
      "Epoch 39/100\n",
      "24524/24544 [============================>.] - ETA: 0s - loss: 0.5808\n",
      "Epoch 39: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.5808 - val_loss: 0.7313\n",
      "Epoch 40/100\n",
      "24516/24544 [============================>.] - ETA: 0s - loss: 0.5772\n",
      "Epoch 40: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5772 - val_loss: 0.7289\n",
      "Epoch 41/100\n",
      "24513/24544 [============================>.] - ETA: 0s - loss: 0.5740\n",
      "Epoch 41: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.5740 - val_loss: 0.7270\n",
      "Epoch 42/100\n",
      "24527/24544 [============================>.] - ETA: 0s - loss: 0.5709\n",
      "Epoch 42: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.5708 - val_loss: 0.7249\n",
      "Epoch 43/100\n",
      "24540/24544 [============================>.] - ETA: 0s - loss: 0.5679\n",
      "Epoch 43: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.5678 - val_loss: 0.7232\n",
      "Epoch 44/100\n",
      "24530/24544 [============================>.] - ETA: 0s - loss: 0.5651\n",
      "Epoch 44: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5651 - val_loss: 0.7217\n",
      "Epoch 45/100\n",
      "24531/24544 [============================>.] - ETA: 0s - loss: 0.5625\n",
      "Epoch 45: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5625 - val_loss: 0.7203\n",
      "Epoch 46/100\n",
      "24497/24544 [============================>.] - ETA: 0s - loss: 0.5600\n",
      "Epoch 46: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 0.5600 - val_loss: 0.7189\n",
      "Epoch 47/100\n",
      "24520/24544 [============================>.] - ETA: 0s - loss: 0.5576\n",
      "Epoch 47: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.5576 - val_loss: 0.7173\n",
      "Epoch 48/100\n",
      "24532/24544 [============================>.] - ETA: 0s - loss: 0.5554\n",
      "Epoch 48: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5554 - val_loss: 0.7168\n",
      "Epoch 49/100\n",
      "24502/24544 [============================>.] - ETA: 0s - loss: 0.5532\n",
      "Epoch 49: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 971us/step - loss: 0.5533 - val_loss: 0.7155\n",
      "Epoch 50/100\n",
      "24542/24544 [============================>.] - ETA: 0s - loss: 0.5512\n",
      "Epoch 50: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 971us/step - loss: 0.5512 - val_loss: 0.7144\n",
      "Epoch 51/100\n",
      "24523/24544 [============================>.] - ETA: 0s - loss: 0.5493\n",
      "Epoch 51: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5493 - val_loss: 0.7137\n",
      "Epoch 52/100\n",
      "24508/24544 [============================>.] - ETA: 0s - loss: 0.5475\n",
      "Epoch 52: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 970us/step - loss: 0.5475 - val_loss: 0.7132\n",
      "Epoch 53/100\n",
      "24511/24544 [============================>.] - ETA: 0s - loss: 0.5458\n",
      "Epoch 53: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.5458 - val_loss: 0.7123\n",
      "Epoch 54/100\n",
      "24489/24544 [============================>.] - ETA: 0s - loss: 0.5441\n",
      "Epoch 54: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.5441 - val_loss: 0.7115\n",
      "Epoch 55/100\n",
      "24521/24544 [============================>.] - ETA: 0s - loss: 0.5426\n",
      "Epoch 55: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 979us/step - loss: 0.5426 - val_loss: 0.7107\n",
      "Epoch 56/100\n",
      "24489/24544 [============================>.] - ETA: 0s - loss: 0.5411\n",
      "Epoch 56: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5411 - val_loss: 0.7102\n",
      "Epoch 57/100\n",
      "24531/24544 [============================>.] - ETA: 0s - loss: 0.5398\n",
      "Epoch 57: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5398 - val_loss: 0.7098\n",
      "Epoch 58/100\n",
      "24496/24544 [============================>.] - ETA: 0s - loss: 0.5383\n",
      "Epoch 58: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5383 - val_loss: 0.7095\n",
      "Epoch 59/100\n",
      "24493/24544 [============================>.] - ETA: 0s - loss: 0.5370\n",
      "Epoch 59: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 971us/step - loss: 0.5370 - val_loss: 0.7089\n",
      "Epoch 60/100\n",
      "24503/24544 [============================>.] - ETA: 0s - loss: 0.5358\n",
      "Epoch 60: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5358 - val_loss: 0.7084\n",
      "Epoch 61/100\n",
      "24540/24544 [============================>.] - ETA: 0s - loss: 0.5345\n",
      "Epoch 61: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5345 - val_loss: 0.7084\n",
      "Epoch 62/100\n",
      "24488/24544 [============================>.] - ETA: 0s - loss: 0.5334\n",
      "Epoch 62: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5334 - val_loss: 0.7078\n",
      "Epoch 63/100\n",
      "24503/24544 [============================>.] - ETA: 0s - loss: 0.5323\n",
      "Epoch 63: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 978us/step - loss: 0.5323 - val_loss: 0.7079\n",
      "Epoch 64/100\n",
      "24519/24544 [============================>.] - ETA: 0s - loss: 0.5312\n",
      "Epoch 64: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 979us/step - loss: 0.5312 - val_loss: 0.7075\n",
      "Epoch 65/100\n",
      "24519/24544 [============================>.] - ETA: 0s - loss: 0.5303\n",
      "Epoch 65: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.5303 - val_loss: 0.7074\n",
      "Epoch 66/100\n",
      "24508/24544 [============================>.] - ETA: 0s - loss: 0.5292\n",
      "Epoch 66: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5292 - val_loss: 0.7070\n",
      "Epoch 67/100\n",
      "24502/24544 [============================>.] - ETA: 0s - loss: 0.5283\n",
      "Epoch 67: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.5282 - val_loss: 0.7062\n",
      "Epoch 68/100\n",
      "24491/24544 [============================>.] - ETA: 0s - loss: 0.5272\n",
      "Epoch 68: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.5273 - val_loss: 0.7063\n",
      "Epoch 69/100\n",
      "24541/24544 [============================>.] - ETA: 0s - loss: 0.5264\n",
      "Epoch 69: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5264 - val_loss: 0.7062\n",
      "Epoch 70/100\n",
      "24533/24544 [============================>.] - ETA: 0s - loss: 0.5255\n",
      "Epoch 70: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 0.5255 - val_loss: 0.7062\n",
      "Epoch 71/100\n",
      "24544/24544 [==============================] - ETA: 0s - loss: 0.5246\n",
      "Epoch 71: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 982us/step - loss: 0.5246 - val_loss: 0.7062\n",
      "Epoch 72/100\n",
      "24508/24544 [============================>.] - ETA: 0s - loss: 0.5239\n",
      "Epoch 72: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 985us/step - loss: 0.5239 - val_loss: 0.7057\n",
      "Epoch 73/100\n",
      "24494/24544 [============================>.] - ETA: 0s - loss: 0.5230\n",
      "Epoch 73: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5230 - val_loss: 0.7058\n",
      "Epoch 74/100\n",
      "24528/24544 [============================>.] - ETA: 0s - loss: 0.5222\n",
      "Epoch 74: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.5222 - val_loss: 0.7058\n",
      "Epoch 75/100\n",
      "24543/24544 [============================>.] - ETA: 0s - loss: 0.5215\n",
      "Epoch 75: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 0.5215 - val_loss: 0.7054\n",
      "Epoch 76/100\n",
      "24541/24544 [============================>.] - ETA: 0s - loss: 0.5206\n",
      "Epoch 76: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5206 - val_loss: 0.7059\n",
      "Epoch 77/100\n",
      "24519/24544 [============================>.] - ETA: 0s - loss: 0.5200\n",
      "Epoch 77: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.5199 - val_loss: 0.7057\n",
      "Epoch 78/100\n",
      "24498/24544 [============================>.] - ETA: 0s - loss: 0.5192\n",
      "Epoch 78: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5192 - val_loss: 0.7060\n",
      "Epoch 79/100\n",
      "24494/24544 [============================>.] - ETA: 0s - loss: 0.5185\n",
      "Epoch 79: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 972us/step - loss: 0.5185 - val_loss: 0.7059\n",
      "Epoch 80/100\n",
      "24541/24544 [============================>.] - ETA: 0s - loss: 0.5178\n",
      "Epoch 80: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5178 - val_loss: 0.7058\n",
      "Epoch 81/100\n",
      "24538/24544 [============================>.] - ETA: 0s - loss: 0.5172\n",
      "Epoch 81: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5172 - val_loss: 0.7061\n",
      "Epoch 82/100\n",
      "24510/24544 [============================>.] - ETA: 0s - loss: 0.5165\n",
      "Epoch 82: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 973us/step - loss: 0.5165 - val_loss: 0.7063\n",
      "Epoch 83/100\n",
      "24529/24544 [============================>.] - ETA: 0s - loss: 0.5159\n",
      "Epoch 83: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 980us/step - loss: 0.5159 - val_loss: 0.7061\n",
      "Epoch 84/100\n",
      "24487/24544 [============================>.] - ETA: 0s - loss: 0.5152\n",
      "Epoch 84: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5152 - val_loss: 0.7063\n",
      "Epoch 85/100\n",
      "24510/24544 [============================>.] - ETA: 0s - loss: 0.5146\n",
      "Epoch 85: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5146 - val_loss: 0.7063\n",
      "Epoch 86/100\n",
      "24505/24544 [============================>.] - ETA: 0s - loss: 0.5140\n",
      "Epoch 86: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5140 - val_loss: 0.7068\n",
      "Epoch 87/100\n",
      "24540/24544 [============================>.] - ETA: 0s - loss: 0.5133\n",
      "Epoch 87: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.5133 - val_loss: 0.7070\n",
      "Epoch 88/100\n",
      "24505/24544 [============================>.] - ETA: 0s - loss: 0.5128\n",
      "Epoch 88: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 976us/step - loss: 0.5128 - val_loss: 0.7072\n",
      "Epoch 89/100\n",
      "24519/24544 [============================>.] - ETA: 0s - loss: 0.5123\n",
      "Epoch 89: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5123 - val_loss: 0.7073\n",
      "Epoch 90/100\n",
      "24536/24544 [============================>.] - ETA: 0s - loss: 0.5118\n",
      "Epoch 90: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5118 - val_loss: 0.7076\n",
      "Epoch 91/100\n",
      "24510/24544 [============================>.] - ETA: 0s - loss: 0.5112\n",
      "Epoch 91: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 977us/step - loss: 0.5112 - val_loss: 0.7076\n",
      "Epoch 92/100\n",
      "24543/24544 [============================>.] - ETA: 0s - loss: 0.5106\n",
      "Epoch 92: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 978us/step - loss: 0.5106 - val_loss: 0.7078\n",
      "Epoch 93/100\n",
      "24516/24544 [============================>.] - ETA: 0s - loss: 0.5101\n",
      "Epoch 93: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5101 - val_loss: 0.7084\n",
      "Epoch 94/100\n",
      "24499/24544 [============================>.] - ETA: 0s - loss: 0.5096\n",
      "Epoch 94: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.5096 - val_loss: 0.7086\n",
      "Epoch 95/100\n",
      "24525/24544 [============================>.] - ETA: 0s - loss: 0.5092\n",
      "Epoch 95: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5091 - val_loss: 0.7089\n",
      "Epoch 96/100\n",
      "24534/24544 [============================>.] - ETA: 0s - loss: 0.5086\n",
      "Epoch 96: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 980us/step - loss: 0.5086 - val_loss: 0.7089\n",
      "Epoch 97/100\n",
      "24532/24544 [============================>.] - ETA: 0s - loss: 0.5082\n",
      "Epoch 97: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 978us/step - loss: 0.5082 - val_loss: 0.7094\n",
      "Epoch 98/100\n",
      "24535/24544 [============================>.] - ETA: 0s - loss: 0.5077\n",
      "Epoch 98: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 974us/step - loss: 0.5077 - val_loss: 0.7096\n",
      "Epoch 99/100\n",
      "24501/24544 [============================>.] - ETA: 0s - loss: 0.5072\n",
      "Epoch 99: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 975us/step - loss: 0.5073 - val_loss: 0.7098\n",
      "Epoch 100/100\n",
      "24500/24544 [============================>.] - ETA: 0s - loss: 0.5068\n",
      "Epoch 100: val_loss did not improve from 0.70502\n",
      "24544/24544 [==============================] - 24s 981us/step - loss: 0.5068 - val_loss: 0.7101\n",
      "\n",
      "batch_size=64\n",
      "Epoch 1/100\n",
      "12269/12272 [============================>.] - ETA: 0s - loss: 3.8556\n",
      "Epoch 1: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 3.8556 - val_loss: 3.8449\n",
      "Epoch 2/100\n",
      "12233/12272 [============================>.] - ETA: 0s - loss: 3.7761\n",
      "Epoch 2: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 3.7758 - val_loss: 3.6555\n",
      "Epoch 3/100\n",
      "12239/12272 [============================>.] - ETA: 0s - loss: 3.4225\n",
      "Epoch 3: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 3.4219 - val_loss: 3.1771\n",
      "Epoch 4/100\n",
      "12214/12272 [============================>.] - ETA: 0s - loss: 2.8695\n",
      "Epoch 4: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 2.8681 - val_loss: 2.6145\n",
      "Epoch 5/100\n",
      "12227/12272 [============================>.] - ETA: 0s - loss: 2.3255\n",
      "Epoch 5: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 2.3246 - val_loss: 2.1402\n",
      "Epoch 6/100\n",
      "12260/12272 [============================>.] - ETA: 0s - loss: 1.9065\n",
      "Epoch 6: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 1.9064 - val_loss: 1.7993\n",
      "Epoch 7/100\n",
      "12253/12272 [============================>.] - ETA: 0s - loss: 1.6105\n",
      "Epoch 7: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 1.6104 - val_loss: 1.5617\n",
      "Epoch 8/100\n",
      "12233/12272 [============================>.] - ETA: 0s - loss: 1.4024\n",
      "Epoch 8: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 1.4023 - val_loss: 1.3951\n",
      "Epoch 9/100\n",
      "12262/12272 [============================>.] - ETA: 0s - loss: 1.2535\n",
      "Epoch 9: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 951us/step - loss: 1.2535 - val_loss: 1.2751\n",
      "Epoch 10/100\n",
      "12245/12272 [============================>.] - ETA: 0s - loss: 1.1437\n",
      "Epoch 10: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 1.1436 - val_loss: 1.1861\n",
      "Epoch 11/100\n",
      "12221/12272 [============================>.] - ETA: 0s - loss: 1.0598\n",
      "Epoch 11: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 1.0597 - val_loss: 1.1183\n",
      "Epoch 12/100\n",
      "12240/12272 [============================>.] - ETA: 0s - loss: 0.9934\n",
      "Epoch 12: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 0.9934 - val_loss: 1.0646\n",
      "Epoch 13/100\n",
      "12229/12272 [============================>.] - ETA: 0s - loss: 0.9394\n",
      "Epoch 13: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 0.9394 - val_loss: 1.0210\n",
      "Epoch 14/100\n",
      "12234/12272 [============================>.] - ETA: 0s - loss: 0.8945\n",
      "Epoch 14: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 0.8946 - val_loss: 0.9850\n",
      "Epoch 15/100\n",
      "12216/12272 [============================>.] - ETA: 0s - loss: 0.8569\n",
      "Epoch 15: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.8568 - val_loss: 0.9557\n",
      "Epoch 16/100\n",
      "12236/12272 [============================>.] - ETA: 0s - loss: 0.8246\n",
      "Epoch 16: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 0.8247 - val_loss: 0.9299\n",
      "Epoch 17/100\n",
      "12244/12272 [============================>.] - ETA: 0s - loss: 0.7967\n",
      "Epoch 17: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 0.7966 - val_loss: 0.9082\n",
      "Epoch 18/100\n",
      "12222/12272 [============================>.] - ETA: 0s - loss: 0.7721\n",
      "Epoch 18: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.7720 - val_loss: 0.8894\n",
      "Epoch 19/100\n",
      "12216/12272 [============================>.] - ETA: 0s - loss: 0.7505\n",
      "Epoch 19: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.7505 - val_loss: 0.8732\n",
      "Epoch 20/100\n",
      "12229/12272 [============================>.] - ETA: 0s - loss: 0.7313\n",
      "Epoch 20: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 0.7313 - val_loss: 0.8586\n",
      "Epoch 21/100\n",
      "12253/12272 [============================>.] - ETA: 0s - loss: 0.7140\n",
      "Epoch 21: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.7140 - val_loss: 0.8461\n",
      "Epoch 22/100\n",
      "12261/12272 [============================>.] - ETA: 0s - loss: 0.6985\n",
      "Epoch 22: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.6985 - val_loss: 0.8348\n",
      "Epoch 23/100\n",
      "12261/12272 [============================>.] - ETA: 0s - loss: 0.6845\n",
      "Epoch 23: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.6845 - val_loss: 0.8250\n",
      "Epoch 24/100\n",
      "12234/12272 [============================>.] - ETA: 0s - loss: 0.6718\n",
      "Epoch 24: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.6718 - val_loss: 0.8160\n",
      "Epoch 25/100\n",
      "12272/12272 [==============================] - ETA: 0s - loss: 0.6601\n",
      "Epoch 25: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.6601 - val_loss: 0.8079\n",
      "Epoch 26/100\n",
      "12222/12272 [============================>.] - ETA: 0s - loss: 0.6495\n",
      "Epoch 26: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.6495 - val_loss: 0.8009\n",
      "Epoch 27/100\n",
      "12225/12272 [============================>.] - ETA: 0s - loss: 0.6397\n",
      "Epoch 27: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.6397 - val_loss: 0.7945\n",
      "Epoch 28/100\n",
      "12214/12272 [============================>.] - ETA: 0s - loss: 0.6307\n",
      "Epoch 28: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.6307 - val_loss: 0.7889\n",
      "Epoch 29/100\n",
      "12213/12272 [============================>.] - ETA: 0s - loss: 0.6224\n",
      "Epoch 29: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.6224 - val_loss: 0.7835\n",
      "Epoch 30/100\n",
      "12259/12272 [============================>.] - ETA: 0s - loss: 0.6148\n",
      "Epoch 30: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.6148 - val_loss: 0.7784\n",
      "Epoch 31/100\n",
      "12213/12272 [============================>.] - ETA: 0s - loss: 0.6075\n",
      "Epoch 31: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.6076 - val_loss: 0.7744\n",
      "Epoch 32/100\n",
      "12255/12272 [============================>.] - ETA: 0s - loss: 0.6010\n",
      "Epoch 32: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.6010 - val_loss: 0.7705\n",
      "Epoch 33/100\n",
      "12242/12272 [============================>.] - ETA: 0s - loss: 0.5947\n",
      "Epoch 33: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5947 - val_loss: 0.7672\n",
      "Epoch 34/100\n",
      "12255/12272 [============================>.] - ETA: 0s - loss: 0.5891\n",
      "Epoch 34: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5890 - val_loss: 0.7637\n",
      "Epoch 35/100\n",
      "12217/12272 [============================>.] - ETA: 0s - loss: 0.5835\n",
      "Epoch 35: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.5835 - val_loss: 0.7609\n",
      "Epoch 36/100\n",
      "12248/12272 [============================>.] - ETA: 0s - loss: 0.5783\n",
      "Epoch 36: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5783 - val_loss: 0.7583\n",
      "Epoch 37/100\n",
      "12231/12272 [============================>.] - ETA: 0s - loss: 0.5738\n",
      "Epoch 37: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.5737 - val_loss: 0.7557\n",
      "Epoch 38/100\n",
      "12228/12272 [============================>.] - ETA: 0s - loss: 0.5692\n",
      "Epoch 38: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 0.5691 - val_loss: 0.7533\n",
      "Epoch 39/100\n",
      "12238/12272 [============================>.] - ETA: 0s - loss: 0.5649\n",
      "Epoch 39: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5650 - val_loss: 0.7512\n",
      "Epoch 40/100\n",
      "12226/12272 [============================>.] - ETA: 0s - loss: 0.5609\n",
      "Epoch 40: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.5610 - val_loss: 0.7492\n",
      "Epoch 41/100\n",
      "12232/12272 [============================>.] - ETA: 0s - loss: 0.5572\n",
      "Epoch 41: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 0.5572 - val_loss: 0.7478\n",
      "Epoch 42/100\n",
      "12261/12272 [============================>.] - ETA: 0s - loss: 0.5537\n",
      "Epoch 42: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.5537 - val_loss: 0.7459\n",
      "Epoch 43/100\n",
      "12229/12272 [============================>.] - ETA: 0s - loss: 0.5502\n",
      "Epoch 43: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5503 - val_loss: 0.7441\n",
      "Epoch 44/100\n",
      "12260/12272 [============================>.] - ETA: 0s - loss: 0.5471\n",
      "Epoch 44: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.5471 - val_loss: 0.7431\n",
      "Epoch 45/100\n",
      "12247/12272 [============================>.] - ETA: 0s - loss: 0.5440\n",
      "Epoch 45: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 952us/step - loss: 0.5440 - val_loss: 0.7419\n",
      "Epoch 46/100\n",
      "12271/12272 [============================>.] - ETA: 0s - loss: 0.5412\n",
      "Epoch 46: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.5412 - val_loss: 0.7406\n",
      "Epoch 47/100\n",
      "12268/12272 [============================>.] - ETA: 0s - loss: 0.5385\n",
      "Epoch 47: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.5385 - val_loss: 0.7396\n",
      "Epoch 48/100\n",
      "12267/12272 [============================>.] - ETA: 0s - loss: 0.5359\n",
      "Epoch 48: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.5359 - val_loss: 0.7384\n",
      "Epoch 49/100\n",
      "12253/12272 [============================>.] - ETA: 0s - loss: 0.5333\n",
      "Epoch 49: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.5334 - val_loss: 0.7377\n",
      "Epoch 50/100\n",
      "12242/12272 [============================>.] - ETA: 0s - loss: 0.5311\n",
      "Epoch 50: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5312 - val_loss: 0.7366\n",
      "Epoch 51/100\n",
      "12234/12272 [============================>.] - ETA: 0s - loss: 0.5288\n",
      "Epoch 51: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5288 - val_loss: 0.7361\n",
      "Epoch 52/100\n",
      "12243/12272 [============================>.] - ETA: 0s - loss: 0.5267\n",
      "Epoch 52: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5268 - val_loss: 0.7354\n",
      "Epoch 53/100\n",
      "12222/12272 [============================>.] - ETA: 0s - loss: 0.5247\n",
      "Epoch 53: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 954us/step - loss: 0.5247 - val_loss: 0.7351\n",
      "Epoch 54/100\n",
      "12231/12272 [============================>.] - ETA: 0s - loss: 0.5227\n",
      "Epoch 54: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 953us/step - loss: 0.5228 - val_loss: 0.7345\n",
      "Epoch 55/100\n",
      "12242/12272 [============================>.] - ETA: 0s - loss: 0.5210\n",
      "Epoch 55: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5209 - val_loss: 0.7338\n",
      "Epoch 56/100\n",
      "12252/12272 [============================>.] - ETA: 0s - loss: 0.5192\n",
      "Epoch 56: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.5192 - val_loss: 0.7335\n",
      "Epoch 57/100\n",
      "12236/12272 [============================>.] - ETA: 0s - loss: 0.5174\n",
      "Epoch 57: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5174 - val_loss: 0.7333\n",
      "Epoch 58/100\n",
      "12246/12272 [============================>.] - ETA: 0s - loss: 0.5159\n",
      "Epoch 58: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5159 - val_loss: 0.7327\n",
      "Epoch 59/100\n",
      "12229/12272 [============================>.] - ETA: 0s - loss: 0.5142\n",
      "Epoch 59: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5142 - val_loss: 0.7323\n",
      "Epoch 60/100\n",
      "12218/12272 [============================>.] - ETA: 0s - loss: 0.5128\n",
      "Epoch 60: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5128 - val_loss: 0.7323\n",
      "Epoch 61/100\n",
      "12255/12272 [============================>.] - ETA: 0s - loss: 0.5113\n",
      "Epoch 61: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.5113 - val_loss: 0.7321\n",
      "Epoch 62/100\n",
      "12240/12272 [============================>.] - ETA: 0s - loss: 0.5099\n",
      "Epoch 62: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5099 - val_loss: 0.7316\n",
      "Epoch 63/100\n",
      "12241/12272 [============================>.] - ETA: 0s - loss: 0.5085\n",
      "Epoch 63: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5086 - val_loss: 0.7319\n",
      "Epoch 64/100\n",
      "12258/12272 [============================>.] - ETA: 0s - loss: 0.5073\n",
      "Epoch 64: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5073 - val_loss: 0.7311\n",
      "Epoch 65/100\n",
      "12260/12272 [============================>.] - ETA: 0s - loss: 0.5060\n",
      "Epoch 65: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.5060 - val_loss: 0.7312\n",
      "Epoch 66/100\n",
      "12269/12272 [============================>.] - ETA: 0s - loss: 0.5048\n",
      "Epoch 66: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.5048 - val_loss: 0.7312\n",
      "Epoch 67/100\n",
      "12246/12272 [============================>.] - ETA: 0s - loss: 0.5036\n",
      "Epoch 67: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5036 - val_loss: 0.7311\n",
      "Epoch 68/100\n",
      "12247/12272 [============================>.] - ETA: 0s - loss: 0.5026\n",
      "Epoch 68: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5026 - val_loss: 0.7307\n",
      "Epoch 69/100\n",
      "12253/12272 [============================>.] - ETA: 0s - loss: 0.5014\n",
      "Epoch 69: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.5014 - val_loss: 0.7310\n",
      "Epoch 70/100\n",
      "12217/12272 [============================>.] - ETA: 0s - loss: 0.5002\n",
      "Epoch 70: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.5003 - val_loss: 0.7307\n",
      "Epoch 71/100\n",
      "12230/12272 [============================>.] - ETA: 0s - loss: 0.4993\n",
      "Epoch 71: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4993 - val_loss: 0.7308\n",
      "Epoch 72/100\n",
      "12263/12272 [============================>.] - ETA: 0s - loss: 0.4982\n",
      "Epoch 72: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 960us/step - loss: 0.4982 - val_loss: 0.7309\n",
      "Epoch 73/100\n",
      "12245/12272 [============================>.] - ETA: 0s - loss: 0.4973\n",
      "Epoch 73: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.4973 - val_loss: 0.7309\n",
      "Epoch 74/100\n",
      "12269/12272 [============================>.] - ETA: 0s - loss: 0.4962\n",
      "Epoch 74: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 958us/step - loss: 0.4962 - val_loss: 0.7310\n",
      "Epoch 75/100\n",
      "12236/12272 [============================>.] - ETA: 0s - loss: 0.4952\n",
      "Epoch 75: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 961us/step - loss: 0.4952 - val_loss: 0.7311\n",
      "Epoch 76/100\n",
      "12228/12272 [============================>.] - ETA: 0s - loss: 0.4943\n",
      "Epoch 76: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4944 - val_loss: 0.7311\n",
      "Epoch 77/100\n",
      "12266/12272 [============================>.] - ETA: 0s - loss: 0.4934\n",
      "Epoch 77: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 959us/step - loss: 0.4934 - val_loss: 0.7312\n",
      "Epoch 78/100\n",
      "12263/12272 [============================>.] - ETA: 0s - loss: 0.4926\n",
      "Epoch 78: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 958us/step - loss: 0.4926 - val_loss: 0.7311\n",
      "Epoch 79/100\n",
      "12263/12272 [============================>.] - ETA: 0s - loss: 0.4918\n",
      "Epoch 79: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 960us/step - loss: 0.4918 - val_loss: 0.7312\n",
      "Epoch 80/100\n",
      "12255/12272 [============================>.] - ETA: 0s - loss: 0.4909\n",
      "Epoch 80: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4909 - val_loss: 0.7314\n",
      "Epoch 81/100\n",
      "12221/12272 [============================>.] - ETA: 0s - loss: 0.4900\n",
      "Epoch 81: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4901 - val_loss: 0.7318\n",
      "Epoch 82/100\n",
      "12247/12272 [============================>.] - ETA: 0s - loss: 0.4893\n",
      "Epoch 82: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4893 - val_loss: 0.7317\n",
      "Epoch 83/100\n",
      "12227/12272 [============================>.] - ETA: 0s - loss: 0.4887\n",
      "Epoch 83: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 958us/step - loss: 0.4887 - val_loss: 0.7321\n",
      "Epoch 84/100\n",
      "12237/12272 [============================>.] - ETA: 0s - loss: 0.4878\n",
      "Epoch 84: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4878 - val_loss: 0.7321\n",
      "Epoch 85/100\n",
      "12217/12272 [============================>.] - ETA: 0s - loss: 0.4871\n",
      "Epoch 85: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 958us/step - loss: 0.4871 - val_loss: 0.7324\n",
      "Epoch 86/100\n",
      "12225/12272 [============================>.] - ETA: 0s - loss: 0.4864\n",
      "Epoch 86: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 958us/step - loss: 0.4864 - val_loss: 0.7325\n",
      "Epoch 87/100\n",
      "12249/12272 [============================>.] - ETA: 0s - loss: 0.4857\n",
      "Epoch 87: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4857 - val_loss: 0.7326\n",
      "Epoch 88/100\n",
      "12258/12272 [============================>.] - ETA: 0s - loss: 0.4850\n",
      "Epoch 88: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 960us/step - loss: 0.4850 - val_loss: 0.7331\n",
      "Epoch 89/100\n",
      "12264/12272 [============================>.] - ETA: 0s - loss: 0.4844\n",
      "Epoch 89: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 955us/step - loss: 0.4844 - val_loss: 0.7329\n",
      "Epoch 90/100\n",
      "12227/12272 [============================>.] - ETA: 0s - loss: 0.4838\n",
      "Epoch 90: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4837 - val_loss: 0.7334\n",
      "Epoch 91/100\n",
      "12264/12272 [============================>.] - ETA: 0s - loss: 0.4831\n",
      "Epoch 91: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.4831 - val_loss: 0.7335\n",
      "Epoch 92/100\n",
      "12269/12272 [============================>.] - ETA: 0s - loss: 0.4825\n",
      "Epoch 92: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 959us/step - loss: 0.4825 - val_loss: 0.7340\n",
      "Epoch 93/100\n",
      "12242/12272 [============================>.] - ETA: 0s - loss: 0.4819\n",
      "Epoch 93: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.4819 - val_loss: 0.7340\n",
      "Epoch 94/100\n",
      "12229/12272 [============================>.] - ETA: 0s - loss: 0.4813\n",
      "Epoch 94: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.4813 - val_loss: 0.7342\n",
      "Epoch 95/100\n",
      "12267/12272 [============================>.] - ETA: 0s - loss: 0.4808\n",
      "Epoch 95: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 959us/step - loss: 0.4808 - val_loss: 0.7346\n",
      "Epoch 96/100\n",
      "12229/12272 [============================>.] - ETA: 0s - loss: 0.4802\n",
      "Epoch 96: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 958us/step - loss: 0.4802 - val_loss: 0.7346\n",
      "Epoch 97/100\n",
      "12238/12272 [============================>.] - ETA: 0s - loss: 0.4797\n",
      "Epoch 97: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4797 - val_loss: 0.7353\n",
      "Epoch 98/100\n",
      "12246/12272 [============================>.] - ETA: 0s - loss: 0.4791\n",
      "Epoch 98: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 956us/step - loss: 0.4791 - val_loss: 0.7355\n",
      "Epoch 99/100\n",
      "12229/12272 [============================>.] - ETA: 0s - loss: 0.4786\n",
      "Epoch 99: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 957us/step - loss: 0.4786 - val_loss: 0.7357\n",
      "Epoch 100/100\n",
      "12263/12272 [============================>.] - ETA: 0s - loss: 0.4782\n",
      "Epoch 100: val_loss did not improve from 0.70502\n",
      "12272/12272 [==============================] - 12s 960us/step - loss: 0.4782 - val_loss: 0.7362\n",
      "\n",
      "batch_size=128\n",
      "Epoch 1/100\n",
      "6085/6136 [============================>.] - ETA: 0s - loss: 3.8558\n",
      "Epoch 1: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 1ms/step - loss: 3.8557 - val_loss: 3.8459\n",
      "Epoch 2/100\n",
      "6114/6136 [============================>.] - ETA: 0s - loss: 3.7815\n",
      "Epoch 2: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 3.7811 - val_loss: 3.6645\n",
      "Epoch 3/100\n",
      "6132/6136 [============================>.] - ETA: 0s - loss: 3.4307\n",
      "Epoch 3: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 986us/step - loss: 3.4305 - val_loss: 3.1814\n",
      "Epoch 4/100\n",
      "6124/6136 [============================>.] - ETA: 0s - loss: 2.8723\n",
      "Epoch 4: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 2.8718 - val_loss: 2.6149\n",
      "Epoch 5/100\n",
      "6125/6136 [============================>.] - ETA: 0s - loss: 2.3233\n",
      "Epoch 5: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 2.3228 - val_loss: 2.1330\n",
      "Epoch 6/100\n",
      "6121/6136 [============================>.] - ETA: 0s - loss: 1.8986\n",
      "Epoch 6: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 1.8981 - val_loss: 1.7872\n",
      "Epoch 7/100\n",
      "6136/6136 [==============================] - ETA: 0s - loss: 1.6012\n",
      "Epoch 7: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 993us/step - loss: 1.6012 - val_loss: 1.5506\n",
      "Epoch 8/100\n",
      "6099/6136 [============================>.] - ETA: 0s - loss: 1.3958\n",
      "Epoch 8: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 1.3954 - val_loss: 1.3854\n",
      "Epoch 9/100\n",
      "6122/6136 [============================>.] - ETA: 0s - loss: 1.2488\n",
      "Epoch 9: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 1.2488 - val_loss: 1.2672\n",
      "Epoch 10/100\n",
      "6111/6136 [============================>.] - ETA: 0s - loss: 1.1413\n",
      "Epoch 10: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 1.1412 - val_loss: 1.1791\n",
      "Epoch 11/100\n",
      "6100/6136 [============================>.] - ETA: 0s - loss: 1.0589\n",
      "Epoch 11: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 1.0588 - val_loss: 1.1116\n",
      "Epoch 12/100\n",
      "6134/6136 [============================>.] - ETA: 0s - loss: 0.9937\n",
      "Epoch 12: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 985us/step - loss: 0.9937 - val_loss: 1.0581\n",
      "Epoch 13/100\n",
      "6110/6136 [============================>.] - ETA: 0s - loss: 0.9408\n",
      "Epoch 13: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.9407 - val_loss: 1.0155\n",
      "Epoch 14/100\n",
      "6104/6136 [============================>.] - ETA: 0s - loss: 0.8968\n",
      "Epoch 14: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 994us/step - loss: 0.8968 - val_loss: 0.9799\n",
      "Epoch 15/100\n",
      "6116/6136 [============================>.] - ETA: 0s - loss: 0.8597\n",
      "Epoch 15: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 1ms/step - loss: 0.8598 - val_loss: 0.9501\n",
      "Epoch 16/100\n",
      "6103/6136 [============================>.] - ETA: 0s - loss: 0.8284\n",
      "Epoch 16: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.8283 - val_loss: 0.9244\n",
      "Epoch 17/100\n",
      "6128/6136 [============================>.] - ETA: 0s - loss: 0.8009\n",
      "Epoch 17: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 0.8009 - val_loss: 0.9029\n",
      "Epoch 18/100\n",
      "6110/6136 [============================>.] - ETA: 0s - loss: 0.7770\n",
      "Epoch 18: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.7770 - val_loss: 0.8839\n",
      "Epoch 19/100\n",
      "6108/6136 [============================>.] - ETA: 0s - loss: 0.7559\n",
      "Epoch 19: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 993us/step - loss: 0.7558 - val_loss: 0.8671\n",
      "Epoch 20/100\n",
      "6088/6136 [============================>.] - ETA: 0s - loss: 0.7371\n",
      "Epoch 20: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 992us/step - loss: 0.7370 - val_loss: 0.8522\n",
      "Epoch 21/100\n",
      "6117/6136 [============================>.] - ETA: 0s - loss: 0.7201\n",
      "Epoch 21: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 0.7202 - val_loss: 0.8396\n",
      "Epoch 22/100\n",
      "6089/6136 [============================>.] - ETA: 0s - loss: 0.7050\n",
      "Epoch 22: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.7051 - val_loss: 0.8279\n",
      "Epoch 23/100\n",
      "6085/6136 [============================>.] - ETA: 0s - loss: 0.6912\n",
      "Epoch 23: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 993us/step - loss: 0.6913 - val_loss: 0.8174\n",
      "Epoch 24/100\n",
      "6096/6136 [============================>.] - ETA: 0s - loss: 0.6788\n",
      "Epoch 24: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.6788 - val_loss: 0.8081\n",
      "Epoch 25/100\n",
      "6101/6136 [============================>.] - ETA: 0s - loss: 0.6675\n",
      "Epoch 25: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.6675 - val_loss: 0.7999\n",
      "Epoch 26/100\n",
      "6078/6136 [============================>.] - ETA: 0s - loss: 0.6570\n",
      "Epoch 26: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 984us/step - loss: 0.6570 - val_loss: 0.7927\n",
      "Epoch 27/100\n",
      "6101/6136 [============================>.] - ETA: 0s - loss: 0.6474\n",
      "Epoch 27: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.6474 - val_loss: 0.7857\n",
      "Epoch 28/100\n",
      "6097/6136 [============================>.] - ETA: 0s - loss: 0.6386\n",
      "Epoch 28: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.6387 - val_loss: 0.7796\n",
      "Epoch 29/100\n",
      "6135/6136 [============================>.] - ETA: 0s - loss: 0.6306\n",
      "Epoch 29: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 986us/step - loss: 0.6306 - val_loss: 0.7738\n",
      "Epoch 30/100\n",
      "6100/6136 [============================>.] - ETA: 0s - loss: 0.6230\n",
      "Epoch 30: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.6231 - val_loss: 0.7686\n",
      "Epoch 31/100\n",
      "6108/6136 [============================>.] - ETA: 0s - loss: 0.6161\n",
      "Epoch 31: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.6161 - val_loss: 0.7639\n",
      "Epoch 32/100\n",
      "6125/6136 [============================>.] - ETA: 0s - loss: 0.6097\n",
      "Epoch 32: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 0.6097 - val_loss: 0.7598\n",
      "Epoch 33/100\n",
      "6104/6136 [============================>.] - ETA: 0s - loss: 0.6036\n",
      "Epoch 33: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.6036 - val_loss: 0.7560\n",
      "Epoch 34/100\n",
      "6122/6136 [============================>.] - ETA: 0s - loss: 0.5980\n",
      "Epoch 34: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 0.5980 - val_loss: 0.7525\n",
      "Epoch 35/100\n",
      "6116/6136 [============================>.] - ETA: 0s - loss: 0.5927\n",
      "Epoch 35: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 0.5927 - val_loss: 0.7492\n",
      "Epoch 36/100\n",
      "6122/6136 [============================>.] - ETA: 0s - loss: 0.5877\n",
      "Epoch 36: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 995us/step - loss: 0.5878 - val_loss: 0.7457\n",
      "Epoch 37/100\n",
      "6111/6136 [============================>.] - ETA: 0s - loss: 0.5831\n",
      "Epoch 37: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5832 - val_loss: 0.7432\n",
      "Epoch 38/100\n",
      "6122/6136 [============================>.] - ETA: 0s - loss: 0.5788\n",
      "Epoch 38: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 996us/step - loss: 0.5788 - val_loss: 0.7402\n",
      "Epoch 39/100\n",
      "6110/6136 [============================>.] - ETA: 0s - loss: 0.5747\n",
      "Epoch 39: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.5748 - val_loss: 0.7377\n",
      "Epoch 40/100\n",
      "6114/6136 [============================>.] - ETA: 0s - loss: 0.5709\n",
      "Epoch 40: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 0.5709 - val_loss: 0.7355\n",
      "Epoch 41/100\n",
      "6128/6136 [============================>.] - ETA: 0s - loss: 0.5672\n",
      "Epoch 41: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 994us/step - loss: 0.5673 - val_loss: 0.7335\n",
      "Epoch 42/100\n",
      "6112/6136 [============================>.] - ETA: 0s - loss: 0.5639\n",
      "Epoch 42: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5639 - val_loss: 0.7321\n",
      "Epoch 43/100\n",
      "6124/6136 [============================>.] - ETA: 0s - loss: 0.5606\n",
      "Epoch 43: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 995us/step - loss: 0.5606 - val_loss: 0.7299\n",
      "Epoch 44/100\n",
      "6086/6136 [============================>.] - ETA: 0s - loss: 0.5575\n",
      "Epoch 44: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 993us/step - loss: 0.5576 - val_loss: 0.7283\n",
      "Epoch 45/100\n",
      "6126/6136 [============================>.] - ETA: 0s - loss: 0.5548\n",
      "Epoch 45: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 996us/step - loss: 0.5548 - val_loss: 0.7268\n",
      "Epoch 46/100\n",
      "6103/6136 [============================>.] - ETA: 0s - loss: 0.5518\n",
      "Epoch 46: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.5519 - val_loss: 0.7255\n",
      "Epoch 47/100\n",
      "6124/6136 [============================>.] - ETA: 0s - loss: 0.5493\n",
      "Epoch 47: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 0.5494 - val_loss: 0.7244\n",
      "Epoch 48/100\n",
      "6120/6136 [============================>.] - ETA: 0s - loss: 0.5469\n",
      "Epoch 48: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 0.5469 - val_loss: 0.7231\n",
      "Epoch 49/100\n",
      "6123/6136 [============================>.] - ETA: 0s - loss: 0.5445\n",
      "Epoch 49: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 995us/step - loss: 0.5445 - val_loss: 0.7218\n",
      "Epoch 50/100\n",
      "6098/6136 [============================>.] - ETA: 0s - loss: 0.5423\n",
      "Epoch 50: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.5423 - val_loss: 0.7210\n",
      "Epoch 51/100\n",
      "6104/6136 [============================>.] - ETA: 0s - loss: 0.5401\n",
      "Epoch 51: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 999us/step - loss: 0.5402 - val_loss: 0.7200\n",
      "Epoch 52/100\n",
      "6081/6136 [============================>.] - ETA: 0s - loss: 0.5381\n",
      "Epoch 52: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 992us/step - loss: 0.5382 - val_loss: 0.7196\n",
      "Epoch 53/100\n",
      "6100/6136 [============================>.] - ETA: 0s - loss: 0.5361\n",
      "Epoch 53: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5362 - val_loss: 0.7186\n",
      "Epoch 54/100\n",
      "6111/6136 [============================>.] - ETA: 0s - loss: 0.5342\n",
      "Epoch 54: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5343 - val_loss: 0.7182\n",
      "Epoch 55/100\n",
      "6120/6136 [============================>.] - ETA: 0s - loss: 0.5326\n",
      "Epoch 55: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 0.5326 - val_loss: 0.7170\n",
      "Epoch 56/100\n",
      "6087/6136 [============================>.] - ETA: 0s - loss: 0.5308\n",
      "Epoch 56: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.5308 - val_loss: 0.7164\n",
      "Epoch 57/100\n",
      "6118/6136 [============================>.] - ETA: 0s - loss: 0.5293\n",
      "Epoch 57: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 998us/step - loss: 0.5293 - val_loss: 0.7159\n",
      "Epoch 58/100\n",
      "6130/6136 [============================>.] - ETA: 0s - loss: 0.5278\n",
      "Epoch 58: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 994us/step - loss: 0.5278 - val_loss: 0.7157\n",
      "Epoch 59/100\n",
      "6131/6136 [============================>.] - ETA: 0s - loss: 0.5263\n",
      "Epoch 59: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 0.5263 - val_loss: 0.7151\n",
      "Epoch 60/100\n",
      "6116/6136 [============================>.] - ETA: 0s - loss: 0.5248\n",
      "Epoch 60: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 988us/step - loss: 0.5248 - val_loss: 0.7149\n",
      "Epoch 61/100\n",
      "6113/6136 [============================>.] - ETA: 0s - loss: 0.5233\n",
      "Epoch 61: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5234 - val_loss: 0.7143\n",
      "Epoch 62/100\n",
      "6107/6136 [============================>.] - ETA: 0s - loss: 0.5221\n",
      "Epoch 62: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.5222 - val_loss: 0.7139\n",
      "Epoch 63/100\n",
      "6110/6136 [============================>.] - ETA: 0s - loss: 0.5210\n",
      "Epoch 63: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5209 - val_loss: 0.7139\n",
      "Epoch 64/100\n",
      "6135/6136 [============================>.] - ETA: 0s - loss: 0.5197\n",
      "Epoch 64: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 986us/step - loss: 0.5197 - val_loss: 0.7133\n",
      "Epoch 65/100\n",
      "6082/6136 [============================>.] - ETA: 0s - loss: 0.5185\n",
      "Epoch 65: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 986us/step - loss: 0.5186 - val_loss: 0.7128\n",
      "Epoch 66/100\n",
      "6124/6136 [============================>.] - ETA: 0s - loss: 0.5173\n",
      "Epoch 66: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 0.5173 - val_loss: 0.7126\n",
      "Epoch 67/100\n",
      "6125/6136 [============================>.] - ETA: 0s - loss: 0.5162\n",
      "Epoch 67: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 987us/step - loss: 0.5162 - val_loss: 0.7124\n",
      "Epoch 68/100\n",
      "6106/6136 [============================>.] - ETA: 0s - loss: 0.5151\n",
      "Epoch 68: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5151 - val_loss: 0.7124\n",
      "Epoch 69/100\n",
      "6117/6136 [============================>.] - ETA: 0s - loss: 0.5142\n",
      "Epoch 69: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.5141 - val_loss: 0.7120\n",
      "Epoch 70/100\n",
      "6092/6136 [============================>.] - ETA: 0s - loss: 0.5130\n",
      "Epoch 70: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.5131 - val_loss: 0.7119\n",
      "Epoch 71/100\n",
      "6104/6136 [============================>.] - ETA: 0s - loss: 0.5121\n",
      "Epoch 71: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.5122 - val_loss: 0.7117\n",
      "Epoch 72/100\n",
      "6108/6136 [============================>.] - ETA: 0s - loss: 0.5111\n",
      "Epoch 72: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 989us/step - loss: 0.5111 - val_loss: 0.7117\n",
      "Epoch 73/100\n",
      "6094/6136 [============================>.] - ETA: 0s - loss: 0.5101\n",
      "Epoch 73: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 992us/step - loss: 0.5102 - val_loss: 0.7115\n",
      "Epoch 74/100\n",
      "6131/6136 [============================>.] - ETA: 0s - loss: 0.5093\n",
      "Epoch 74: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 994us/step - loss: 0.5093 - val_loss: 0.7116\n",
      "Epoch 75/100\n",
      "6116/6136 [============================>.] - ETA: 0s - loss: 0.5084\n",
      "Epoch 75: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 996us/step - loss: 0.5084 - val_loss: 0.7115\n",
      "Epoch 76/100\n",
      "6116/6136 [============================>.] - ETA: 0s - loss: 0.5074\n",
      "Epoch 76: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 997us/step - loss: 0.5074 - val_loss: 0.7117\n",
      "Epoch 77/100\n",
      "6080/6136 [============================>.] - ETA: 0s - loss: 0.5066\n",
      "Epoch 77: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 992us/step - loss: 0.5066 - val_loss: 0.7114\n",
      "Epoch 78/100\n",
      "6127/6136 [============================>.] - ETA: 0s - loss: 0.5058\n",
      "Epoch 78: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 995us/step - loss: 0.5058 - val_loss: 0.7114\n",
      "Epoch 79/100\n",
      "6133/6136 [============================>.] - ETA: 0s - loss: 0.5050\n",
      "Epoch 79: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 995us/step - loss: 0.5050 - val_loss: 0.7116\n",
      "Epoch 80/100\n",
      "6124/6136 [============================>.] - ETA: 0s - loss: 0.5042\n",
      "Epoch 80: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 995us/step - loss: 0.5042 - val_loss: 0.7113\n",
      "Epoch 81/100\n",
      "6128/6136 [============================>.] - ETA: 0s - loss: 0.5034\n",
      "Epoch 81: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 994us/step - loss: 0.5034 - val_loss: 0.7114\n",
      "Epoch 82/100\n",
      "6112/6136 [============================>.] - ETA: 0s - loss: 0.5027\n",
      "Epoch 82: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 997us/step - loss: 0.5027 - val_loss: 0.7115\n",
      "Epoch 83/100\n",
      "6085/6136 [============================>.] - ETA: 0s - loss: 0.5019\n",
      "Epoch 83: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.5019 - val_loss: 0.7119\n",
      "Epoch 84/100\n",
      "6126/6136 [============================>.] - ETA: 0s - loss: 0.5013\n",
      "Epoch 84: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 996us/step - loss: 0.5013 - val_loss: 0.7114\n",
      "Epoch 85/100\n",
      "6086/6136 [============================>.] - ETA: 0s - loss: 0.5005\n",
      "Epoch 85: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 993us/step - loss: 0.5005 - val_loss: 0.7114\n",
      "Epoch 86/100\n",
      "6124/6136 [============================>.] - ETA: 0s - loss: 0.4998\n",
      "Epoch 86: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 995us/step - loss: 0.4998 - val_loss: 0.7117\n",
      "Epoch 87/100\n",
      "6100/6136 [============================>.] - ETA: 0s - loss: 0.4992\n",
      "Epoch 87: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 999us/step - loss: 0.4991 - val_loss: 0.7119\n",
      "Epoch 88/100\n",
      "6104/6136 [============================>.] - ETA: 0s - loss: 0.4982\n",
      "Epoch 88: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 998us/step - loss: 0.4983 - val_loss: 0.7122\n",
      "Epoch 89/100\n",
      "6085/6136 [============================>.] - ETA: 0s - loss: 0.4979\n",
      "Epoch 89: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 1ms/step - loss: 0.4979 - val_loss: 0.7120\n",
      "Epoch 90/100\n",
      "6111/6136 [============================>.] - ETA: 0s - loss: 0.4971\n",
      "Epoch 90: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 997us/step - loss: 0.4972 - val_loss: 0.7128\n",
      "Epoch 91/100\n",
      "6123/6136 [============================>.] - ETA: 0s - loss: 0.4966\n",
      "Epoch 91: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 996us/step - loss: 0.4966 - val_loss: 0.7126\n",
      "Epoch 92/100\n",
      "6081/6136 [============================>.] - ETA: 0s - loss: 0.4959\n",
      "Epoch 92: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 993us/step - loss: 0.4960 - val_loss: 0.7129\n",
      "Epoch 93/100\n",
      "6093/6136 [============================>.] - ETA: 0s - loss: 0.4954\n",
      "Epoch 93: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 1000us/step - loss: 0.4954 - val_loss: 0.7130\n",
      "Epoch 94/100\n",
      "6098/6136 [============================>.] - ETA: 0s - loss: 0.4948\n",
      "Epoch 94: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.4948 - val_loss: 0.7129\n",
      "Epoch 95/100\n",
      "6110/6136 [============================>.] - ETA: 0s - loss: 0.4942\n",
      "Epoch 95: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 990us/step - loss: 0.4942 - val_loss: 0.7133\n",
      "Epoch 96/100\n",
      "6095/6136 [============================>.] - ETA: 0s - loss: 0.4936\n",
      "Epoch 96: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.4937 - val_loss: 0.7138\n",
      "Epoch 97/100\n",
      "6133/6136 [============================>.] - ETA: 0s - loss: 0.4931\n",
      "Epoch 97: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 986us/step - loss: 0.4931 - val_loss: 0.7137\n",
      "Epoch 98/100\n",
      "6102/6136 [============================>.] - ETA: 0s - loss: 0.4925\n",
      "Epoch 98: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.4926 - val_loss: 0.7138\n",
      "Epoch 99/100\n",
      "6100/6136 [============================>.] - ETA: 0s - loss: 0.4920\n",
      "Epoch 99: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 992us/step - loss: 0.4921 - val_loss: 0.7140\n",
      "Epoch 100/100\n",
      "6100/6136 [============================>.] - ETA: 0s - loss: 0.4916\n",
      "Epoch 100: val_loss did not improve from 0.70502\n",
      "6136/6136 [==============================] - 6s 991us/step - loss: 0.4917 - val_loss: 0.7146\n",
      "\n",
      "\n",
      "\n",
      "optimizer=SGD()\n",
      "batch_size=8\n",
      "Epoch 1/100\n",
      "98167/98176 [============================>.] - ETA: 0s - loss: 3.8570\n",
      "Epoch 1: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 66s 672us/step - loss: 3.8570 - val_loss: 3.8545\n",
      "Epoch 2/100\n",
      "98142/98176 [============================>.] - ETA: 0s - loss: 3.8571\n",
      "Epoch 2: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 65s 664us/step - loss: 3.8570 - val_loss: 3.8545\n",
      "Epoch 3/100\n",
      "98139/98176 [============================>.] - ETA: 0s - loss: 3.8570\n",
      "Epoch 3: val_loss did not improve from 0.70502\n",
      "98176/98176 [==============================] - 65s 664us/step - loss: 3.8570 - val_loss: 3.8545\n",
      "Epoch 4/100\n",
      "98140/98176 [============================>.] - ETA: 0s - loss: 3.8570"
     ]
    }
   ],
   "source": [
    "model.compile(loss=MeanAbsoluteError(), optimizer=Adam())\n",
    "print('loss function=MeanAbsoluteError()')\n",
    "print('optimizer=Adam()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss=MeanAbsoluteError(), optimizer=RMSprop())\n",
    "print('optimizer=RMSprop()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss=MeanAbsoluteError(), optimizer=SGD())\n",
    "print('optimizer=SGD()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mae_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mae_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "print('loss function=mean_squared_error')\n",
    "print('optimizer=Adam()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=20, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss='mean_squared_error', optimizer=RMSprop())\n",
    "print('optimizer=RMSprop()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD())\n",
    "print('optimizer=SGD()')\n",
    "print('batch_size=8')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=8, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=16')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=16, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=32')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=32, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=64')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=64, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('batch_size=128')\n",
    "model.set_weights(mse_initial_weights)\n",
    "history = model.fit(x=[train.user.values, train.book.values], y=train.rating.values,\n",
    "                    batch_size=128, epochs=100, verbose=1,\n",
    "                    validation_data=([test.user.values, test.book.values], test.rating.values),\n",
    "                    callbacks=[mse_checkpoint])\n",
    "print('')\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "We evaluate our trained model on the test data to see how well it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136/6136 [==============================] - 3s 483us/step - loss: 0.9376\n",
      "Test MSE: 0.9375975728034973\n"
     ]
    }
   ],
   "source": [
    "model=load_model('../data/book/mse_best_model.h5')\n",
    "mse = model.evaluate([test.user.values, test.book.values], test.rating.values)\n",
    "print(f'Test MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136/6136 [==============================] - 3s 495us/step - loss: 0.7050\n",
      "Test MSE: 0.7050154209136963\n"
     ]
    }
   ],
   "source": [
    "model=load_model('../data/book/mae_best_model.h5')\n",
    "mae = model.evaluate([test.user.values, test.book.values], test.rating.values)\n",
    "print(f'Test MSE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
